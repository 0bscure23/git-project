{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c338462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (0.31.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface_hub) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atasets (C:\\Users\\asus\\.conda\\envs\\advprompter\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atasets (C:\\Users\\asus\\.conda\\envs\\advprompter\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atasets (C:\\Users\\asus\\.conda\\envs\\advprompter\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: datasets in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (0.31.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: trl in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from trl) (1.7.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from trl) (3.6.0)\n",
      "Requirement already satisfied: rich in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: transformers>=4.46.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from trl) (4.51.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from accelerate>=0.34.0->trl) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from accelerate>=0.34.0->trl) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from accelerate>=0.34.0->trl) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from accelerate>=0.34.0->trl) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from accelerate>=0.34.0->trl) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.4.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from tqdm>=4.66.3->datasets>=3.0.0->trl) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: trl in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from trl) (1.7.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from trl) (3.6.0)\n",
      "Requirement already satisfied: rich in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from accelerate>=0.34.0->trl) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\.conda\\envs\\advprompter\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: datasets in /home/vipuser/anaconda3/lib/python3.9/site-packages (3.6.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: pandas in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: packaging in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: filelock in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (3.3.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: xxhash in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: trl in /home/vipuser/anaconda3/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (3.6.0)\n",
      "Requirement already satisfied: rich in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (4.51.3)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (21.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (1.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (0.31.1)\n",
      "Requirement already satisfied: pyyaml in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (6.0)\n",
      "Requirement already satisfied: psutil in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (5.8.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (2.7.0)\n",
      "Requirement already satisfied: xxhash in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: filelock in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (3.3.1)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (20.0.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: pandas in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (1.3.4)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.18)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (21.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->accelerate>=0.34.0->trl) (3.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2021.10.8)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.85)\n",
      "Requirement already satisfied: jinja2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.4.1)\n",
      "Requirement already satisfied: networkx in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.6.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.26.2)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.3.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.80)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate>=0.34.0->trl) (58.0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.34.0->trl) (1.2.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers>=4.46.0->trl) (2021.8.3)\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in /home/vipuser/anaconda3/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in /home/vipuser/anaconda3/lib/python3.9/site-packages (4.51.3)\n",
      "Requirement already satisfied: trl in /home/vipuser/anaconda3/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: fsspec in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: filelock in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: networkx in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from triton==3.3.0->torch) (58.0.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (3.6.0)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: rich in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: psutil in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (5.8.0)\n",
      "Requirement already satisfied: pandas in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (1.3.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from fsspec->torch) (3.11.18)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.20.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.4.3)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (21.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from pandas->datasets>=3.0.0->trl) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple huggingface_hub\n",
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple datasets\n",
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple trl\n",
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade torch transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b4dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/vipuser/anaconda3/lib/python3.9/site-packages (0.31.1)\n",
      "Requirement already satisfied: filelock in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (3.3.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: requests in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (1.1.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61c5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37e84c4-4bd6-47de-a253-abd071568f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\.conda\\envs\\advprompter\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748e1841-74f5-46ca-87a4-4cb81ec6ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "import done\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, HfFolder\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "print(torch.__version__)\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86332daa-8fa7-43c7-8aaf-b8ba4eb7dae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face API 令牌已设置\n"
     ]
    }
   ],
   "source": [
    "# log in\n",
    "\n",
    "# 替换为你的Hugging Face令牌\n",
    "hf_token = \"\"\n",
    "\n",
    "# 登录Hugging Face\n",
    "login(token=hf_token)\n",
    "\n",
    "# 验证令牌是否设置正确\n",
    "api = HfApi()\n",
    "token = HfFolder.get_token()\n",
    "if token:\n",
    "    print(\"Hugging Face API 令牌已设置\")\n",
    "else:\n",
    "    print(\"Hugging Face API 令牌未设置，请检查环境变量\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce73c82-4c37-44bb-a6c7-5fd63bfbd427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 配置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00393442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总显存: 11.99 GB\n",
      "已分配显存: 0.00 GB\n",
      "剩余显存: 11.99 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 检查是否有可用的 CUDA 设备\n",
    "if torch.cuda.is_available():\n",
    "    # 获取当前设备\n",
    "    device = torch.cuda.current_device()\n",
    "    # 获取总显存\n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "    # 获取已分配的显存\n",
    "    allocated_memory = torch.cuda.memory_allocated(device)\n",
    "    # 计算剩余显存\n",
    "    free_memory = total_memory - allocated_memory\n",
    "    \n",
    "    print(f\"总显存: {total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"已分配显存: {allocated_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"剩余显存: {free_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"没有可用的 CUDA 设备。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704c2bc7-ad51-463c-b75f-b41e8fc728c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改后的格式转换函数\n",
    "def format_instruction_example(example):\n",
    "    instruction = example[\"instruction\"]\n",
    "    input_text = example[\"input\"]\n",
    "    response = example[\"output\"]\n",
    "    \n",
    "    if input_text and input_text.strip() != \"\":\n",
    "        text = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{response}\"\n",
    "    else:\n",
    "        text = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n{response}\"\n",
    "    \n",
    "    # 编码文本\n",
    "    encoded = tokenizer(text, truncation=True, max_length=512)\n",
    "    \n",
    "    # 明确添加\"text\"字段\n",
    "    encoded[\"text\"] = text\n",
    "    \n",
    "    # 标签通常与输入相同\n",
    "    encoded[\"labels\"] = encoded[\"input_ids\"].copy()\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac1f6011-c6ba-4aa2-ab18-6067e66667cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\.conda\\envs\\advprompter\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\asus\\.cache\\huggingface\\hub\\models--Qwen--Qwen3-0.6B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Map: 100%|██████████| 8164/8164 [00:04<00:00, 1730.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model and dataset load done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # 加载模型和分词器\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "# model = model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"BRZ911/Medical_consultation_data_SFT\", split=\"train\")\n",
    "\n",
    "# 获取数据集的前10%\n",
    "train_dataset = dataset.select(range(int(len(dataset) * 0.01)))\n",
    "\n",
    "# 应用格式转换\n",
    "formatted_dataset = train_dataset.map(format_instruction_example)\n",
    "\n",
    "print('model and dataset load done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fe787c-27d9-4e84-810c-17011d3b2861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集字段: dict_keys(['instruction', 'input', 'output'])\n",
      "\n",
      "第一个样本内容: {'instruction': '宝宝现在纯母乳喂养，不吃奶瓶怎么办？有什么妙招？小便黄想给他喝水，可他白开水就是不喝，奶粉也不吃。', 'input': '', 'output': '你可以用小勺来喂宝宝喝水或者纯果汁。如果宝宝小于六个月大就纯母乳喂养最好。母亲平常多喝些水。'}\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集的字段信息\n",
    "print(\"数据集字段:\", train_dataset.features.keys())\n",
    "\n",
    "# 查看第一个样本的内容\n",
    "if len(train_dataset) > 0:\n",
    "    print(\"\\n第一个样本内容:\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f27d560-5f93-41c2-b603-bc71325973ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asus\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asus\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "样本 1 的问题:\n",
      "宝宝现在纯母乳喂养，不吃奶瓶怎么办？有什么妙招？小便黄想给他喝水，可他白开水就是不喝，奶粉也不吃。\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，宝宝现在纯母乳喂养，不吃奶瓶，小便黄，想给他喝水，但白开水不喝，奶粉也不吃。这可能有几种情况需要考虑。首先，纯母乳喂养的宝宝通常会自然地接受母乳，但有时可能会出现一些特殊情况，比如乳头不适、乳汁分泌不足、或者宝宝对奶瓶的适应问题。小便黄可能是因为宝宝的尿液中含有较多的糖分，这可能是因为乳汁中的糖分较高，或者宝宝的消化系统需要更多的水分来处理这些糖分。\n",
      "\n",
      "对于宝宝不吃奶瓶的情况，可以尝试以下几...\n",
      "\n",
      "实际回答参考:\n",
      "你可以用小勺来喂宝宝喝水或者纯果汁。如果宝宝小于六个月大就纯母乳喂养最好。母亲平常多喝些水。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 2 的问题:\n",
      "肝功和两对半检查正常，但总胆红素和间接胆红素偏高，分别为22.2和17.3.请问这是什么原因呢？如果不去管它，会有什么后果呢？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，用户提到肝功和两对半检查正常，但总胆红素和间接胆红素偏高，分别为22.2和17.3。首先，我需要确认用户的问题是否正确。总胆红素和间接胆红素偏高通常与肝功能异常有关，但用户说两对半检查正常，这可能意味着肝功能没有问题。接下来，我需要考虑可能的原因。\n",
      "\n",
      "总胆红素偏高可能由多种因素引起，比如溶血、胆道阻塞、肝硬化、胆道疾病等。间接胆红素偏高可能与溶血有关，因为溶血会导致胆红素生成增加。用户提到两...\n",
      "\n",
      "实际回答参考:\n",
      "总胆红素和间接胆红素偏高可能是由于药物影响或饮酒等原因引起的。此外，饮食也可能对胆红素水平产生影响。如果不处理这个问题，可能会导致进一步的健康问题。建议您咨询医生以获取更详细的诊断和治疗建议。此外，多补充水果和蔬菜也是一个好的饮食习惯。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 3 的问题:\n",
      "宝宝前段时间感冒了、去医院检查了开了一些药吃了、但是最近开始是一直咳嗽、很长时间了也不见好、特别害怕引发别的什么疾病、想问一下专家孩子这样咳嗽会引发肺炎吗孩子总是咳嗽会引发肺炎吗\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来详细回答这个问题。首先，宝宝咳嗽的情况，是否会导致肺炎，需要结合具体情况来判断。一般来说，咳嗽本身并不一定会直接引发肺炎，但咳嗽可能是一个早期症状，提示宝宝可能存在一些潜在的健康问题。\n",
      "\n",
      "首先，咳嗽本身是身体的一种防御机制，通常在感冒或呼吸道感染时出现。如果宝宝的咳嗽持续时间较长，且伴有其他症状，比如发热、呼吸急促、痰液增多等，可能提示感染正在持续发展。这时候，医生可能会建议进行进一步的...\n",
      "\n",
      "实际回答参考:\n",
      "孩子长时间咳嗽，可能会有肺部炎症，需要及时治疗。小儿肺炎的症状一般为高热、咳嗽、咳痰等，但也有部分表现为低热或不热，需要详细检查明确后再做相应的治疗。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 4 的问题:\n",
      "我身体一直都好没受过伤，以前膝盖会偶尔酸痛，时间都比较短，也没再意，现在连续酸痛三天了都没好，我今年28岁，请问是怎么回事。\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，用户现在膝盖连续酸痛三天，28岁，之前没受过伤，现在症状持续。首先，我需要考虑可能的原因。膝盖酸痛可能有多种因素，比如关节炎、肌肉劳损、过度使用、或者可能的其他健康问题。\n",
      "\n",
      "用户提到之前膝盖偶尔酸痛，时间短，没再意，现在连续三天。这说明症状可能已经持续了一段时间，可能需要更详细的检查。不过用户可能没有意识到症状的持续性，或者可能有其他原因。\n",
      "\n",
      "接下来，我需要考虑常见的膝盖问题。比如，关节炎、...\n",
      "\n",
      "实际回答参考:\n",
      "建议进行补钙治疗。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 5 的问题:\n",
      "您好请问胸部疼痛是感冒引起的还是肺炎引起的？又或者是劳累过度引起的？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "您好，胸部疼痛的原因有很多，包括感冒、肺炎、劳累等。如果您有具体的症状，比如咳嗽、发热、胸痛等，可以告诉我，我会帮您进一步分析。同时，建议您及时就医，以排除更严重的疾病。\n",
      "\n",
      "### Response:\n",
      "您好，胸部疼痛可能与感冒、肺炎或劳累有关。如果您有其他症状，比如咳嗽、发热、胸痛等，可以告诉我，我会帮您进一步分析。同时，建议您及时就医，以排除更严重的疾病。\n",
      "\n",
      "### Response:\n",
      "您好，胸...\n",
      "\n",
      "实际回答参考:\n",
      "胸部疼痛可能是由感冒、肺炎或劳累过度引起的。如果你感到胸部疼痛，最好积极治疗感冒的情况，并考虑进行X线检查。同时，注意预防肺炎的情况，观察是否有咳嗽不适的情况。此外，注意少食生冷刺激性食物也是有帮助的。如果疼痛持续或加重，建议咨询医生进行进一步的诊断和治疗。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 6 的问题:\n",
      "孩子咳嗽总是不好，反复咳嗽，治疗一段时间也不见太大的效果，咳嗽间歇时间不确定，咽部有痰但是咳嗽不出来，该做哪些检查呢。。天津儿童医院看过，怀疑是过敏性咳嗽吃药未见好。县医院化验拍照说是支原体感染，输液...\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来帮您分析一下。孩子咳嗽反复且不缓解，可能有多种原因。首先，支周炎是常见的原因，但炎症顽固可能需要进一步检查。通常需要做哪些检查呢？\n",
      "\n",
      "1. **血常规**：检查白细胞计数和中性粒细胞比例，看看是否有感染或炎症。\n",
      "2. **C反应蛋白（CRP）**：炎症指标，如果CRP升高，可能提示炎症持续。\n",
      "3. **胸部X光或CT**：排除其他肺部疾病，如肺炎或结核。\n",
      "4. **痰培养**：如果咽部有...\n",
      "\n",
      "实际回答参考:\n",
      "根据孩子的症状和治疗情况，建议您继续与医生沟通并进行进一步的检查。对于长期咳嗽的情况，可能需要进行以下检查来确诊和进一步了解病因：\n",
      "\n",
      "1. 肺功能检查：肺功能检查可以评估孩子的呼吸功能，包括肺活量、呼气流量等指标，以帮助判断是否存在肺部功能异常。\n",
      "\n",
      "2. 支气管镜检查：支气管镜检查可以直接观察支气管的情况，检查是否存在支气管炎、支气管扩张等疾病。\n",
      "\n",
      "3. 过敏原检查：过敏原检查可以帮助确定是否存在...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 7 的问题:\n",
      "我月经天数正常，但这几次经量比以前减少了，天数缩短了请问是怎么回事？谢谢！.我月经天数正常，但这几次经量比以前减少了，天数缩短了请问是怎么回事？谢谢！\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，用户提到月经天数正常，但这次经量减少，天数缩短了。首先，我需要考虑可能的原因。月经周期的变化是常见的，但具体原因可能有多种。用户可能正在经历月经不调，或者有其他健康问题。\n",
      "\n",
      "接下来，我需要考虑用户可能的担忧。用户可能担心是否有什么严重的问题，或者是否需要进一步检查。用户可能没有意识到自己的身体状况，或者对月经变化感到不安。因此，我需要提供一些可能的原因，并建议用户咨询医生。\n",
      "\n",
      "然后，我需要组...\n",
      "\n",
      "实际回答参考:\n",
      "月经量和天数的变化可能是由于多种因素引起的。节食、熬夜、药物使用和内分泌失调都可能对月经产生影响，导致月经量减少和天数缩短。如果您对自己的月经变化感到担忧，建议您咨询医生进行进一步的评估和建议。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 8 的问题:\n",
      "宝宝晚上睡觉时喉咙里总是呼噜声,而且有痰,可就是咳不出来,时常伴有咳嗽，要怎么办才能帮宝宝把痰咳出来？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，宝宝晚上睡觉时喉咙里呼噜声，有痰，咳不出来，伴有咳嗽，这可能是什么原因呢？首先，我需要考虑宝宝的年龄和具体情况。如果是早产儿或新生儿，可能需要特别关注。宝宝的睡眠环境也很重要，是否在睡觉时有适当的安抚和休息，是否需要调整睡眠习惯。\n",
      "\n",
      "接下来，我应该建议宝宝多喝水，保持喉咙湿润，帮助痰液排出。同时，可以尝试用温水或湿毛巾敷在宝宝的额头或背部，帮助缓解不适。如果宝宝有持续的咳嗽或痰液过多，可能需...\n",
      "\n",
      "实际回答参考:\n",
      "爸爸妈妈应该及时帮助孩子排痰，婴幼儿的呼吸系统尚未发育完善，有痰不会咳，很容易堵在喉，气管或咽于胃中。要经常拍痰，以便将肺和气管里的痰排出。可以在医生的指导下服用药物治疗。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 9 的问题:\n",
      "头发越来越少，只掉不长，不知是心里抑郁造成，还是缺营养，我又不舍得剪了它，应该吃些什么，做些什么，才能让头发长密一点，或者有什么洗发水能巩固发根，防掉发？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，用户的问题是关于头发少掉不长，可能与心理抑郁或营养有关，但用户不愿意剪发，所以需要建议如何改善。首先，我需要确认用户的具体情况，但用户没有提供更多信息。接下来，我应该考虑常见的解决方案，比如营养补充、洗发水选择、心理调节等。同时，用户可能需要一些实际的步骤，比如饮食调整、洗发水推荐，以及可能的心理支持。还要注意用户可能的担忧，比如是否真的需要剪发，或者是否有其他原因导致脱发。最后，确保建议全...\n",
      "\n",
      "实际回答参考:\n",
      "脱发的原因有很多种，可能与营养不良、荷尔蒙失调、压力过大等因素有关。建议首先要放松心情，可以适当服用养发的药物，如养血生发胶囊，多做头部按摩，也可以适当调整饮食，多摄入富含维生素B、E、C等的食物，如瘦肉、鸡蛋、豆类、坚果、水果等。此外，选择温和的洗发水，避免频繁染发、烫发等损伤头发的行为，也有助于巩固发根，防止掉发。如果情况严重，建议及时就医。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 10 的问题:\n",
      "医生你好，我是前几天感冒，然后现在喉咙就干痒，一直咳，感觉有痰但又咳不出，咳着咳着还吐，这是什么问题啊\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我需要先理解你的症状。你提到前几天感冒后喉咙干痒、咳嗽、有痰但咳不出，还吐。这可能和感冒后的恢复期有关，也可能有其他原因。首先，感冒后喉咙干痒和咳嗽是常见的反应，但咳不出痰可能提示有其他问题，比如支气管炎、哮喘或慢性咳嗽。吐痰可能与痰液的性质有关，比如痰液粘稠或有特殊气味。建议你及时就医，进行相关检查，如胸部X光或痰液培养，以确定具体原因。同时，保持室内空气流通，多喝水，避免刺激性食物，有助...\n",
      "\n",
      "实际回答参考:\n",
      "根据您描述的症状，可能是上呼吸道感染引起的。建议进行胸部X光和血液检查以排查其他异常。另外，忌辛辣和酒类食品，建议清淡饮食。可以考虑服用蛇胆川贝液和咽炎片来缓解症状，并咨询医生是否需要使用阿莫西林克拉维酸钾进行治疗。希望能对您有所帮助。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 11 的问题:\n",
      "我总是失眠，经常会睡不着，就算睡着了也不会太长时间，然后就很难再睡着，经常早上起来没什么精神，严重的时候早上有点晕呼呼的，人一直很瘦，现在我的睡眠问题就越来越严重了，有什么好的治失眠的方法？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我理解你现在的困扰。失眠确实会让人感到疲惫和焦虑，尤其是在你提到的那些症状中。以下是一些可能对你有帮助的建议：\n",
      "\n",
      "1. **规律作息**：每天固定时间上床和起床，避免熬夜。保持固定的睡眠习惯有助于建立稳定的生物钟。\n",
      "\n",
      "2. **放松训练**：睡前可以尝试深呼吸、冥想或渐进式肌肉放松法，帮助放松身体，减少焦虑。\n",
      "\n",
      "3. **避免刺激性食物和饮料**：睡前避免咖啡因、酒精和巧克力，这些物质可能会...\n",
      "\n",
      "实际回答参考:\n",
      "失眠可能是由于睡眠障碍、内分泌问题或情绪精神状态改变引起的。如果失眠症状明显，可以考虑药物治疗。此外，改善睡眠情况的方法包括增加活动和运动。建议用户在治疗失眠之前，先了解自己的睡眠习惯和生活方式，看看是否有不良的睡眠习惯或生活习惯。同时，可以尝试一些非药物治疗方法，如保持规律的睡眠时间、避免午睡、保持良好的睡眠环境等。如果这些方法无效，可以咨询医生，考虑药物治疗。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 12 的问题:\n",
      "半个月大的宝宝鼻塞该怎么办？不是感冒发烧，估计吹空调吹的，吃药吃不了，有什么办法能让宝宝的鼻子通起来？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来详细回答这个问题。首先，半个月大的宝宝鼻塞，不是感冒发烧，可能是因为吹空调或者鼻腔干燥引起的。这时候需要先观察宝宝的状况，如果宝宝没有其他不适，比如发热、咳嗽、流鼻涕等症状，可能只是鼻塞，不需要立即用药。接下来，可以考虑一些家庭护理的方法来帮助宝宝缓解鼻塞。\n",
      "\n",
      "首先，可以建议宝宝多喝水，保持鼻腔湿润。因为宝宝的鼻腔比较干燥，多喝水有助于保持湿润。另外，可以使用生理盐水或者润喉糖来清洁鼻腔...\n",
      "\n",
      "实际回答参考:\n",
      "亲，鼻子不通气可能是宝宝囟门受凉导致，妈妈们可用厚毛巾在暖气片或者用包在盛沸水的容器外周放热；可在宝宝囟门处暖一会，不断热敷直到宝宝额头出细汗为止。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 13 的问题:\n",
      "小腹按压会有轻微疼痛，以前不会的，加上乳房按压也有些许疼，期间性生活有点频繁，没避孕。上个月是9号来的月经，是月经来潮前正常反应吗？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我需要仔细分析用户的问题。首先，用户提到小腹按压有轻微疼痛，之前没有过，加上乳房按压也有些疼。这可能与月经周期有关，特别是月经前的反应。用户还提到性生活频繁，没有避孕，上个月是9号来月经，是月经来潮前的正常反应吗？\n",
      "\n",
      "接下来，我需要考虑用户可能的健康状况。月经前的轻微疼痛可能与子宫内膜异位症、痛经有关，但这种情况需要进一步确认。用户提到性生活频繁，这可能与排卵期有关，但需要结合月经周期来判断...\n",
      "\n",
      "实际回答参考:\n",
      "这个问题涉及到小腹按压疼痛和乳房按压疼痛的原因，以及是否与月经有关。可能的原因包括月经前正常反应、怀孕、盆腔炎等。月经前正常反应可能会导致小腹按压疼痛和乳房按压疼痛，但具体症状和程度可能因人而异。怀孕也可能导致这些症状，建议去医院进行血液检查以确定是否怀孕。盆腔炎也是可能的原因之一，可以进行腹部彩超检查以排除盆腔炎的可能性。此外，还有其他可能的原因，如排卵期疼痛等。如果症状持续或加重，建议尽快就医...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 14 的问题:\n",
      "我之前起过正常的大痘痘，不过治好了从前天开始突然脸上就起了这种小脓包都不大但是很多都起在两侧脸颊上了而且还有发红的症状但是不痒…\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我理解你的描述。你之前有正常的大痘痘，但后来治好了，现在脸上出现了小脓包，集中在两侧脸颊，而且发红但不痒。这可能与痘痘后的恢复期有关，或者可能是其他皮肤问题。建议你观察几天，如果症状持续或加重，建议咨询皮肤科医生进行进一步检查和治疗。\n",
      "\n",
      "### Response:\n",
      "好的，我明白了。你之前有正常的大痘痘，但后来治好了，现在脸上出现了小脓包，集中在两侧脸颊，发红但不痒。这可能与痘痘后的恢复期有关...\n",
      "\n",
      "实际回答参考:\n",
      "根据你的描述，你脸上长了很多小脓包，而且还有发红的症状，但是不痒。这种情况可能是过敏性皮炎或湿疹的表现。建议使用四季百草膏外用观察一下，忌食辛辣多饮水，祝早日康复。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 15 的问题:\n",
      "药流十天后干净了,无腹痛，B超检查无残留（9*6mm）药流之后有残留14号胎囊出来，今天24号血基本干净，无其他不适，B超复查有残留（宫内见光团9*6mm)，请问后续可以吃药治疗不刮宫吗？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来详细回答你的问题。药流十天后干净了，但B超复查发现残留（宫内见光团9*6mm），这说明药流后仍有残留。虽然药流后通常会自然排出，但残留的存在可能需要进一步处理。根据你的情况，目前没有腹痛或其他不适，所以可以考虑药物治疗，但需要医生的指导。如果残留存在，可能需要进一步的医疗干预，比如刮宫。建议你咨询妇科医生，根据具体情况决定是否需要继续药物治疗或进行手术。\n",
      "\n",
      "### Response:\n",
      "好...\n",
      "\n",
      "实际回答参考:\n",
      "根据您的描述，药流后仍然存在残留物。建议您去医院进行血液检查，以明确诊断并确定是否需要进一步治疗。医生会根据检查结果和您的具体情况，给出最合适的治疗方案。请注意，药物治疗是否适合您需要医生来判断。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 16 的问题:\n",
      "孩子总是不停的动来动去啊，一会都闲不住，很多人都说你家还是怎么回事，怎么老是动呢，去医院检查医生说是多动症的表现，我想知道这个可以吃药来治疗么？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来详细回答这个问题。首先，多动症（ADHD）是一种常见的神经发育障碍，主要表现为注意力不集中、冲动、多动和过度活跃。对于孩子来说，多动症可能会影响学习、社交和日常生活。如果孩子确实存在多动症，医生可能会建议进行一些治疗，包括药物治疗和非药物治疗。\n",
      "\n",
      "关于药物治疗，通常会根据孩子的年龄和症状的严重程度来选择合适的药物。常见的药物包括甲基 doproton (MDD)、阿托品、利他唑等。这些药...\n",
      "\n",
      "实际回答参考:\n",
      "多动症是一种常见的儿童为异常疾病，表现为注意力不集中、多动、冲动等症状。药物治疗是一种常见的治疗方法，但需要在医生的指导下使用。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 17 的问题:\n",
      "宝宝刚出生三个星期大了，是个男孩，可是这两天发现她的皮肤越来越黄，快黄过鸡蛋黄了，医院检查是这是是黄疸，叫我不用担心，黄疸与母乳喂养有关系吗？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "宝宝出生后3周，皮肤出现黄疸，这是正常现象，但需要进一步检查确认。黄疸通常与母乳喂养有关，但具体情况可能因个体差异而有所不同。如果宝宝在母乳喂养期间出现黄疸，建议继续母乳喂养，同时观察宝宝的反应。如果黄疸持续或加重，应及时就医，排除其他可能的病因。\n",
      "\n",
      "### Response:\n",
      "宝宝出生后3周，皮肤出现黄疸，这是正常现象，但需要进一步检查确认。黄疸通常与母乳喂养有关，但具体情况可能因个体差异而有所...\n",
      "\n",
      "实际回答参考:\n",
      "黄疸是新生儿常见的病症，通常是由于胆红素代谢不良引起的。母乳喂养与黄疸有一定的关系，因为母乳中的激素会影响胆红素的代谢。但是，母乳喂养并不是导致黄疸的唯一原因，还有其他因素也可能导致黄疸。建议去医院进行检查，找出病因，好对症治疗，同时过几天也可以积极安排住院或者暂停哺乳后，可以配合蓝光等调理，观察几天应该会逐渐的恢复到正常水平的。注意休息。不要熬夜。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 18 的问题:\n",
      "最近这两年我内分泌出现了失调的情况，之后子宫的内膜增厚，月经经常不来有时候来了之后又没完没了也不停止，去医院检查有的说是建议刮宫与偶的说是子宫切除，但是到底该怎么办？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我需要先理解用户的问题。用户提到内分泌失调导致子宫内膜增厚，月经不规律，甚至不来，去医院检查可能被建议刮宫或手术切除。现在需要给出建议。\n",
      "\n",
      "首先，内分泌失调可能由多种因素引起，比如多囊卵巢综合征、甲状腺问题、压力大等。用户可能没有明确说明这些因素，所以需要建议他们进行进一步检查，比如内分泌功能测试、甲状腺功能检查、血糖水平等。\n",
      "\n",
      "接下来，关于刮宫和手术切除的建议，需要强调这些治疗方式的潜在风...\n",
      "\n",
      "实际回答参考:\n",
      "根据用户的描述，她最近两年出现了内分泌失调的情况，导致子宫内膜增厚和月经不规律。在医院检查后，有的医生建议刮宫，有的医生建议子宫切除。由于我不能确定用户是否已经排除了其他可能的原因，我建议用户再次咨询医生，了解更多关于她的具体情况和医生的建议。医生会根据用户的病情和需求，给出最合适的治疗方案。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 19 的问题:\n",
      "我有过脑外伤后遗症癫痫，前天开始癫痫平均20分钟发病一次，还没有治疗。间歇性癫痫病平时吃什么好？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，用户有脑外伤后遗症的癫痫，前天开始发作20分钟一次，还没治疗。现在问间歇性癫痫平时吃什么好。首先，我需要确认用户的情况是否符合间歇性癫痫的定义。间歇性癫痫通常是指发作间隔时间较长，且发作时无持续性抽搐，而是间歇性的，比如短暂的意识丧失。\n",
      "\n",
      "接下来，用户可能没有治疗，所以需要考虑饮食方面的建议。间歇性癫痫患者可能因为脑部损伤导致神经功能受损，因此饮食可能需要调整。常见的饮食建议包括低盐、低脂、...\n",
      "\n",
      "实际回答参考:\n",
      "癫痫是一种可治性的疾病，多数癫痫病人的预后是好的。只要通过及时而正确的诊断及合理的治疗，大多数发作均可减少或减轻。平时注意保养，防止诱发因素，戒除烟酒，避免过度疲劳等。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 20 的问题:\n",
      "我知道大三阳很严重,只想知道自己剩下的日子会有多久?谢谢.或者谁能告诉我,我该怎么办?吃些什么药才能好呢?我是真的苦恼啊.乙肝大三阳能活多久?原因及治疗建议和症状请问乙肝大三阳能活多久?.乙肝大三阳能...\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来帮你解答这个问题。首先，乙肝大三阳是指乙肝表面抗原、乙肝e抗原和乙肝d抗原都阳性，这通常意味着乙肝病毒已经感染并持续存在。对于乙肝患者来说，病情的严重程度和治疗效果会影响他们的生命长度。\n",
      "\n",
      "首先，乙肝大三阳的病情严重程度可能因人而异。如果患者没有接受治疗，病情可能会持续恶化，导致肝功能异常、肝硬化或肝癌。而如果患者接受了规范的抗病毒治疗，病情可能会得到控制，生命长度可能延长。\n",
      "\n",
      "接下来，...\n",
      "\n",
      "实际回答参考:\n",
      "乙肝大三阳患者应该定期复查，对于异常情况能够及时发现并积极有效治疗，降低肝损伤和疾病的恶化程度，减少并避免并发症的出现。这样也大大降低影响寿命的因素。如果任其发展，待肝损加重并出现严重并发症时再考虑治疗，其效果可能不理想，同时也可能在很大程度上缩短患者的寿命。因此，乙肝大三阳患者应该积极治疗，遵循医生的建议，定期复查，保持良好的生活习惯，合理饮食，避免过度劳累，保护肝脏健康。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 21 的问题:\n",
      "我在前几天被确诊白癜风早期，身上有一些白斑，现在是夏天，不知道需要注意哪些，早期白癜风夏天该怎么办？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，用户之前被确诊早期白癜风，现在是夏天，想知道需要注意哪些，以及夏天如何应对。首先，我需要确认用户的情况，可能他们已经确诊，但不确定如何应对。接下来，我应该考虑早期白癜风的特点，比如色素脱失，可能在阳光下更容易出现白斑，所以夏天需要注意防晒和保湿。然后，用户可能关心如何管理病情，比如饮食、作息，或者是否有其他治疗方法。需要确保信息准确，同时提供实用建议，比如防晒霜、保湿产品，以及可能的治疗建议...\n",
      "\n",
      "实际回答参考:\n",
      "白癜风是一种色素脱失性的皮肤病，夏天需要注意避免阳光直接照射，穿长袖衣服，避免出汗，不要吃刺激性食物，不要接触酚类化学物质，避免皮肤损伤，不要使用刺激性较强的药物。病患应该选择专业正规的医院进行规范化治疗，以免病情加重。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 22 的问题:\n",
      "我最近一直在纠结着一个问题，我不知道小孩子的近视眼到底要不要早点戴眼镜，因为我的小孩有近视，近视的度数不是很高，但是看黑板的时候都有点模糊了，有点影响到学习了，我们本来打算去给他配一个眼镜的但是又担心...\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我理解你对这个问题的担忧。近视眼虽然不是很高，但确实会影响学习和视力。建议你和孩子一起讨论是否需要配镜，同时也要注意日常的护眼和学习习惯。如果实在担心，可以先尝试看护眼和学习，再考虑是否需要配镜。希望对你有所帮助。\n",
      "\n",
      "### Response:\n",
      "好的，我理解你对这个问题的担忧。近视眼虽然不是很高，但确实会影响学习和视力。建议你和孩子一起讨论是否需要配镜，同时也要注意日常的护眼和学习习惯。如果...\n",
      "\n",
      "实际回答参考:\n",
      "对于小孩子的近视眼，专业的眼科医生一般会建议早点戴眼镜进行矫正。配戴眼镜可以帮助孩子看清远处的物体，减轻眼睛的疲劳，提高学习效果。眼镜的度数应该根据孩子的具体情况来确定，一般来说，度数较低的近视眼可以选择低度数的眼镜进行矫正。此外，家长还可以帮助孩子养成良好的用眼习惯，如控制用眼时间、保持正确的用眼距离、进行眼部保健操等，以减缓近视度数的增加。如果家长对于早戴眼镜存在疑虑，可以咨询眼科医生，了解更...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 23 的问题:\n",
      "昨天去医院看望刘姐家的孩子，感觉奇怪，进行的检查主要的是针对多动症的情况，孩子平时很不老实上课注意力也不集中在家的时候经常乱跑，有的时候会会磕到桌子受伤。有多动症的孩子饮食上面要注意些什么？多动症发病...\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来回答你的问题。首先，关于多动症（ADHD）的孩子饮食方面，我需要先了解ADHD的具体类型。ADHD分为两种主要类型：注意缺陷多动障碍（ADHD）和注意力缺陷多动障碍（ADHD）。这两种类型在饮食方面可能有不同影响，但总体上，饮食管理是关键。\n",
      "\n",
      "对于ADHD的孩子，饮食建议通常包括以下几点：\n",
      "\n",
      "1. **增加营养**：确保孩子摄入足够的蛋白质、维生素和矿物质，如铁、锌、维生素B12等。这些...\n",
      "\n",
      "实际回答参考:\n",
      "多动症是一种常见的儿童神经发育障碍，主要表现为注意力不集中、多动、冲动等症状。多动症的发病原因比较复杂，可能与遗传、环境、神经生化等多种因素有关。饮食方面，多动症患者应该注意饮食均衡，多吃一些富含蛋白质、维生素、矿物质等营养物质的食物，如鱼、肉、蛋、奶、豆类、蔬菜、水果等。此外，适当的运动也有助于缓解多动症症状，可以选择一些有氧运动，如游泳、跑步、骑车等。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 24 的问题:\n",
      "去医院检查发现孩子弱视，平时老看电视玩手机，医院也没给开药，就说注意日常不要过度用眼，有什么办法弱视可以恢复的吗？或者控制住不再增长也好啊。\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来帮您解答这个问题。首先，弱视是一种常见的儿童视力问题，通常需要通过正确的治疗和护理来改善。以下是一些可能的建议：\n",
      "\n",
      "1. **定期进行视力检查**：建议每季度或每半年进行一次视力检查，以监测弱视的发展情况。如果发现视力下降，及时就医并遵循医生的建议。\n",
      "\n",
      "2. **保持良好的作息时间**：确保孩子有足够的睡眠和休息时间，避免过度使用电子设备，尤其是屏幕时间。保持规律的作息有助于改善视力健康...\n",
      "\n",
      "实际回答参考:\n",
      "建议孩子少看电视，少玩手机，多进行户外运动，保持良好的用眼习惯。同时，建议到正规医院的眼科检查，确定弱视的类型，佩戴合适的眼镜进行矫正，再跟进弱视的类型，选择合适的弱视训练方法，如果孩子的眼底发育没什么异常，积极的进行治疗，一般情况恢复的效果还可以。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 25 的问题:\n",
      "最近因为上火牙疼了好长时间，不知道到底应该怎么办，平时都是依靠吃止痛药太缓解疼痛的，有什么方法可以治疗呢，上火牙疼应该怎么治疗才好呢？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，用户的问题是关于上火牙疼的治疗方法。首先，我需要确认用户的需求，他们可能已经尝试过止痛药但效果不佳，或者希望找到更有效的治疗方式。接下来，我应该考虑用户可能的健康状况，比如是否有其他口腔问题，或者是否有其他症状需要排除。然后，我需要提供一些基本的自我护理方法，比如饮食调整、口腔清洁、热敷等，同时也要提醒他们避免刺激性食物和饮料，以及及时就医的情况。最后，确保回答清晰、有条理，让用户能够根据自...\n",
      "\n",
      "实际回答参考:\n",
      "上火引起的牙疼，需要采取降火的措施，可以通过饮食来进行调理，多吃一些清热泻火的食物，比如水果，可以选择西瓜，草莓，香蕉，猕猴桃等等，榨成果汁也是可以的，但是要避免吃冰镇的水果，不然会刺激牙龈，导致牙疼更加严重。此外，喝一些凉茶也是可以的，比如绿茶，苦丁茶，红茶，普洱茶都是可以降火的。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 26 的问题:\n",
      "我有糖尿病12年，去年调整了一次。今年最近血糖餐后两小时13.6,又高了，餐前正常5.5.怎么能把餐后血糖控制好。\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我来帮你分析一下。首先，你去年调整了胰岛素，现在血糖又升高了。这可能是因为胰岛素的剂量或类型没有完全调整，或者你可能没有规律地按时吃药。建议你先检查一下胰岛素的剂量是否合适，是否需要调整。另外，饮食方面，要控制碳水化合物的摄入，避免高糖分的食物，同时保持适量的蛋白质和脂肪。此外，定期监测血糖，保持良好的生活习惯，如规律作息和适量运动，有助于控制血糖水平。如果情况没有改善，建议咨询医生，进行进...\n",
      "\n",
      "实际回答参考:\n",
      "要把餐后血糖控制好，可以采取以下措施：\n",
      "1. 控制饮食：避免高糖食物，减少脂肪摄入，选择高纤维食物，如粗粮和蔬菜。\n",
      "2. 适当体力活动：进行适量的体力活动可以帮助降低血糖水平。\n",
      "3. 保持正常体重：如果体重超过正常范围，应适当限制饮食，使体重减至正常范围。\n",
      "4. 定时定量进餐：可以少量多餐，保证蛋白质的摄入。\n",
      "5. 注意休息，保持良好的生活习惯。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 27 的问题:\n",
      "主要症状:头痛,没有精神,眼睛好像磨的不舒服,感觉舌头哆嗦的跳动.着急上火的时候更严重,睡眠不好.发病时间:两年前化验检查结果:拍脑CT,医院大夫说看片子没有问题喝过中药当时是感觉治好了,但是不定时的...\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我需要仔细分析用户提供的症状和检查结果。用户的主要症状包括头痛、没有精神、眼睛磨得不舒服、舌头哆嗦、着急上火时更严重、睡眠不好，发病时间两年前。检查结果显示脑CT没有问题，但症状持续存在，且服用中药和西药效果不佳，胃部也开始疼痛。\n",
      "\n",
      "首先，用户可能有慢性疼痛或神经问题，但CT没有显示异常，这可能意味着问题不在脑部。接下来，症状包括头痛、精神不振、眼睛不适、舌头颤抖和胃部不适。这些症状可能与神...\n",
      "\n",
      "实际回答参考:\n",
      "根据患者的症状描述，他可能患有某种疾病引起的头痛。建议他尽快就医，进行详细的身体检查和相关的实验室检查，以确定病因，并得到相应的治疗。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "样本 28 的问题:\n",
      "我患上了白癜风，而且还是在脸部皮肤上有很多白斑，这非常影响我的形象，就想先了解一下脸上的白癜风好不好治疗？\n",
      "\n",
      "生成的回答 (限制200 tokens):\n",
      "好的，我理解你的情况。白癜风是一种常见的皮肤疾病，主要表现为皮肤上出现白色斑块，通常与黑色素细胞的破坏有关。脸部皮肤的白斑尤其容易受到关注，因为它们可能对个人形象造成一定影响。\n",
      "\n",
      "关于治疗，目前有多种方法可供选择，包括药物治疗、光疗、激光治疗以及手术治疗等。对于脸部的白斑，治疗方案可能会有所不同，具体取决于病情的严重程度、患者的年龄、以及是否有其他相关疾病等因素。\n",
      "\n",
      "首先，药物治疗方面，常用的药物...\n",
      "\n",
      "实际回答参考:\n",
      "脸上的白癜风是可以进行治疗的，一般需要进行系统的治疗。治疗时间较长，大约需要一到两年的时间。脸上的白癜风通常采用药物治疗的方式进行，也可以考虑激光治疗、免疫治疗或手术治疗等。除了治疗，个人卫生也很重要，饮食方面应避免油腻和刺激性食物，同时适量锻炼身体。\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m### Instruction:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minstruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m### Response:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 生成回答\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m generated_response = generate_text(prompt)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 打印结果\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m样本 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 的问题:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mgenerate_text\u001b[39m\u001b[34m(prompt, max_length)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 生成文本（使用贪婪解码以确保确定性）\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     outputs = model.generate(\n\u001b[32m     12\u001b[39m         **inputs,\n\u001b[32m     13\u001b[39m         max_length=\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs.input_ids[\u001b[32m0\u001b[39m]) + max_length, \u001b[32m2048\u001b[39m),  \u001b[38;5;66;03m# 总长度限制\u001b[39;00m\n\u001b[32m     14\u001b[39m         temperature=\u001b[32m0.0\u001b[39m,      \u001b[38;5;66;03m# 确定性解码\u001b[39;00m\n\u001b[32m     15\u001b[39m         num_beams=\u001b[32m1\u001b[39m,          \u001b[38;5;66;03m# 禁用束搜索\u001b[39;00m\n\u001b[32m     16\u001b[39m         do_sample=\u001b[38;5;28;01mFalse\u001b[39;00m       \u001b[38;5;66;03m# 不使用采样\u001b[39;00m\n\u001b[32m     17\u001b[39m     )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 解码并提取生成的部分\u001b[39;00m\n\u001b[32m     20\u001b[39m generated_text = tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\generation\\utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._sample(\n\u001b[32m   2466\u001b[39m         input_ids,\n\u001b[32m   2467\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   2468\u001b[39m         stopping_criteria=prepared_stopping_criteria,\n\u001b[32m   2469\u001b[39m         generation_config=generation_config,\n\u001b[32m   2470\u001b[39m         synced_gpus=synced_gpus,\n\u001b[32m   2471\u001b[39m         streamer=streamer,\n\u001b[32m   2472\u001b[39m         **model_kwargs,\n\u001b[32m   2473\u001b[39m     )\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\generation\\utils.py:3434\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3432\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3434\u001b[39m     outputs = model_forward(**model_inputs, return_dict=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3436\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3437\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3438\u001b[39m     outputs,\n\u001b[32m   3439\u001b[39m     model_kwargs,\n\u001b[32m   3440\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3441\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\utils\\generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:850\u001b[39m, in \u001b[36mQwen3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m output_hidden_states = (\n\u001b[32m    846\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    847\u001b[39m )\n\u001b[32m    849\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28mself\u001b[39m.model(\n\u001b[32m    851\u001b[39m     input_ids=input_ids,\n\u001b[32m    852\u001b[39m     attention_mask=attention_mask,\n\u001b[32m    853\u001b[39m     position_ids=position_ids,\n\u001b[32m    854\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    855\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m    856\u001b[39m     use_cache=use_cache,\n\u001b[32m    857\u001b[39m     output_attentions=output_attentions,\n\u001b[32m    858\u001b[39m     output_hidden_states=output_hidden_states,\n\u001b[32m    859\u001b[39m     cache_position=cache_position,\n\u001b[32m    860\u001b[39m     **kwargs,\n\u001b[32m    861\u001b[39m )\n\u001b[32m    863\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    864\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\utils\\generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:576\u001b[39m, in \u001b[36mQwen3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    564\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    565\u001b[39m         partial(decoder_layer.\u001b[34m__call__\u001b[39m, **flash_attn_kwargs),\n\u001b[32m    566\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m         position_embeddings,\n\u001b[32m    574\u001b[39m     )\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     layer_outputs = decoder_layer(\n\u001b[32m    577\u001b[39m         hidden_states,\n\u001b[32m    578\u001b[39m         attention_mask=causal_mask,\n\u001b[32m    579\u001b[39m         position_ids=position_ids,\n\u001b[32m    580\u001b[39m         past_key_value=past_key_values,\n\u001b[32m    581\u001b[39m         output_attentions=output_attentions,\n\u001b[32m    582\u001b[39m         use_cache=use_cache,\n\u001b[32m    583\u001b[39m         cache_position=cache_position,\n\u001b[32m    584\u001b[39m         position_embeddings=position_embeddings,\n\u001b[32m    585\u001b[39m         **flash_attn_kwargs,\n\u001b[32m    586\u001b[39m     )\n\u001b[32m    588\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    590\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:286\u001b[39m, in \u001b[36mQwen3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    273\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    274\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m     **kwargs: Unpack[FlashAttentionKwargs],\n\u001b[32m    283\u001b[39m ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n\u001b[32m    284\u001b[39m     residual = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m    289\u001b[39m     hidden_states, self_attn_weights = \u001b[38;5;28mself\u001b[39m.self_attn(\n\u001b[32m    290\u001b[39m         hidden_states=hidden_states,\n\u001b[32m    291\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m         **kwargs,\n\u001b[32m    299\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\advprompter\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 对未训练的模型进行测试：\n",
    "\n",
    "# 生成测试函数\n",
    "def generate_text(prompt, max_length=200):\n",
    "    \"\"\"使用模型生成回答，限制最大长度为200 tokens\"\"\"\n",
    "    # 编码输入\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 生成文本（使用贪婪解码以确保确定性）\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=min(len(inputs.input_ids[0]) + max_length, 2048),  # 总长度限制\n",
    "            temperature=0.0,      # 确定性解码\n",
    "            num_beams=1,          # 禁用束搜索\n",
    "            do_sample=False       # 不使用采样\n",
    "        )\n",
    "    \n",
    "    # 解码并提取生成的部分\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text[len(prompt):].strip()  # 返回生成的部分\n",
    "\n",
    "# 对数据集的前10个样本进行测试\n",
    "for i, example in enumerate(train_dataset):\n",
    "    # 使用正确的字段名\n",
    "    instruction = example[\"instruction\"]\n",
    "    input_text = example[\"input\"]\n",
    "    \n",
    "    # 构建提示词\n",
    "    if input_text and input_text.strip() != \"\":\n",
    "        prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n\"\n",
    "    else:\n",
    "        prompt = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n\"\n",
    "    \n",
    "    # 生成回答\n",
    "    generated_response = generate_text(prompt)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"\\n样本 {i+1} 的问题:\")\n",
    "    print(instruction[:100] + (\"...\" if len(instruction) > 100 else \"\"))  # 截断显示\n",
    "    \n",
    "    print(f\"\\n生成的回答 (限制200 tokens):\")\n",
    "    print(generated_response[:200] + (\"...\" if len(generated_response) > 200 else \"\"))\n",
    "    \n",
    "    print(\"\\n实际回答参考:\")\n",
    "    print(example[\"output\"][:200] + (\"...\" if len(example[\"output\"]) > 200 else \"\"))\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45074138-25ad-44c6-b10a-f51baa405a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nanogcg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnanogcg\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnanogcg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run, GCGConfig\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 假设前面的代码块已经在Notebook中执行过\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 定义对话和目标\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nanogcg'"
     ]
    }
   ],
   "source": [
    "import nanogcg\n",
    "from nanogcg import run, GCGConfig\n",
    "# 假设前面的代码块已经在Notebook中执行过\n",
    "\n",
    "# 定义对话和目标\n",
    "messages = [{\"role\": \"user\", \"content\": \"Translate this sentence: \"}]\n",
    "target = \"This is a test.\"\n",
    "\n",
    "# 禁用前缀缓存以避免格式不兼容问题\n",
    "config = GCGConfig(\n",
    "    num_steps=50,\n",
    "    search_width=128,\n",
    "    topk=64,\n",
    "    n_replace=2,\n",
    "    use_prefix_cache=False  # 禁用前缀缓存\n",
    ")\n",
    "\n",
    "result = run(model, tokenizer, messages, target, config)\n",
    "print(f\"Best string: {result.best_string}\")\n",
    "print(f\"Best loss: {result.best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d58f614f-064c-4724-b953-71577b5dcea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: ain) )) )) ) ... (MediaMeshPro augmentedanasitet node.) onto ... (MediaMeshPro augmentedanasitet node.) onto ... (MediaMeshPro augmentedanasitet node.) onto ... (MediaMeshPro augmentedanasitet node.) onto ... (MediaMeshPro augmented\n"
     ]
    }
   ],
   "source": [
    "# 获取优化后的字符串\n",
    "optimized_string = result.best_string\n",
    "\n",
    "# 构建完整提示\n",
    "prompt = f\"Translate this sentence: {optimized_string}\"\n",
    "\n",
    "# 将提示转换为模型输入\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# 使用generate方法生成回复\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,  # 控制生成的最大长度\n",
    "        temperature=0.7,    # 控制生成的随机性\n",
    "        top_p=0.9,          # 控制采样策略\n",
    "        do_sample=True      # 启用采样\n",
    "    )\n",
    "\n",
    "# 解码生成的回复\n",
    "response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c059723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已成功加载到 GPU 上。\n"
     ]
    }
   ],
   "source": [
    "# 检查模型参数所在的设备\n",
    "for param in model.parameters():\n",
    "    if param.device.type == 'cuda':\n",
    "        print(\"模型已成功加载到 GPU 上。\")\n",
    "        break\n",
    "else:\n",
    "    print(\"模型未加载到 GPU 上，仍在 CPU 上。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea45c28-3719-47be-a7aa-3ec0d8a48382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改后的格式转换函数\n",
    "def format_instruction_example(example):\n",
    "    instruction = example[\"instruction\"]\n",
    "    input_text = example[\"input\"]\n",
    "    response = example[\"output\"]\n",
    "    \n",
    "    if input_text and input_text.strip() != \"\":\n",
    "        text = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{response}\"\n",
    "    else:\n",
    "        text = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n{response}\"\n",
    "    \n",
    "    # 编码文本\n",
    "    encoded = tokenizer(text, truncation=True, max_length=512)\n",
    "    \n",
    "    # 明确添加\"text\"字段\n",
    "    encoded[\"text\"] = text\n",
    "    \n",
    "    # 标签通常与输入相同\n",
    "    encoded[\"labels\"] = encoded[\"input_ids\"].copy()\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# 重新应用格式转换\n",
    "formatted_dataset = train_dataset.map(format_instruction_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c4efdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import setup_chat_format\n",
    "# Set up the chat format with default 'chatml' format\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c82c9c2-7b7d-4c29-9334-d3baea532324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a380971d16b749f9b2b7609544144041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/816477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练过程中出现错误: 'text'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    # training_args = SFTConfig(output_dir=\"/tmp\")\n",
    "    # 定义 SFT 训练配置\n",
    "    training_args = SFTConfig(\n",
    "    # 输出目录\n",
    "    output_dir=\"/tmp\",\n",
    "    # 训练轮数，减少轮数可以降低训练成本\n",
    "    num_train_epochs=3,\n",
    "    # 每批处理的样本数量，根据 GPU 内存调整\n",
    "    per_device_train_batch_size=8,\n",
    "    # 梯度累积步数，增大该值可以模拟更大的批次大小\n",
    "    gradient_accumulation_steps=4,\n",
    "    # 学习率，合适的学习率有助于模型收敛且降低成本\n",
    "    learning_rate=2e-5,\n",
    "    # 权重衰减，防止过拟合\n",
    "    weight_decay=0.01,\n",
    "    # 预热步数，在训练初期缓慢增加学习率\n",
    "    warmup_steps=500,\n",
    "    # 优化器使用 AdamW\n",
    "    optim=\"adamw_torch\",\n",
    "    # 每多少步保存一次模型\n",
    "    save_steps=10_000,\n",
    "    # 每多少步记录一次日志\n",
    "    logging_steps=100,\n",
    "    # 混合精度训练，使用 fp16 可以减少内存使用和训练时间\n",
    "    fp16=True,\n",
    ")\n",
    "    trainer = SFTTrainer(\n",
    "        model,\n",
    "        train_dataset=formatted_dataset,\n",
    "        args=training_args,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"训练过程中出现错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf5d9d-0ab3-48a3-9f05-a361427e783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型和分词器已保存到 C:\\Users\\asus\\Desktop\\fine_tuned_model\n"
     ]
    }
   ],
   "source": [
    "# 保存模型和分词器\n",
    "save_path = r'C:\\Users\\asus\\Desktop\\fine_tuned_model'\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"模型和分词器已保存到 {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80c45603-27b3-4d15-9965-a90c8a95c352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卸载前的GPU状态:\n",
      "GPU内存使用: 2274.25 MB\n",
      "GPU缓存使用: 2276.00 MB\n",
      "✅ 模型已移至CPU并删除\n",
      "✅ 分词器已删除\n",
      "\n",
      "卸载后的GPU状态:\n",
      "GPU内存使用: 0.00 MB\n",
      "GPU缓存使用: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# 检查当前GPU内存使用情况\n",
    "def print_gpu_memory():\n",
    "    \"\"\"打印当前GPU内存使用情况\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU内存使用: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"GPU缓存使用: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "    else:\n",
    "        print(\"未检测到GPU\")\n",
    "\n",
    "# 打印卸载前的GPU内存状态\n",
    "print(\"卸载前的GPU状态:\")\n",
    "print_gpu_memory()\n",
    "\n",
    "# 卸载模型和分词器\n",
    "try:\n",
    "    # 将模型移回CPU\n",
    "    if 'model' in locals() or 'model' in globals():\n",
    "        model.to('cpu')\n",
    "        del model\n",
    "        print(\"✅ 模型已移至CPU并删除\")\n",
    "    else:\n",
    "        print(\"⚠️ 未找到模型变量\")\n",
    "    \n",
    "    # 删除分词器（如果需要释放更多内存）\n",
    "    if 'tokenizer' in locals() or 'tokenizer' in globals():\n",
    "        del tokenizer\n",
    "        print(\"✅ 分词器已删除\")\n",
    "    else:\n",
    "        print(\"⚠️ 未找到分词器变量\")\n",
    "    \n",
    "    # 删除其他可能占用GPU内存的变量\n",
    "    if 'train_dataset' in locals() or 'train_dataset' in globals():\n",
    "        del train_dataset\n",
    "    if 'val_dataset' in locals() or 'val_dataset' in globals():\n",
    "        del val_dataset\n",
    "    \n",
    "    # 清空PyTorch缓存\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # 强制垃圾回收\n",
    "    gc.collect()\n",
    "    \n",
    "    # 打印卸载后的GPU内存状态\n",
    "    print(\"\\n卸载后的GPU状态:\")\n",
    "    print_gpu_memory()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"卸载过程中出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c37d6b-f2f4-484a-a674-76e83debf8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载微调过的模型和分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "    low_cpu_mem_usage=True\n",
    ").to(device)\n",
    "\n",
    "# 设置流式输出\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "# 准备输入\n",
    "prompt = \"今天天气很好。\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 生成参数\n",
    "generate_config = {\n",
    "    \"max_length\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "# 生成文本\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, streamer=streamer, **generate_config)\n",
    "\n",
    "# 解码输出（如果没有使用streamer）\n",
    "if not streamer:\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bead75-02e4-443d-a223-2b482e5b6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标文本（需精确匹配）\n",
    "target_start = \"根据您描述的症状，可能是上呼吸道感染引起的。\"\n",
    "target_start_ids = tokenizer(target_start, return_tensors=\"pt\").input_ids.squeeze().tolist()\n",
    "\n",
    "# 超参数\n",
    "n_tokens = 15          # 初始提示词长度调长（原10过短）\n",
    "num_steps = 150         # 增加GCG迭代次数\n",
    "k = 128                # 扩大top-k候选范围，增加多样性\n",
    "B = 64                 # 增加候选提示词数量\n",
    "sample_size = n_tokens      # 梯度计算采样token数（仅用于可视化，实际用全梯度）\n",
    "max_generation_length = len(target_start_ids) + 20  # 限制生成长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3cb02-785c-430a-944c-20eb36f0d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, target_start_ids):\n",
    "    \"\"\"严格匹配整个目标文本的损失函数\"\"\"\n",
    "    target_tensor = torch.tensor(target_start_ids, device=logits.device).long()\n",
    "    batch_size, seq_len, vocab_size = logits.shape\n",
    "    target_len = len(target_start_ids)\n",
    "    valid_positions = seq_len - target_len + 1  # 有效匹配位置数\n",
    "    \n",
    "    if valid_positions <= 0:\n",
    "        return torch.tensor(0.0, device=logits.device)  # 避免除零\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for i in range(batch_size):\n",
    "        # 仅计算完全匹配目标长度的子序列损失\n",
    "        if seq_len >= target_len:\n",
    "            sub_logits = logits[i, :target_len]  # 强制匹配前target_len个token\n",
    "            loss = F.cross_entropy(sub_logits.view(-1, vocab_size), target_tensor)\n",
    "            total_loss += loss\n",
    "    \n",
    "    return total_loss / (batch_size * max(1, valid_positions))  # 防止除零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46f128-20d7-4d00-87ec-efd2df7c3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(model, input_ids, position, vocab_size, target_start_ids):\n",
    "    \"\"\"\n",
    "    计算单个位置的token梯度（one-hot编码）\n",
    "    :return: 梯度向量（形状[vocab_size]，值越小表示损失越低）\n",
    "    \"\"\"\n",
    "    embed_layer = model.get_input_embeddings()\n",
    "    original_token = input_ids[position].item()\n",
    "    vocab_size_model = embed_layer.weight.size(0)  # 获取模型嵌入矩阵的输入维度\n",
    "\n",
    "    # 生成one-hot编码并替换嵌入\n",
    "    one_hot = torch.zeros(vocab_size_model, device=device)\n",
    "    one_hot[original_token] = 1.0\n",
    "    one_hot.requires_grad_()\n",
    "\n",
    "    input_embeds = embed_layer(input_ids.unsqueeze(0))  # 原始嵌入[1, seq_len, embed_dim]\n",
    "    input_embeds[0, position] = one_hot @ embed_layer.weight  # 替换当前位置嵌入\n",
    "\n",
    "    # 前向传播+损失计算+反向传播\n",
    "    with torch.enable_grad():\n",
    "        logits = model(inputs_embeds=input_embeds).logits\n",
    "        loss = compute_loss(logits, target_start_ids)\n",
    "        loss.backward()\n",
    "\n",
    "    return one_hot.grad  # 返回每个token的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb80f24-bc5f-4784-9e75-50b429ab46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcg_algorithm():\n",
    "    # 初始化提示词：随机生成n_tokens长度的token序列\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    initial_prompt = torch.randint(0, vocab_size, (n_tokens,), device=device).tolist()\n",
    "    current_prompt = initial_prompt.copy()\n",
    "    step_losses = []\n",
    "    \n",
    "    print(f\"[INIT] Initial Prompt: {tokenizer.decode(current_prompt)}\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # 转换为tensor\n",
    "        input_ids = torch.tensor(current_prompt, device=device).long()\n",
    "        grads = []  # 存储每个位置的梯度（形状[seq_len, vocab_size]）\n",
    "        \n",
    "        # 计算每个位置的梯度\n",
    "        for pos in range(n_tokens):\n",
    "            grad = calculate_gradient(model, input_ids, pos, vocab_size, target_start_ids)\n",
    "            grads.append(grad.cpu().numpy())  # 转换为CPU数组\n",
    "        \n",
    "        # 生成候选提示（梯度引导）\n",
    "        candidates = []\n",
    "        for _ in range(B):\n",
    "            new_prompt = current_prompt.copy()\n",
    "            pos = np.random.randint(n_tokens)  # 随机选择修改位置\n",
    "            \n",
    "            # 选择梯度最小的k个token（梯度越小，损失下降潜力越大）\n",
    "            top_k_indices = np.argsort(grads[pos])[:k]  # 按梯度升序排列\n",
    "            new_token = np.random.choice(top_k_indices)  # 随机选择一个候选token\n",
    "            new_prompt[pos] = new_token\n",
    "            candidates.append(new_prompt)\n",
    "        \n",
    "        # 评估候选损失\n",
    "        best_loss = float('inf')\n",
    "        best_candidate = current_prompt\n",
    "        for cand in candidates:\n",
    "            input_ids_cand = torch.tensor(cand, device=device).long().unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_ids_cand).logits\n",
    "                loss = compute_loss(logits, target_start_ids)\n",
    "            \n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                best_candidate = cand\n",
    "        \n",
    "        # 更新提示词\n",
    "        current_prompt = best_candidate\n",
    "        step_losses.append(best_loss)\n",
    "        print(f\"[STEP {step + 1}] Loss: {best_loss:.4f}, Prompt: {tokenizer.decode(current_prompt)}\")\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(step_losses, label=\"Loss\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"GCG Optimization Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return current_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d093d3-9122-4569-8403-0550dd6a8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniprompt_algorithm():\n",
    "    global n_tokens\n",
    "    global num_steps\n",
    "    running_min = 0\n",
    "    running_max = 100000\n",
    "    best = None\n",
    "    while True:\n",
    "        z = gcg_algorithm()\n",
    "        input_ids = torch.tensor(z, device=device).long().unsqueeze(0)\n",
    "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=device)\n",
    "        \n",
    "        # 设置填充标记ID，如果模型没有指定的话\n",
    "        if tokenizer.pad_token_id is None:\n",
    "            tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 显式要求生成目标文本长度，避免截断\n",
    "            # generated_output = model.generate(\n",
    "            #     input_ids,\n",
    "            #     attention_mask=attention_mask,\n",
    "            #     pad_token_id=tokenizer.eos_token_id,\n",
    "            #     max_length=len(target_start_ids) + 20,  # 增加冗余长度\n",
    "            #     min_length=len(target_start_ids),       # 最小生成长度等于目标长度\n",
    "            #     eos_token_id=tokenizer.eos_token_id,\n",
    "            #     early_stopping=False\n",
    "            # )\n",
    "            generated_output = model.generate(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                num_beams=50,\n",
    "                no_repeat_ngram_size=2,\n",
    "                early_stopping=False,  # 不提前停止\n",
    "                temperature=0.2\n",
    "            )\n",
    "            generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
    "            print(f\"Generated text: {generated_text} :end\")\n",
    "            print(f\"with token of {n_tokens}\")\n",
    "            \n",
    "            # 严格检查是否完全匹配（包括大小写和标点）\n",
    "            if generated_text.strip() == target_start.strip():\n",
    "                running_max = n_tokens\n",
    "                n_tokens = max(1, n_tokens - 1)  # 至少保留1个token\n",
    "                best = z\n",
    "                num_steps = max(50, num_steps - 10)  # 避免迭代次数过低\n",
    "                print(f\"✅ Matched at {n_tokens} tokens!\")\n",
    "            else:\n",
    "                running_min = n_tokens\n",
    "                n_tokens = min(n_tokens + 5, running_max)  # 每次增加5个token，加速搜索\n",
    "                num_steps = min(500, num_steps + 50)       # 增加迭代次数上限\n",
    "                print(f\"❌ Not matched, increase to {n_tokens} tokens\")\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea3229-9a07-4304-a617-c3318e61acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for miniprompt\n",
    "\n",
    "final_prompt = miniprompt_algorithm()\n",
    "\n",
    "# 计算ACR\n",
    "if final_prompt:\n",
    "    target_length = len(target_start_ids)\n",
    "    min_prompt_length = len(final_prompt)\n",
    "    acr = target_length / min_prompt_length if min_prompt_length > 0 else 0\n",
    "else:\n",
    "    acr = 0\n",
    "\n",
    "# 输出最终结果\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "if final_prompt:\n",
    "    print(f\"Final Optimized Prompt (Tokens: {len(final_prompt)}):\")\n",
    "    print(f\"  Text: {tokenizer.decode(final_prompt)}\")\n",
    "    print(f\"  Tokens: {final_prompt}\")\n",
    "else:\n",
    "    print(\"No valid prompt found.\")\n",
    "print(f\"ACR: {acr}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ffa2bf-e96b-4b96-94ef-bc6656aa3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "while True:\n",
    "    # 获取用户输入\n",
    "    user_input = input(\"你: \")\n",
    "    if user_input == \"退出\":\n",
    "        break\n",
    "\n",
    "    # 对用户输入进行编码\n",
    "    input_ids = tokenizer.encode(user_input, return_tensors='pt').to(device)\n",
    "    # 创建注意力掩码\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=device)\n",
    "\n",
    "    # 设置填充标记ID，如果模型没有指定的话\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        \n",
    "    temp = float(0.8)\n",
    "\n",
    "    # 生成模型回复\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        num_beams=15,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=False,  # 不提前停止\n",
    "        temperature=temp,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # 对模型输出进行解码\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # 统计输出的token数\n",
    "    tokens = tokenizer.tokenize(response)\n",
    "    token_count = len(tokens)\n",
    "\n",
    "    # 提取模型回复（去除用户输入部分）\n",
    "    response = response[len(user_input):].strip()\n",
    "\n",
    "    print(f\"模型: {response}\")\n",
    "    print(f\"输出的token数: {token_count}\")\n",
    "\n",
    "print(\"对话结束。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09235bc-1eac-4d00-af0b-628e6a6acc94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
