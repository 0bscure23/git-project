{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c338462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (0.30.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: datasets in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.2.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: trl in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (0.17.0)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from trl) (3.5.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from trl) (13.7.1)\n",
      "Requirement already satisfied: transformers>=4.46.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trl) (4.47.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate>=0.34.0->trl) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate>=0.34.0->trl) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate>=0.34.0->trl) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate>=0.34.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate>=0.34.0->trl) (2.6.0+cu126)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from accelerate>=0.34.0->trl) (0.30.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (3.10.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->trl) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->trl) (2.15.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.1.31)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets>=3.0.0->trl) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\asus\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\asus\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\asus\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu126 requires torch==2.6.0+cu126, but you have torch 2.7.0 which is incompatible.\n",
      "torchvision 0.21.0+cu126 requires torch==2.6.0+cu126, but you have torch 2.7.0 which is incompatible.\n",
      "nanogcg 0.3.0 requires transformers<=4.47.1,>=4.4, but you have transformers 4.51.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (2.6.0+cu126)\n",
      "Collecting torch\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/44/80/b353c024e6b624cd9ce1d66dcb9d24e0294680f95b369f19280e241a0159/torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "     ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.5/212.5 MB 1.7 MB/s eta 0:02:07\n",
      "     ---------------------------------------- 0.8/212.5 MB 1.8 MB/s eta 0:02:00\n",
      "     ---------------------------------------- 1.6/212.5 MB 2.2 MB/s eta 0:01:36\n",
      "     ---------------------------------------- 2.1/212.5 MB 2.3 MB/s eta 0:01:30\n",
      "      --------------------------------------- 2.9/212.5 MB 2.6 MB/s eta 0:01:20\n",
      "      --------------------------------------- 3.7/212.5 MB 2.9 MB/s eta 0:01:13\n",
      "      --------------------------------------- 4.2/212.5 MB 3.0 MB/s eta 0:01:10\n",
      "      --------------------------------------- 4.2/212.5 MB 3.0 MB/s eta 0:01:10\n",
      "      --------------------------------------- 4.2/212.5 MB 3.0 MB/s eta 0:01:10\n",
      "      --------------------------------------- 5.0/212.5 MB 2.3 MB/s eta 0:01:31\n",
      "     - -------------------------------------- 5.8/212.5 MB 2.4 MB/s eta 0:01:26\n",
      "     - -------------------------------------- 5.8/212.5 MB 2.4 MB/s eta 0:01:26\n",
      "     - -------------------------------------- 5.8/212.5 MB 2.4 MB/s eta 0:01:26\n",
      "     - -------------------------------------- 5.8/212.5 MB 2.4 MB/s eta 0:01:26\n",
      "     - -------------------------------------- 6.3/212.5 MB 2.0 MB/s eta 0:01:45\n",
      "     - -------------------------------------- 6.3/212.5 MB 2.0 MB/s eta 0:01:45\n",
      "     - -------------------------------------- 8.1/212.5 MB 2.2 MB/s eta 0:01:32\n",
      "     - -------------------------------------- 8.1/212.5 MB 2.2 MB/s eta 0:01:32\n",
      "     - -------------------------------------- 8.9/212.5 MB 2.2 MB/s eta 0:01:33\n",
      "     - -------------------------------------- 9.4/212.5 MB 2.2 MB/s eta 0:01:32\n",
      "     - ------------------------------------- 10.0/212.5 MB 2.2 MB/s eta 0:01:32\n",
      "     - ------------------------------------- 10.2/212.5 MB 2.2 MB/s eta 0:01:33\n",
      "     - ------------------------------------- 10.2/212.5 MB 2.2 MB/s eta 0:01:33\n",
      "     - ------------------------------------- 10.2/212.5 MB 2.2 MB/s eta 0:01:33\n",
      "     -- ------------------------------------ 11.5/212.5 MB 2.1 MB/s eta 0:01:34\n",
      "     -- ------------------------------------ 11.8/212.5 MB 2.2 MB/s eta 0:01:33\n",
      "     -- ------------------------------------ 11.8/212.5 MB 2.2 MB/s eta 0:01:33\n",
      "     -- ------------------------------------ 12.1/212.5 MB 2.0 MB/s eta 0:01:40\n",
      "     -- ------------------------------------ 13.4/212.5 MB 2.2 MB/s eta 0:01:33\n",
      "     -- ------------------------------------ 14.2/212.5 MB 2.2 MB/s eta 0:01:30\n",
      "     -- ------------------------------------ 14.2/212.5 MB 2.2 MB/s eta 0:01:30\n",
      "     -- ------------------------------------ 14.2/212.5 MB 2.2 MB/s eta 0:01:30\n",
      "     -- ------------------------------------ 14.7/212.5 MB 2.1 MB/s eta 0:01:36\n",
      "     -- ------------------------------------ 15.2/212.5 MB 2.1 MB/s eta 0:01:33\n",
      "     -- ------------------------------------ 15.7/212.5 MB 2.1 MB/s eta 0:01:34\n",
      "     -- ------------------------------------ 16.0/212.5 MB 2.1 MB/s eta 0:01:35\n",
      "     -- ------------------------------------ 16.0/212.5 MB 2.1 MB/s eta 0:01:35\n",
      "     --- ----------------------------------- 16.5/212.5 MB 2.0 MB/s eta 0:01:37\n",
      "     --- ----------------------------------- 17.3/212.5 MB 2.1 MB/s eta 0:01:33\n",
      "     --- ----------------------------------- 17.6/212.5 MB 2.1 MB/s eta 0:01:35\n",
      "     --- ----------------------------------- 17.8/212.5 MB 2.0 MB/s eta 0:01:36\n",
      "     --- ----------------------------------- 18.4/212.5 MB 2.0 MB/s eta 0:01:36\n",
      "     --- ----------------------------------- 19.4/212.5 MB 2.1 MB/s eta 0:01:32\n",
      "     --- ----------------------------------- 19.7/212.5 MB 2.1 MB/s eta 0:01:32\n",
      "     --- ----------------------------------- 19.9/212.5 MB 2.1 MB/s eta 0:01:32\n",
      "     --- ----------------------------------- 19.9/212.5 MB 2.1 MB/s eta 0:01:32\n",
      "     --- ----------------------------------- 20.2/212.5 MB 2.0 MB/s eta 0:01:35\n",
      "     --- ----------------------------------- 20.4/212.5 MB 2.0 MB/s eta 0:01:37\n",
      "     --- ----------------------------------- 21.0/212.5 MB 2.0 MB/s eta 0:01:36\n",
      "     --- ----------------------------------- 21.2/212.5 MB 2.0 MB/s eta 0:01:36\n",
      "     --- ----------------------------------- 21.5/212.5 MB 2.0 MB/s eta 0:01:36\n",
      "     ---- ---------------------------------- 22.0/212.5 MB 2.0 MB/s eta 0:01:37\n",
      "     ---- ---------------------------------- 22.3/212.5 MB 2.0 MB/s eta 0:01:37\n",
      "     ---- ---------------------------------- 22.5/212.5 MB 2.0 MB/s eta 0:01:38\n",
      "     ---- ---------------------------------- 22.5/212.5 MB 2.0 MB/s eta 0:01:38\n",
      "     ---- ---------------------------------- 22.5/212.5 MB 2.0 MB/s eta 0:01:38\n",
      "     ---- ---------------------------------- 23.1/212.5 MB 1.9 MB/s eta 0:01:40\n",
      "     ---- ---------------------------------- 23.6/212.5 MB 1.9 MB/s eta 0:01:40\n",
      "     ---- ---------------------------------- 23.6/212.5 MB 1.9 MB/s eta 0:01:40\n",
      "     ---- ---------------------------------- 23.6/212.5 MB 1.9 MB/s eta 0:01:40\n",
      "     ---- ---------------------------------- 23.9/212.5 MB 1.8 MB/s eta 0:01:43\n",
      "     ---- ---------------------------------- 24.6/212.5 MB 1.9 MB/s eta 0:01:41\n",
      "     ---- ---------------------------------- 24.9/212.5 MB 1.9 MB/s eta 0:01:41\n",
      "     ---- ---------------------------------- 24.9/212.5 MB 1.9 MB/s eta 0:01:41\n",
      "     ---- ---------------------------------- 24.9/212.5 MB 1.9 MB/s eta 0:01:41\n",
      "     ---- ---------------------------------- 24.9/212.5 MB 1.9 MB/s eta 0:01:41\n",
      "     ---- ---------------------------------- 26.0/212.5 MB 1.8 MB/s eta 0:01:43\n",
      "     ---- ---------------------------------- 26.7/212.5 MB 1.9 MB/s eta 0:01:41\n",
      "     ---- ---------------------------------- 27.0/212.5 MB 1.8 MB/s eta 0:01:42\n",
      "     ----- --------------------------------- 27.3/212.5 MB 1.8 MB/s eta 0:01:41\n",
      "     ----- --------------------------------- 27.8/212.5 MB 1.8 MB/s eta 0:01:41\n",
      "     ----- --------------------------------- 28.0/212.5 MB 1.8 MB/s eta 0:01:41\n",
      "     ----- --------------------------------- 28.3/212.5 MB 1.8 MB/s eta 0:01:41\n",
      "     ----- --------------------------------- 28.3/212.5 MB 1.8 MB/s eta 0:01:41\n",
      "     ----- --------------------------------- 28.6/212.5 MB 1.8 MB/s eta 0:01:43\n",
      "     ----- --------------------------------- 29.6/212.5 MB 1.8 MB/s eta 0:01:41\n",
      "     ----- --------------------------------- 29.9/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ----- --------------------------------- 30.1/212.5 MB 1.8 MB/s eta 0:01:41\n",
      "     ----- --------------------------------- 30.4/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ----- --------------------------------- 30.9/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ----- --------------------------------- 31.2/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ----- --------------------------------- 31.5/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ----- --------------------------------- 31.5/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ----- --------------------------------- 31.7/212.5 MB 1.8 MB/s eta 0:01:42\n",
      "     ----- --------------------------------- 32.0/212.5 MB 1.8 MB/s eta 0:01:42\n",
      "     ------ -------------------------------- 33.0/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ------ -------------------------------- 33.3/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ------ -------------------------------- 33.3/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ------ -------------------------------- 33.6/212.5 MB 1.8 MB/s eta 0:01:41\n",
      "     ------ -------------------------------- 34.3/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ------ -------------------------------- 34.6/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ------ -------------------------------- 34.9/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------ -------------------------------- 35.4/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ------ -------------------------------- 35.7/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------ -------------------------------- 36.2/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------ -------------------------------- 36.4/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------ -------------------------------- 36.7/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------ -------------------------------- 36.7/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------ -------------------------------- 37.2/212.5 MB 1.8 MB/s eta 0:01:40\n",
      "     ------ -------------------------------- 37.5/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------ -------------------------------- 38.0/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 38.3/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 38.5/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 38.8/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 39.1/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 39.6/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 39.8/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 40.1/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 40.4/212.5 MB 1.8 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 40.9/212.5 MB 1.7 MB/s eta 0:01:39\n",
      "     ------- ------------------------------- 41.2/212.5 MB 1.7 MB/s eta 0:01:38\n",
      "     ------- ------------------------------- 41.4/212.5 MB 1.7 MB/s eta 0:01:38\n",
      "     ------- ------------------------------- 41.9/212.5 MB 1.7 MB/s eta 0:01:38\n",
      "     ------- ------------------------------- 42.2/212.5 MB 1.7 MB/s eta 0:01:38\n",
      "     ------- ------------------------------- 42.5/212.5 MB 1.7 MB/s eta 0:01:38\n",
      "     ------- ------------------------------- 42.7/212.5 MB 1.7 MB/s eta 0:01:38\n",
      "     ------- ------------------------------- 43.3/212.5 MB 1.7 MB/s eta 0:01:38\n",
      "     ------- ------------------------------- 43.5/212.5 MB 1.7 MB/s eta 0:01:37\n",
      "     -------- ------------------------------ 43.8/212.5 MB 1.7 MB/s eta 0:01:37\n",
      "     -------- ------------------------------ 44.3/212.5 MB 1.7 MB/s eta 0:01:37\n",
      "     -------- ------------------------------ 44.6/212.5 MB 1.7 MB/s eta 0:01:37\n",
      "     -------- ------------------------------ 44.8/212.5 MB 1.7 MB/s eta 0:01:37\n",
      "     -------- ------------------------------ 45.4/212.5 MB 1.7 MB/s eta 0:01:37\n",
      "     -------- ------------------------------ 45.6/212.5 MB 1.7 MB/s eta 0:01:37\n",
      "     -------- ------------------------------ 45.9/212.5 MB 1.7 MB/s eta 0:01:36\n",
      "     -------- ------------------------------ 46.4/212.5 MB 1.7 MB/s eta 0:01:36\n",
      "     -------- ------------------------------ 46.7/212.5 MB 1.7 MB/s eta 0:01:36\n",
      "     -------- ------------------------------ 46.9/212.5 MB 1.7 MB/s eta 0:01:36\n",
      "     -------- ------------------------------ 47.4/212.5 MB 1.7 MB/s eta 0:01:36\n",
      "     -------- ------------------------------ 47.7/212.5 MB 1.7 MB/s eta 0:01:36\n",
      "     -------- ------------------------------ 48.2/212.5 MB 1.7 MB/s eta 0:01:35\n",
      "     -------- ------------------------------ 48.5/212.5 MB 1.7 MB/s eta 0:01:35\n",
      "     -------- ------------------------------ 48.8/212.5 MB 1.7 MB/s eta 0:01:35\n",
      "     --------- ----------------------------- 49.3/212.5 MB 1.7 MB/s eta 0:01:35\n",
      "     --------- ----------------------------- 49.5/212.5 MB 1.7 MB/s eta 0:01:34\n",
      "     --------- ----------------------------- 50.1/212.5 MB 1.7 MB/s eta 0:01:34\n",
      "     --------- ----------------------------- 50.3/212.5 MB 1.7 MB/s eta 0:01:34\n",
      "     --------- ----------------------------- 50.9/212.5 MB 1.7 MB/s eta 0:01:34\n",
      "     --------- ----------------------------- 51.1/212.5 MB 1.7 MB/s eta 0:01:33\n",
      "     --------- ----------------------------- 51.6/212.5 MB 1.7 MB/s eta 0:01:33\n",
      "     --------- ----------------------------- 51.9/212.5 MB 1.7 MB/s eta 0:01:33\n",
      "     --------- ----------------------------- 52.4/212.5 MB 1.7 MB/s eta 0:01:32\n",
      "     --------- ----------------------------- 52.7/212.5 MB 1.7 MB/s eta 0:01:32\n",
      "     --------- ----------------------------- 53.2/212.5 MB 1.7 MB/s eta 0:01:32\n",
      "     --------- ----------------------------- 53.5/212.5 MB 1.7 MB/s eta 0:01:32\n",
      "     --------- ----------------------------- 54.0/212.5 MB 1.7 MB/s eta 0:01:32\n",
      "     --------- ----------------------------- 54.0/212.5 MB 1.7 MB/s eta 0:01:32\n",
      "     --------- ----------------------------- 54.3/212.5 MB 1.7 MB/s eta 0:01:34\n",
      "     ---------- ---------------------------- 54.8/212.5 MB 1.7 MB/s eta 0:01:33\n",
      "     ---------- ---------------------------- 55.6/212.5 MB 1.7 MB/s eta 0:01:32\n",
      "     ---------- ---------------------------- 56.1/212.5 MB 1.7 MB/s eta 0:01:31\n",
      "     ---------- ---------------------------- 56.6/212.5 MB 1.7 MB/s eta 0:01:31\n",
      "     ---------- ---------------------------- 57.1/212.5 MB 1.7 MB/s eta 0:01:31\n",
      "     ---------- ---------------------------- 57.7/212.5 MB 1.8 MB/s eta 0:01:29\n",
      "     ---------- ---------------------------- 58.2/212.5 MB 1.8 MB/s eta 0:01:28\n",
      "     ---------- ---------------------------- 58.7/212.5 MB 1.8 MB/s eta 0:01:28\n",
      "     ---------- ---------------------------- 59.2/212.5 MB 1.8 MB/s eta 0:01:27\n",
      "     ---------- ---------------------------- 59.8/212.5 MB 1.8 MB/s eta 0:01:26\n",
      "     ----------- --------------------------- 60.3/212.5 MB 1.8 MB/s eta 0:01:25\n",
      "     ----------- --------------------------- 61.1/212.5 MB 1.8 MB/s eta 0:01:27\n",
      "     ----------- --------------------------- 61.3/212.5 MB 1.7 MB/s eta 0:01:27\n",
      "     ----------- --------------------------- 61.9/212.5 MB 1.7 MB/s eta 0:01:27\n",
      "     ----------- --------------------------- 62.1/212.5 MB 1.7 MB/s eta 0:01:27\n",
      "     ----------- --------------------------- 62.7/212.5 MB 1.7 MB/s eta 0:01:26\n",
      "     ----------- --------------------------- 63.2/212.5 MB 1.8 MB/s eta 0:01:24\n",
      "     ----------- --------------------------- 63.7/212.5 MB 1.8 MB/s eta 0:01:24\n",
      "     ----------- --------------------------- 64.2/212.5 MB 1.8 MB/s eta 0:01:24\n",
      "     ----------- --------------------------- 64.7/212.5 MB 1.8 MB/s eta 0:01:24\n",
      "     ----------- --------------------------- 65.0/212.5 MB 1.8 MB/s eta 0:01:23\n",
      "     ------------ -------------------------- 65.5/212.5 MB 1.8 MB/s eta 0:01:23\n",
      "     ------------ -------------------------- 66.1/212.5 MB 1.8 MB/s eta 0:01:23\n",
      "     ------------ -------------------------- 66.6/212.5 MB 1.7 MB/s eta 0:01:24\n",
      "     ------------ -------------------------- 66.8/212.5 MB 1.8 MB/s eta 0:01:23\n",
      "     ------------ -------------------------- 67.4/212.5 MB 1.8 MB/s eta 0:01:22\n",
      "     ------------ -------------------------- 67.9/212.5 MB 1.8 MB/s eta 0:01:22\n",
      "     ------------ -------------------------- 68.4/212.5 MB 1.8 MB/s eta 0:01:21\n",
      "     ------------ -------------------------- 68.9/212.5 MB 1.8 MB/s eta 0:01:21\n",
      "     ------------ -------------------------- 69.2/212.5 MB 1.8 MB/s eta 0:01:21\n",
      "     ------------ -------------------------- 69.7/212.5 MB 1.8 MB/s eta 0:01:20\n",
      "     ------------ -------------------------- 70.3/212.5 MB 1.8 MB/s eta 0:01:20\n",
      "     ------------ -------------------------- 70.8/212.5 MB 1.8 MB/s eta 0:01:20\n",
      "     ------------- ------------------------- 71.0/212.5 MB 1.8 MB/s eta 0:01:20\n",
      "     ------------- ------------------------- 71.6/212.5 MB 1.8 MB/s eta 0:01:19\n",
      "     ------------- ------------------------- 72.1/212.5 MB 1.8 MB/s eta 0:01:19\n",
      "     ------------- ------------------------- 72.6/212.5 MB 1.8 MB/s eta 0:01:19\n",
      "     ------------- ------------------------- 73.1/212.5 MB 1.8 MB/s eta 0:01:19\n",
      "     ------------- ------------------------- 73.4/212.5 MB 1.8 MB/s eta 0:01:18\n",
      "     ------------- ------------------------- 73.9/212.5 MB 1.8 MB/s eta 0:01:17\n",
      "     ------------- ------------------------- 74.4/212.5 MB 1.8 MB/s eta 0:01:17\n",
      "     ------------- ------------------------- 75.0/212.5 MB 1.8 MB/s eta 0:01:16\n",
      "     ------------- ------------------------- 75.5/212.5 MB 1.8 MB/s eta 0:01:16\n",
      "     ------------- ------------------------- 76.0/212.5 MB 1.8 MB/s eta 0:01:15\n",
      "     -------------- ------------------------ 76.3/212.5 MB 1.8 MB/s eta 0:01:15\n",
      "     -------------- ------------------------ 76.8/212.5 MB 1.8 MB/s eta 0:01:15\n",
      "     -------------- ------------------------ 77.3/212.5 MB 1.8 MB/s eta 0:01:14\n",
      "     -------------- ------------------------ 77.6/212.5 MB 1.8 MB/s eta 0:01:14\n",
      "     -------------- ------------------------ 77.9/212.5 MB 1.9 MB/s eta 0:01:13\n",
      "     -------------- ------------------------ 78.4/212.5 MB 1.9 MB/s eta 0:01:13\n",
      "     -------------- ------------------------ 78.9/212.5 MB 1.9 MB/s eta 0:01:12\n",
      "     -------------- ------------------------ 79.4/212.5 MB 1.9 MB/s eta 0:01:12\n",
      "     -------------- ------------------------ 80.0/212.5 MB 1.9 MB/s eta 0:01:10\n",
      "     -------------- ------------------------ 80.2/212.5 MB 1.9 MB/s eta 0:01:10\n",
      "     -------------- ------------------------ 80.7/212.5 MB 1.9 MB/s eta 0:01:10\n",
      "     -------------- ------------------------ 81.3/212.5 MB 1.9 MB/s eta 0:01:10\n",
      "     --------------- ----------------------- 81.8/212.5 MB 1.9 MB/s eta 0:01:08\n",
      "     --------------- ----------------------- 82.1/212.5 MB 1.9 MB/s eta 0:01:08\n",
      "     --------------- ----------------------- 82.6/212.5 MB 1.9 MB/s eta 0:01:08\n",
      "     --------------- ----------------------- 83.1/212.5 MB 1.9 MB/s eta 0:01:07\n",
      "     --------------- ----------------------- 83.6/212.5 MB 1.9 MB/s eta 0:01:07\n",
      "     --------------- ----------------------- 84.1/212.5 MB 1.9 MB/s eta 0:01:07\n",
      "     --------------- ----------------------- 84.7/212.5 MB 1.9 MB/s eta 0:01:07\n",
      "     --------------- ----------------------- 84.9/212.5 MB 1.9 MB/s eta 0:01:07\n",
      "     --------------- ----------------------- 85.7/212.5 MB 1.9 MB/s eta 0:01:06\n",
      "     --------------- ----------------------- 86.0/212.5 MB 1.9 MB/s eta 0:01:06\n",
      "     --------------- ----------------------- 86.5/212.5 MB 1.9 MB/s eta 0:01:05\n",
      "     --------------- ----------------------- 87.0/212.5 MB 2.0 MB/s eta 0:01:04\n",
      "     ---------------- ---------------------- 87.6/212.5 MB 2.0 MB/s eta 0:01:04\n",
      "     ---------------- ---------------------- 88.1/212.5 MB 2.0 MB/s eta 0:01:04\n",
      "     ---------------- ---------------------- 88.6/212.5 MB 2.0 MB/s eta 0:01:04\n",
      "     ---------------- ---------------------- 88.9/212.5 MB 2.0 MB/s eta 0:01:04\n",
      "     ---------------- ---------------------- 89.4/212.5 MB 2.0 MB/s eta 0:01:03\n",
      "     ---------------- ---------------------- 89.9/212.5 MB 2.0 MB/s eta 0:01:03\n",
      "     ---------------- ---------------------- 90.4/212.5 MB 2.0 MB/s eta 0:01:02\n",
      "     ---------------- ---------------------- 90.7/212.5 MB 2.0 MB/s eta 0:01:01\n",
      "     ---------------- ---------------------- 91.2/212.5 MB 2.0 MB/s eta 0:01:01\n",
      "     ---------------- ---------------------- 92.0/212.5 MB 2.0 MB/s eta 0:01:00\n",
      "     ----------------- --------------------- 92.8/212.5 MB 2.0 MB/s eta 0:01:00\n",
      "     ----------------- --------------------- 93.1/212.5 MB 2.0 MB/s eta 0:01:00\n",
      "     ----------------- --------------------- 94.4/212.5 MB 2.1 MB/s eta 0:00:58\n",
      "     ----------------- --------------------- 94.6/212.5 MB 2.1 MB/s eta 0:00:58\n",
      "     ----------------- --------------------- 94.9/212.5 MB 2.0 MB/s eta 0:00:58\n",
      "     ----------------- --------------------- 95.4/212.5 MB 2.1 MB/s eta 0:00:57\n",
      "     ----------------- --------------------- 96.5/212.5 MB 2.1 MB/s eta 0:00:57\n",
      "     ----------------- --------------------- 97.3/212.5 MB 2.1 MB/s eta 0:00:56\n",
      "     ----------------- --------------------- 97.8/212.5 MB 2.1 MB/s eta 0:00:55\n",
      "     ------------------ -------------------- 98.3/212.5 MB 2.1 MB/s eta 0:00:55\n",
      "     ------------------ -------------------- 99.1/212.5 MB 2.1 MB/s eta 0:00:54\n",
      "     ------------------ -------------------- 99.6/212.5 MB 2.1 MB/s eta 0:00:54\n",
      "     ----------------- -------------------- 100.4/212.5 MB 2.1 MB/s eta 0:00:53\n",
      "     ------------------ ------------------- 100.7/212.5 MB 2.1 MB/s eta 0:00:53\n",
      "     ------------------ ------------------- 101.4/212.5 MB 2.1 MB/s eta 0:00:52\n",
      "     ------------------ ------------------- 102.2/212.5 MB 2.2 MB/s eta 0:00:52\n",
      "     ------------------ ------------------- 102.5/212.5 MB 2.2 MB/s eta 0:00:51\n",
      "     ------------------ ------------------- 103.5/212.5 MB 2.2 MB/s eta 0:00:51\n",
      "     ------------------ ------------------- 104.1/212.5 MB 2.2 MB/s eta 0:00:50\n",
      "     ------------------ ------------------- 104.9/212.5 MB 2.2 MB/s eta 0:00:49\n",
      "     ------------------ ------------------- 104.9/212.5 MB 2.2 MB/s eta 0:00:49\n",
      "     ------------------ ------------------- 104.9/212.5 MB 2.2 MB/s eta 0:00:49\n",
      "     ------------------ ------------------- 104.9/212.5 MB 2.2 MB/s eta 0:00:49\n",
      "     ------------------ ------------------- 105.1/212.5 MB 2.2 MB/s eta 0:00:50\n",
      "     ------------------ ------------------- 105.9/212.5 MB 2.2 MB/s eta 0:00:49\n",
      "     ------------------- ------------------ 106.4/212.5 MB 2.2 MB/s eta 0:00:49\n",
      "     ------------------- ------------------ 107.0/212.5 MB 2.2 MB/s eta 0:00:49\n",
      "     ------------------- ------------------ 107.5/212.5 MB 2.2 MB/s eta 0:00:48\n",
      "     ------------------- ------------------ 108.0/212.5 MB 2.2 MB/s eta 0:00:48\n",
      "     ------------------- ------------------ 108.5/212.5 MB 2.2 MB/s eta 0:00:47\n",
      "     ------------------- ------------------ 109.3/212.5 MB 2.2 MB/s eta 0:00:47\n",
      "     ------------------- ------------------ 109.8/212.5 MB 2.2 MB/s eta 0:00:46\n",
      "     ------------------- ------------------ 110.4/212.5 MB 2.2 MB/s eta 0:00:46\n",
      "     ------------------- ------------------ 110.9/212.5 MB 2.2 MB/s eta 0:00:46\n",
      "     ------------------- ------------------ 111.4/212.5 MB 2.3 MB/s eta 0:00:45\n",
      "     ------------------- ------------------ 111.7/212.5 MB 2.2 MB/s eta 0:00:45\n",
      "     -------------------- ----------------- 111.9/212.5 MB 2.3 MB/s eta 0:00:45\n",
      "     -------------------- ----------------- 112.7/212.5 MB 2.3 MB/s eta 0:00:45\n",
      "     -------------------- ----------------- 113.2/212.5 MB 2.3 MB/s eta 0:00:44\n",
      "     -------------------- ----------------- 114.0/212.5 MB 2.3 MB/s eta 0:00:44\n",
      "     -------------------- ----------------- 114.3/212.5 MB 2.3 MB/s eta 0:00:43\n",
      "     -------------------- ----------------- 115.1/212.5 MB 2.3 MB/s eta 0:00:43\n",
      "     -------------------- ----------------- 115.6/212.5 MB 2.3 MB/s eta 0:00:43\n",
      "     -------------------- ----------------- 116.1/212.5 MB 2.3 MB/s eta 0:00:42\n",
      "     -------------------- ----------------- 116.9/212.5 MB 2.3 MB/s eta 0:00:42\n",
      "     -------------------- ----------------- 117.2/212.5 MB 2.3 MB/s eta 0:00:42\n",
      "     --------------------- ---------------- 117.4/212.5 MB 2.3 MB/s eta 0:00:41\n",
      "     --------------------- ---------------- 118.5/212.5 MB 2.3 MB/s eta 0:00:41\n",
      "     --------------------- ---------------- 119.0/212.5 MB 2.3 MB/s eta 0:00:40\n",
      "     --------------------- ---------------- 119.3/212.5 MB 2.3 MB/s eta 0:00:40\n",
      "     --------------------- ---------------- 120.1/212.5 MB 2.4 MB/s eta 0:00:40\n",
      "     --------------------- ---------------- 120.6/212.5 MB 2.4 MB/s eta 0:00:39\n",
      "     --------------------- ---------------- 121.4/212.5 MB 2.4 MB/s eta 0:00:39\n",
      "     --------------------- ---------------- 121.6/212.5 MB 2.4 MB/s eta 0:00:39\n",
      "     --------------------- ---------------- 122.4/212.5 MB 2.4 MB/s eta 0:00:38\n",
      "     --------------------- ---------------- 122.7/212.5 MB 2.4 MB/s eta 0:00:38\n",
      "     ---------------------- --------------- 123.2/212.5 MB 2.4 MB/s eta 0:00:38\n",
      "     ---------------------- --------------- 124.0/212.5 MB 2.4 MB/s eta 0:00:38\n",
      "     ---------------------- --------------- 124.8/212.5 MB 2.4 MB/s eta 0:00:37\n",
      "     ---------------------- --------------- 125.0/212.5 MB 2.4 MB/s eta 0:00:37\n",
      "     ---------------------- --------------- 126.1/212.5 MB 2.4 MB/s eta 0:00:36\n",
      "     ---------------------- --------------- 126.4/212.5 MB 2.4 MB/s eta 0:00:36\n",
      "     ---------------------- --------------- 126.6/212.5 MB 2.4 MB/s eta 0:00:36\n",
      "     ---------------------- --------------- 127.4/212.5 MB 2.4 MB/s eta 0:00:35\n",
      "     ---------------------- --------------- 128.2/212.5 MB 2.5 MB/s eta 0:00:35\n",
      "     ----------------------- -------------- 129.0/212.5 MB 2.4 MB/s eta 0:00:35\n",
      "     ----------------------- -------------- 129.2/212.5 MB 2.4 MB/s eta 0:00:35\n",
      "     ----------------------- -------------- 130.8/212.5 MB 2.5 MB/s eta 0:00:34\n",
      "     ----------------------- -------------- 131.6/212.5 MB 2.5 MB/s eta 0:00:33\n",
      "     ----------------------- -------------- 132.9/212.5 MB 2.5 MB/s eta 0:00:32\n",
      "     ----------------------- -------------- 133.4/212.5 MB 2.5 MB/s eta 0:00:32\n",
      "     ----------------------- -------------- 134.0/212.5 MB 2.5 MB/s eta 0:00:32\n",
      "     ------------------------ ------------- 135.0/212.5 MB 2.5 MB/s eta 0:00:31\n",
      "     ------------------------ ------------- 135.5/212.5 MB 2.5 MB/s eta 0:00:31\n",
      "     ------------------------ ------------- 136.1/212.5 MB 2.5 MB/s eta 0:00:31\n",
      "     ------------------------ ------------- 136.8/212.5 MB 2.5 MB/s eta 0:00:30\n",
      "     ------------------------ ------------- 137.9/212.5 MB 2.6 MB/s eta 0:00:30\n",
      "     ------------------------ ------------- 138.9/212.5 MB 2.6 MB/s eta 0:00:29\n",
      "     ------------------------ ------------- 139.7/212.5 MB 2.6 MB/s eta 0:00:29\n",
      "     ------------------------- ------------ 140.2/212.5 MB 2.6 MB/s eta 0:00:28\n",
      "     ------------------------- ------------ 141.3/212.5 MB 2.6 MB/s eta 0:00:28\n",
      "     ------------------------- ------------ 142.6/212.5 MB 2.6 MB/s eta 0:00:27\n",
      "     ------------------------- ------------ 143.7/212.5 MB 2.6 MB/s eta 0:00:26\n",
      "     ------------------------- ------------ 144.4/212.5 MB 2.7 MB/s eta 0:00:26\n",
      "     -------------------------- ----------- 145.5/212.5 MB 2.7 MB/s eta 0:00:26\n",
      "     -------------------------- ----------- 145.8/212.5 MB 2.7 MB/s eta 0:00:25\n",
      "     -------------------------- ----------- 146.8/212.5 MB 2.7 MB/s eta 0:00:25\n",
      "     -------------------------- ----------- 147.6/212.5 MB 2.7 MB/s eta 0:00:24\n",
      "     -------------------------- ----------- 148.1/212.5 MB 2.7 MB/s eta 0:00:24\n",
      "     -------------------------- ----------- 149.7/212.5 MB 2.7 MB/s eta 0:00:23\n",
      "     -------------------------- ----------- 150.7/212.5 MB 2.8 MB/s eta 0:00:23\n",
      "     --------------------------- ---------- 151.5/212.5 MB 2.8 MB/s eta 0:00:22\n",
      "     --------------------------- ---------- 152.6/212.5 MB 2.8 MB/s eta 0:00:22\n",
      "     --------------------------- ---------- 153.4/212.5 MB 2.8 MB/s eta 0:00:22\n",
      "     --------------------------- ---------- 154.1/212.5 MB 2.8 MB/s eta 0:00:21\n",
      "     --------------------------- ---------- 155.2/212.5 MB 2.8 MB/s eta 0:00:21\n",
      "     --------------------------- ---------- 156.0/212.5 MB 2.8 MB/s eta 0:00:20\n",
      "     ---------------------------- --------- 156.8/212.5 MB 2.9 MB/s eta 0:00:20\n",
      "     ---------------------------- --------- 157.8/212.5 MB 2.9 MB/s eta 0:00:20\n",
      "     ---------------------------- --------- 158.6/212.5 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------------------------- --------- 159.6/212.5 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------------------------- --------- 160.4/212.5 MB 2.9 MB/s eta 0:00:18\n",
      "     ---------------------------- --------- 161.2/212.5 MB 2.9 MB/s eta 0:00:18\n",
      "     ----------------------------- -------- 162.3/212.5 MB 2.9 MB/s eta 0:00:18\n",
      "     ----------------------------- -------- 163.1/212.5 MB 3.0 MB/s eta 0:00:17\n",
      "     ----------------------------- -------- 163.6/212.5 MB 3.0 MB/s eta 0:00:17\n",
      "     ----------------------------- -------- 164.4/212.5 MB 3.0 MB/s eta 0:00:17\n",
      "     ----------------------------- -------- 165.2/212.5 MB 3.0 MB/s eta 0:00:16\n",
      "     ----------------------------- -------- 166.2/212.5 MB 3.0 MB/s eta 0:00:16\n",
      "     ----------------------------- -------- 167.2/212.5 MB 3.0 MB/s eta 0:00:16\n",
      "     ------------------------------ ------- 168.3/212.5 MB 3.0 MB/s eta 0:00:15\n",
      "     ------------------------------ ------- 169.1/212.5 MB 3.1 MB/s eta 0:00:15\n",
      "     ------------------------------ ------- 170.1/212.5 MB 3.1 MB/s eta 0:00:14\n",
      "     ------------------------------ ------- 170.9/212.5 MB 3.1 MB/s eta 0:00:14\n",
      "     ------------------------------ ------- 171.7/212.5 MB 3.1 MB/s eta 0:00:14\n",
      "     ------------------------------ ------- 172.8/212.5 MB 3.1 MB/s eta 0:00:13\n",
      "     ------------------------------- ------ 173.5/212.5 MB 3.1 MB/s eta 0:00:13\n",
      "     ------------------------------- ------ 174.6/212.5 MB 3.1 MB/s eta 0:00:13\n",
      "     ------------------------------- ------ 175.4/212.5 MB 3.2 MB/s eta 0:00:12\n",
      "     ------------------------------- ------ 176.2/212.5 MB 3.2 MB/s eta 0:00:12\n",
      "     ------------------------------- ------ 177.2/212.5 MB 3.2 MB/s eta 0:00:12\n",
      "     ------------------------------- ------ 178.0/212.5 MB 3.2 MB/s eta 0:00:11\n",
      "     -------------------------------- ----- 179.0/212.5 MB 3.2 MB/s eta 0:00:11\n",
      "     -------------------------------- ----- 179.8/212.5 MB 3.2 MB/s eta 0:00:11\n",
      "     -------------------------------- ----- 180.6/212.5 MB 3.2 MB/s eta 0:00:10\n",
      "     -------------------------------- ----- 181.7/212.5 MB 3.3 MB/s eta 0:00:10\n",
      "     -------------------------------- ----- 182.5/212.5 MB 3.3 MB/s eta 0:00:10\n",
      "     -------------------------------- ----- 183.2/212.5 MB 3.3 MB/s eta 0:00:09\n",
      "     -------------------------------- ----- 184.3/212.5 MB 3.3 MB/s eta 0:00:09\n",
      "     --------------------------------- ---- 185.1/212.5 MB 3.3 MB/s eta 0:00:09\n",
      "     --------------------------------- ---- 186.1/212.5 MB 3.3 MB/s eta 0:00:08\n",
      "     --------------------------------- ---- 186.9/212.5 MB 3.3 MB/s eta 0:00:08\n",
      "     --------------------------------- ---- 188.0/212.5 MB 3.4 MB/s eta 0:00:08\n",
      "     --------------------------------- ---- 188.7/212.5 MB 3.4 MB/s eta 0:00:08\n",
      "     --------------------------------- ---- 189.5/212.5 MB 3.4 MB/s eta 0:00:07\n",
      "     ---------------------------------- --- 190.6/212.5 MB 3.4 MB/s eta 0:00:07\n",
      "     ---------------------------------- --- 191.4/212.5 MB 3.4 MB/s eta 0:00:07\n",
      "     ---------------------------------- --- 192.2/212.5 MB 3.4 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 193.2/212.5 MB 3.4 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 194.0/212.5 MB 3.4 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 195.0/212.5 MB 3.5 MB/s eta 0:00:06\n",
      "     ----------------------------------- -- 195.8/212.5 MB 3.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- -- 196.6/212.5 MB 3.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- -- 197.7/212.5 MB 3.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- -- 198.4/212.5 MB 3.5 MB/s eta 0:00:05\n",
      "     ----------------------------------- -- 199.2/212.5 MB 3.5 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 200.3/212.5 MB 3.5 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 201.1/212.5 MB 3.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ - 201.9/212.5 MB 3.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ - 202.9/212.5 MB 3.5 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 203.7/212.5 MB 3.5 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 204.7/212.5 MB 3.6 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 205.5/212.5 MB 3.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 206.3/212.5 MB 3.6 MB/s eta 0:00:02\n",
      "     -------------------------------------  207.4/212.5 MB 3.6 MB/s eta 0:00:02\n",
      "     -------------------------------------  208.1/212.5 MB 3.6 MB/s eta 0:00:02\n",
      "     -------------------------------------  209.2/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  209.7/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  209.7/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  211.0/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 212.5/212.5 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.47.1)\n",
      "Collecting transformers\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a9/b6/5257d04ae327b44db31f15cce39e6020cc986333c715660b1315a9724d82/transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Requirement already satisfied: trl in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (0.17.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from trl) (3.5.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from trl) (13.7.1)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate>=0.34.0->trl) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from datasets>=3.0.0->trl) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->trl) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->trl) (2.15.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl) (1.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Installing collected packages: sympy, torch, transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0 transformers-4.51.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: datasets in /home/vipuser/anaconda3/lib/python3.9/site-packages (3.6.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: pandas in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: packaging in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: filelock in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (3.3.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: xxhash in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: trl in /home/vipuser/anaconda3/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (3.6.0)\n",
      "Requirement already satisfied: rich in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (4.51.3)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (21.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (1.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (0.31.1)\n",
      "Requirement already satisfied: pyyaml in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (6.0)\n",
      "Requirement already satisfied: psutil in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (5.8.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (2.7.0)\n",
      "Requirement already satisfied: xxhash in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: filelock in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (3.3.1)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (20.0.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: pandas in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (1.3.4)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.18)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (21.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->accelerate>=0.34.0->trl) (3.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2021.10.8)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.85)\n",
      "Requirement already satisfied: jinja2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.4.1)\n",
      "Requirement already satisfied: networkx in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.6.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.26.2)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.3.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.77)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.6.80)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate>=0.34.0->trl) (58.0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.34.0->trl) (1.2.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers>=4.46.0->trl) (2021.8.3)\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in /home/vipuser/anaconda3/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in /home/vipuser/anaconda3/lib/python3.9/site-packages (4.51.3)\n",
      "Requirement already satisfied: trl in /home/vipuser/anaconda3/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: fsspec in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: filelock in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: networkx in /home/vipuser/anaconda3/lib/python3.9/site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from triton==3.3.0->torch) (58.0.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (3.6.0)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: rich in /home/vipuser/anaconda3/lib/python3.9/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: psutil in /home/vipuser/anaconda3/lib/python3.9/site-packages (from accelerate>=0.34.0->trl) (5.8.0)\n",
      "Requirement already satisfied: pandas in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (1.3.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /home/vipuser/anaconda3/lib/python3.9/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from fsspec->torch) (3.11.18)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.20.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.4.3)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (21.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from pandas->datasets>=3.0.0->trl) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple huggingface_hub\n",
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple datasets\n",
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple trl\n",
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade torch transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b4dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/vipuser/anaconda3/lib/python3.9/site-packages (0.31.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (1.1.0)\n",
      "Requirement already satisfied: filelock in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (3.3.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (21.0)\n",
      "Requirement already satisfied: requests in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipuser/anaconda3/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61c5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "748e1841-74f5-46ca-87a4-4cb81ec6ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu118\n",
      "import done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "print(torch.__version__)\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86332daa-8fa7-43c7-8aaf-b8ba4eb7dae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face API 令牌已设置\n"
     ]
    }
   ],
   "source": [
    "# log in\n",
    "\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 替换为你的Hugging Face令牌\n",
    "hf_token = \"\"\n",
    "\n",
    "# 登录Hugging Face\n",
    "login(token=hf_token)\n",
    "\n",
    "# 验证令牌是否设置正确\n",
    "api = HfApi()\n",
    "token = HfFolder.get_token()\n",
    "if token:\n",
    "    print(\"Hugging Face API 令牌已设置\")\n",
    "else:\n",
    "    print(\"Hugging Face API 令牌未设置，请检查环境变量\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce73c82-4c37-44bb-a6c7-5fd63bfbd427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 配置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00393442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总显存: 11.99 GB\n",
      "已分配显存: 0.00 GB\n",
      "剩余显存: 11.99 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 检查是否有可用的 CUDA 设备\n",
    "if torch.cuda.is_available():\n",
    "    # 获取当前设备\n",
    "    device = torch.cuda.current_device()\n",
    "    # 获取总显存\n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "    # 获取已分配的显存\n",
    "    allocated_memory = torch.cuda.memory_allocated(device)\n",
    "    # 计算剩余显存\n",
    "    free_memory = total_memory - allocated_memory\n",
    "    \n",
    "    print(f\"总显存: {total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"已分配显存: {allocated_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"剩余显存: {free_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"没有可用的 CUDA 设备。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10516e5a-9180-455d-a6ba-c6c89b9b4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式转换函数\n",
    "def format_instruction_example(example):\n",
    "    question = example[\"Question\"]          # 对应原instruction字段\n",
    "    complex_cot = example[\"Complex_CoT\"]    # 对应原input字段（复杂思考过程）\n",
    "    response = example[\"Response\"]          # 对应原output字段\n",
    "    \n",
    "    # 根据Complex_CoT是否存在构建不同模板\n",
    "    if complex_cot and complex_cot.strip() != \"\":\n",
    "        text = f\"### Question:\\n{question}\\n\\n### Complex_CoT:\\n{complex_cot}\\n\\n### Response:\\n{response}\"\n",
    "    else:\n",
    "        text = f\"### Question:\\n{question}\\n\\n### Response:\\n{response}\"\n",
    "    \n",
    "    # 编码文本（保持原截断和最大长度逻辑）\n",
    "    encoded = tokenizer(text, truncation=True, max_length=512)\n",
    "    \n",
    "    # 显式添加原始文本字段（用于调试或验证）\n",
    "    encoded[\"text\"] = text\n",
    "    \n",
    "    # 标签与输入token_ids一致（适用于因果语言模型训练）\n",
    "    encoded[\"labels\"] = encoded[\"input_ids\"].copy()\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac1f6011-c6ba-4aa2-ab18-6067e66667cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model and dataset load done\n"
     ]
    }
   ],
   "source": [
    "# # 加载模型和分词器\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "# model = model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-1.4b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-1.4b\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", name=\"en\", split=\"train\")\n",
    "\n",
    "train_dataset = dataset.select(range(10))\n",
    "\n",
    "# 重新应用格式转换\n",
    "formatted_dataset = train_dataset.map(format_instruction_example)\n",
    "\n",
    "print('model and dataset load done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c059723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已成功加载到 GPU 上。\n"
     ]
    }
   ],
   "source": [
    "# 检查模型参数所在的设备\n",
    "for param in model.parameters():\n",
    "    if param.device.type == 'cuda':\n",
    "        print(\"模型已成功加载到 GPU 上。\")\n",
    "        break\n",
    "else:\n",
    "    print(\"模型未加载到 GPU 上，仍在 CPU 上。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a9d170f-5d81-4c26-9801-fe58112f204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 1 生成的回答:\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Question:\n",
      "\n",
      "### Q...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 2 生成的回答:\n",
      "The patient is stable. She's got a 5-cm stab wound to the left upper chest. She's got a pneumothorax, and she's got a low blood pressure. She's got a heart rate of 110, and her blood pressure is 90.\n",
      "\n",
      "...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 3 生成的回答:\n",
      "### Question:\n",
      "A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 4 生成的回答:\n",
      "Okay, so we have a 45-year-old man with a history of alcohol use, who has been abstinent for the past 10 years. He suddenly starts showing some pretty specific symptoms: dysarthria, shuffling gait, an...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 5 生成的回答:\n",
      "I think that's a great point. I think that's a great point. I think that's a great point. I think that's a great point. I think that's a great point. I think that's a great point. I think that's a gre...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 6 生成的回答:\n",
      "I'm not sure what you mean by \"pustular psoriasis.\" I've seen this before, but I don't recall it being generalized. I think it's more likely to be localized to the skin, like a rash. \n",
      "\n",
      "Okay, so pustul...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 7 生成的回答:\n",
      "I think the most likely diagnosis is SCFE.\n",
      "\n",
      "The child is 70 kg, and the symptoms are consistent with SCFE.\n",
      "\n",
      "The child is a toddler, and the symptoms are consistent with SCFE.\n",
      "\n",
      "The child is a 2-year-ol...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 8 生成的回答:\n",
      "### Question:\n",
      "What is the maximum amount of a drug that can be given to a patient?\n",
      "\n",
      "### Complex_CoT:\n",
      "The maximum amount of a drug that can be given to a patient is the amount that will give the maximu...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本 9 生成的回答:\n",
      "I’m glad you brought this up because it’s a very interesting case. I’m not sure if you’ve ever heard of Klinefelter syndrome, but it’s a condition that affects males with an extra X chromosome.\n",
      "\n",
      "Kline...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "样本 10 生成的回答:\n",
      "### Question:\n",
      "In a case where a child with pneumonia is diagnosed, and their chest X-ray indicates a pattern consistent with a common bacterial infection, what is the most likely causative organism ba...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 对未训练的模型进行测试：\n",
    "\n",
    "# 生成测试函数\n",
    "def generate_text(question, max_length=200):\n",
    "    \"\"\"使用模型生成回答，限制最大长度为200 tokens\"\"\"\n",
    "    # 编码输入\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 生成文本（使用贪婪解码以确保确定性）\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=min(len(inputs.input_ids[0]) + max_length, 2048),  # 总长度限制\n",
    "            temperature=0.0,      # 确定性解码\n",
    "            num_beams=1,          # 禁用束搜索\n",
    "            do_sample=False       # 不使用采样\n",
    "        )\n",
    "    \n",
    "    # 解码并提取生成的部分\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text[len(question):].strip()  # 返回生成的部分\n",
    "\n",
    "# 对数据集的前10个样本进行测试\n",
    "for i, example in enumerate(train_dataset):\n",
    "    question = example[\"Question\"]\n",
    "    \n",
    "    # 如果有Complex_CoT，也包含在内\n",
    "    if example[\"Complex_CoT\"] and example[\"Complex_CoT\"].strip() != \"\":\n",
    "        prompt = f\"### Question:\\n{question}\\n\\n### Complex_CoT:\\n{example['Complex_CoT']}\\n\\n### Response:\\n\"\n",
    "    else:\n",
    "        prompt = f\"### Question:\\n{question}\\n\\n### Response:\\n\"\n",
    "    \n",
    "    # 生成回答\n",
    "    generated_response = generate_text(prompt)\n",
    "    \n",
    "    # 只打印生成的回答\n",
    "    print(f\"样本 {i+1} 生成的回答:\")\n",
    "    print(generated_response[:200] + (\"...\" if len(generated_response) > 200 else \"\"))\n",
    "    print(\"\\n\" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c82c9c2-7b7d-4c29-9334-d3baea532324",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncating train dataset: 100%|██████████| 10/10 [00:00<00:00, 1780.79 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m\n\u001b[0;32m      5\u001b[0m     training_args \u001b[38;5;241m=\u001b[39m SFTConfig(\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# 输出目录\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[0;32m     30\u001b[0m         model,\n\u001b[0;32m     31\u001b[0m         train_dataset\u001b[38;5;241m=\u001b[39mformatted_dataset,\n\u001b[0;32m     32\u001b[0m         args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     33\u001b[0m     )\n\u001b[1;32m---> 35\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m训练过程中出现错误: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2246\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2247\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2248\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2249\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2250\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2558\u001b[0m )\n\u001b[0;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2566\u001b[0m ):\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\trainer.py:3736\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3735\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3736\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, num_items_in_batch\u001b[38;5;241m=\u001b[39mnum_items_in_batch)\n\u001b[0;32m   3738\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3741\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3742\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\trl\\trainer\\sft_trainer.py:654\u001b[0m, in \u001b[0;36mSFTTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03mCompute training loss and additionally compute token accuracies\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    653\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 654\u001b[0m (loss, outputs) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcompute_loss(\n\u001b[0;32m    655\u001b[0m     model, inputs, return_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_items_in_batch\u001b[38;5;241m=\u001b[39mnum_items_in_batch\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;66;03m# When using padding-free, the attention_mask is not present in the inputs, instead we have cu_seq_lens_q,\u001b[39;00m\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;66;03m# cu_seq_lens_k, and max_length_k, max_length_q and position_ids.\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\trainer.py:3801\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3799\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3800\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3801\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\accelerate\\utils\\operations.py:814\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\accelerate\\utils\\operations.py:802\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\amp\\autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[1;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[0;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:803\u001b[0m, in \u001b[0;36mGPTNeoXForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, inputs_embeds, head_mask, past_key_values, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(GPT_NEOX_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    758\u001b[0m \u001b[38;5;129m@replace_return_docstrings\u001b[39m(output_type\u001b[38;5;241m=\u001b[39mCausalLMOutputWithPast, config_class\u001b[38;5;241m=\u001b[39m_CONFIG_FOR_DOC)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[KwargsForCausalLM],\n\u001b[0;32m    774\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, CausalLMOutputWithPast]:\n\u001b[0;32m    775\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;124;03m    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;124;03m        Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;124;03m    >>> prediction_logits = outputs.logits\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m--> 803\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpt_neox(\n\u001b[0;32m    804\u001b[0m         input_ids,\n\u001b[0;32m    805\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    806\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    807\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    808\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    809\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    810\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    811\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    812\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    813\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    815\u001b[0m     )\n\u001b[0;32m    817\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[0;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:572\u001b[0m, in \u001b[0;36mGPTNeoXModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, past_key_values, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    560\u001b[0m         layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    561\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    569\u001b[0m         position_embeddings,\n\u001b[0;32m    570\u001b[0m     )\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 572\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m layer(\n\u001b[0;32m    573\u001b[0m         hidden_states,\n\u001b[0;32m    574\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m    575\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    576\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i],\n\u001b[0;32m    577\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    578\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    579\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    580\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    581\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs,\n\u001b[0;32m    583\u001b[0m     )\n\u001b[0;32m    584\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:272\u001b[0m, in \u001b[0;36mGPTNeoXLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, head_mask, use_cache, layer_past, output_attentions, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_dropout(attn_output)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_parallel_residual:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# pseudocode:\u001b[39;00m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# x = x + attn(ln1(x)) + mlp(ln2(x))\u001b[39;00m\n\u001b[1;32m--> 272\u001b[0m     mlp_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states))\n\u001b[0;32m    273\u001b[0m     mlp_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_mlp_dropout(mlp_output)\n\u001b[0;32m    274\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m mlp_output \u001b[38;5;241m+\u001b[39m attn_output \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:61\u001b[0m, in \u001b[0;36mGPTNeoXMLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m---> 61\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_h_to_4h(hidden_states)\n\u001b[0;32m     62\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[0;32m     63\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_4h_to_h(hidden_states)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# origin train method\n",
    "\n",
    "try:\n",
    "\n",
    "    # training_args = SFTConfig(output_dir=\"/tmp\")\n",
    "    # 定义 SFT 训练配置\n",
    "    training_args = SFTConfig(\n",
    "    # 输出目录\n",
    "    output_dir=\"/tmp\",\n",
    "    # 训练轮数，减少轮数可以降低训练成本\n",
    "    num_train_epochs=3,\n",
    "    # 每批处理的样本数量，根据 GPU 内存调整\n",
    "    per_device_train_batch_size=8,\n",
    "    # 梯度累积步数，增大该值可以模拟更大的批次大小\n",
    "    gradient_accumulation_steps=4,\n",
    "    # 学习率，合适的学习率有助于模型收敛且降低成本\n",
    "    learning_rate=2e-5,\n",
    "    # 权重衰减，防止过拟合\n",
    "    weight_decay=0.01,\n",
    "    # 预热步数，在训练初期缓慢增加学习率\n",
    "    warmup_steps=500,\n",
    "    # 优化器使用 AdamW\n",
    "    optim=\"adamw_torch\",\n",
    "    # 每多少步保存一次模型\n",
    "    save_steps=10_000,\n",
    "    # 每多少步记录一次日志\n",
    "    logging_steps=100,\n",
    "    # 混合精度训练，使用 fp16 可以减少内存使用和训练时间\n",
    "    fp16=True,\n",
    ")\n",
    "    trainer = SFTTrainer(\n",
    "        model,\n",
    "        train_dataset=formatted_dataset,\n",
    "        args=training_args,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"训练过程中出现错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80317475-46fa-4ca1-8edf-d4b27f8456b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练过程中出现错误: SFTConfig.__init__() got an unexpected keyword argument 'use_eval_mode'\n"
     ]
    }
   ],
   "source": [
    "# 不计一切代价让模型背掉数据集的少量数据：\n",
    "\n",
    "try:\n",
    "    # 定义 SFT 训练配置 - 仅使用 SFTConfig 支持的参数\n",
    "    training_args = SFTConfig(\n",
    "        output_dir=\"/tmp\",\n",
    "        num_train_epochs=50,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.0,  # 关闭正则化以增强记忆\n",
    "        warmup_steps=0,\n",
    "        optim=\"adamw_torch\",\n",
    "\n",
    "        logging_steps=1,\n",
    "        fp16=False,\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=formatted_dataset,\n",
    "        args=training_args,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"训练过程中出现错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32bf5d9d-0ab3-48a3-9f05-a361427e783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型和分词器已保存到 fine_tuned_pythia\n"
     ]
    }
   ],
   "source": [
    "# 保存模型和分词器\n",
    "save_path = r'fine_tuned_pythia_TestVersion'\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"模型和分词器已保存到 {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b04e6-15af-46cf-90b7-1a387de7d9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c45603-27b3-4d15-9965-a90c8a95c352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卸载前的GPU状态:\n",
      "GPU内存使用: 0.00 MB\n",
      "GPU缓存使用: 0.00 MB\n",
      "⚠️ 未找到模型变量\n",
      "⚠️ 未找到分词器变量\n",
      "\n",
      "卸载后的GPU状态:\n",
      "GPU内存使用: 0.00 MB\n",
      "GPU缓存使用: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# 检查当前GPU内存使用情况\n",
    "def print_gpu_memory():\n",
    "    \"\"\"打印当前GPU内存使用情况\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU内存使用: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"GPU缓存使用: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "    else:\n",
    "        print(\"未检测到GPU\")\n",
    "\n",
    "# 打印卸载前的GPU内存状态\n",
    "print(\"卸载前的GPU状态:\")\n",
    "print_gpu_memory()\n",
    "\n",
    "# 卸载模型和分词器\n",
    "try:\n",
    "    # 将模型移回CPU\n",
    "    if 'model' in locals() or 'model' in globals():\n",
    "        model.to('cpu')\n",
    "        del model\n",
    "        print(\"✅ 模型已移至CPU并删除\")\n",
    "    else:\n",
    "        print(\"⚠️ 未找到模型变量\")\n",
    "    \n",
    "    # 删除分词器（如果需要释放更多内存）\n",
    "    if 'tokenizer' in locals() or 'tokenizer' in globals():\n",
    "        del tokenizer\n",
    "        print(\"✅ 分词器已删除\")\n",
    "    else:\n",
    "        print(\"⚠️ 未找到分词器变量\")\n",
    "    \n",
    "    # 删除其他可能占用GPU内存的变量\n",
    "    if 'train_dataset' in locals() or 'train_dataset' in globals():\n",
    "        del train_dataset\n",
    "    if 'val_dataset' in locals() or 'val_dataset' in globals():\n",
    "        del val_dataset\n",
    "    \n",
    "    # 清空PyTorch缓存\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # 强制垃圾回收\n",
    "    gc.collect()\n",
    "    \n",
    "    # 打印卸载后的GPU内存状态\n",
    "    print(\"\\n卸载后的GPU状态:\")\n",
    "    print_gpu_memory()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"卸载过程中出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4f02a-e6ad-4d90-afcc-fc29c056915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载保存的模型和分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained('fine_tuned_pythia_TestVersion')\n",
    "model = AutoModelForCausalLM.from_pretrained('fine_tuned_pythia_TestVersion')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", name=\"en\", split=\"train\")\n",
    "train_dataset = dataset.select(range(10))\n",
    "\n",
    "# 生成测试函数\n",
    "def generate_text(question, max_length=200):\n",
    "    \"\"\"使用模型生成回答，限制最大长度为200 tokens\"\"\"\n",
    "    # 编码输入\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # 生成文本（使用贪婪解码以确保确定性）\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=min(len(inputs.input_ids[0]) + max_length, 2048),  # 总长度限制\n",
    "            temperature=0.0,      # 确定性解码\n",
    "            num_beams=1,          # 禁用束搜索\n",
    "            do_sample=False       # 不使用采样\n",
    "        )\n",
    "\n",
    "    # 解码并提取生成的部分\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text[len(question):].strip()  # 返回生成的部分\n",
    "\n",
    "# 对数据集的前10个样本进行测试\n",
    "for i, example in enumerate(train_dataset):\n",
    "    question = example[\"Question\"]\n",
    "\n",
    "    # 如果有Complex_CoT，也包含在内\n",
    "    if example[\"Complex_CoT\"] and example[\"Complex_CoT\"].strip() != \"\":\n",
    "        prompt = f\"### Question:\\n{question}\\n\\n### Complex_CoT:\\n{example['Complex_CoT']}\\n\\n### Response:\\n\"\n",
    "    else:\n",
    "        prompt = f\"### Question:\\n{question}\\n\\n### Response:\\n\"\n",
    "\n",
    "    # 生成回答\n",
    "    generated_response = generate_text(prompt)\n",
    "\n",
    "    # 只打印生成的回答\n",
    "    print(f\"样本 {i + 1} 生成的回答:\")\n",
    "    print(generated_response[:200] + (\"...\" if len(generated_response) > 200 else \"\"))\n",
    "    print(\"\\n\" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c37d6b-f2f4-484a-a674-76e83debf8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "昨天下午开始，我就感觉嗓子很不舒服，开始咳嗽，之后就感觉喉咙痛，一直咳嗽，吐出白色的痰，咳嗽不起来，然后我就去药店买了药吃了，可是效果不怎么好，今天早上起来，我就感觉喉咙里很堵，还感觉有痰，但是咳不出来，而且感觉嗓子很痛，就是咳嗽不出来，感觉嗓子有痰。今天早上起来，我就感觉喉咙里很堵，还感觉有痰，\n"
     ]
    }
   ],
   "source": [
    "# 加载微调过的模型和分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    save_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "    low_cpu_mem_usage=True\n",
    ").to(device)\n",
    "\n",
    "# 设置流式输出\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "# 准备输入\n",
    "prompt = \"今天天气很好。\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 生成参数\n",
    "generate_config = {\n",
    "    \"max_length\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "# 生成文本\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, streamer=streamer, **generate_config)\n",
    "\n",
    "# 解码输出（如果没有使用streamer）\n",
    "if not streamer:\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4bead75-02e4-443d-a223-2b482e5b6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# 目标文本（需精确匹配）\n",
    "# target_start = \"根据您描述的症状，可能是上呼吸道感染引起的。\"\n",
    "target_start = \"建议进行补钙治疗。\"\n",
    "target_start_ids = tokenizer(target_start, return_tensors=\"pt\").input_ids.squeeze().tolist()\n",
    "\n",
    "# 超参数\n",
    "n_tokens = 15          # 初始提示词长度\n",
    "num_steps = 150         # GCG迭代次数\n",
    "k = 128                # top-k\n",
    "B = 64                 # 候选提示词数量\n",
    "sample_size = n_tokens      # 梯度计算采样token数（仅用于可视化，实际用全梯度）\n",
    "max_generation_length = len(target_start_ids) + 20  # 限制生成长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe3cb02-785c-430a-944c-20eb36f0d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, target_start_ids):\n",
    "    \"\"\"简化的损失函数，计算目标序列整体交叉熵\"\"\"\n",
    "    target_tensor = torch.tensor(target_start_ids, device=logits.device).long()\n",
    "    batch_size, seq_len, vocab_size = logits.shape\n",
    "    target_len = len(target_start_ids)\n",
    "    \n",
    "    # 生成长度不足时赋予大损失\n",
    "    if seq_len < target_len:\n",
    "        return torch.max(logits) * 1e6\n",
    "    \n",
    "    # 计算目标序列对应logits的交叉熵\n",
    "    loss = F.cross_entropy(\n",
    "        logits[:, :target_len, :].reshape(-1, vocab_size), \n",
    "        target_tensor.repeat(batch_size)\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46f128-20d7-4d00-87ec-efd2df7c3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(model, input_ids, position, vocab_size, target_start_ids):\n",
    "    \"\"\"计算单个位置的token梯度（one-hot编码）\"\"\"\n",
    "    embed_layer = model.get_input_embeddings()\n",
    "    actual_vocab_size = embed_layer.weight.shape[0]\n",
    "    \n",
    "    # 创建 one-hot 向量\n",
    "    one_hot = torch.zeros(actual_vocab_size, device=device, dtype=embed_layer.weight.dtype)\n",
    "    one_hot.requires_grad_()\n",
    "    \n",
    "    input_embeds = embed_layer(input_ids.unsqueeze(0)).detach().clone()\n",
    "    input_embeds[0, position] = torch.matmul(one_hot.unsqueeze(0), embed_layer.weight)\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        logits = model(inputs_embeds=input_embeds).logits\n",
    "        \n",
    "        # 确保生成长度足够，否则赋予大损失\n",
    "        if logits.shape[1] < len(target_start_ids):\n",
    "            loss = torch.max(logits) * 1e6\n",
    "        else:\n",
    "            # 判断position是否超出target_start_ids范围\n",
    "            if position < len(target_start_ids):\n",
    "                relevant_logits = logits[0, position]\n",
    "                target = torch.tensor([target_start_ids[position]], device=device)\n",
    "                loss = F.cross_entropy(relevant_logits.unsqueeze(0), target)\n",
    "            else:\n",
    "                # 如果position超出范围，使用一个小的损失值\n",
    "                loss = torch.tensor(1e-6, device=device, requires_grad=True)\n",
    "            \n",
    "        loss.backward()\n",
    "    \n",
    "    # 确保返回有效的梯度，如果梯度为None则返回零梯度\n",
    "    if one_hot.grad is None:\n",
    "        return torch.zeros_like(one_hot, device=device)\n",
    "    \n",
    "    return one_hot.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb80f24-bc5f-4784-9e75-50b429ab46d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def gcg_algorithm():\n",
    "    # 初始化提示词：随机生成n_tokens长度的token序列\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    initial_prompt = torch.randint(0, vocab_size, (n_tokens,), device=device).tolist()\n",
    "    current_prompt = initial_prompt.copy()\n",
    "    step_losses = []\n",
    "    \n",
    "    print(f\"[INIT] Initial Prompt: {tokenizer.decode(current_prompt)}\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # 转换为tensor\n",
    "        input_ids = torch.tensor(current_prompt, device=device).long()\n",
    "        grads = []  # 存储每个位置的梯度（形状[seq_len, vocab_size]）\n",
    "        \n",
    "        # 计算每个位置的梯度\n",
    "        for pos in range(n_tokens):\n",
    "            grad = calculate_gradient(model, input_ids, pos, vocab_size, target_start_ids)\n",
    "            grads.append(grad.cpu().numpy())  # 转换为CPU数组\n",
    "        \n",
    "        # 生成候选提示（梯度引导）\n",
    "        candidates = []\n",
    "        for _ in range(B):\n",
    "            new_prompt = current_prompt.copy()\n",
    "            pos = np.random.randint(n_tokens)  # 随机选择修改位置\n",
    "            \n",
    "            # 选择梯度最小的k个token（梯度越小，损失下降潜力越大）\n",
    "            top_k_indices = np.argsort(grads[pos])[:k]  # 按梯度升序排列\n",
    "            new_token = np.random.choice(top_k_indices)  # 随机选择一个候选token\n",
    "            new_prompt[pos] = new_token\n",
    "            candidates.append(new_prompt)\n",
    "        \n",
    "        # 评估候选损失\n",
    "        best_loss = float('inf')\n",
    "        best_candidate = current_prompt\n",
    "        for cand in candidates:\n",
    "            input_ids_cand = torch.tensor(cand, device=device).long().unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_ids_cand).logits\n",
    "                loss = compute_loss(logits, target_start_ids)\n",
    "            \n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                best_candidate = cand\n",
    "        \n",
    "        # 更新提示词\n",
    "        current_prompt = best_candidate\n",
    "        step_losses.append(best_loss)\n",
    "        print(f\"[STEP {step + 1}] Loss: {best_loss:.4f}, Prompt: {tokenizer.decode(current_prompt)}\")\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(step_losses, label=\"Loss\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"GCG Optimization Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return current_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d093d3-9122-4569-8403-0550dd6a8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniprompt_algorithm():\n",
    "    global n_tokens\n",
    "    global num_steps\n",
    "    running_min = 0\n",
    "    running_max = 100000\n",
    "    best = None\n",
    "    while True:\n",
    "        z = gcg_algorithm()\n",
    "        input_ids = torch.tensor(z, device=device).long().unsqueeze(0)\n",
    "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 显式要求生成目标文本长度，避免截断\n",
    "            generated_output = model.generate(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                num_beams=50,\n",
    "                no_repeat_ngram_size=2,\n",
    "                early_stopping=False,  # 不提前停止\n",
    "                temperature=0.2\n",
    "            )\n",
    "            generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
    "            print(f\"Generated text: {generated_text} :end\")\n",
    "            print(f\"with token of {n_tokens}\")\n",
    "            \n",
    "            # 严格检查是否完全匹配（包括大小写和标点）\n",
    "            if generated_text.strip() == target_start.strip():\n",
    "                running_max = n_tokens\n",
    "                n_tokens = max(1, n_tokens - 1)  # 至少保留1个token\n",
    "                best = z\n",
    "                num_steps = max(50, num_steps - 10)  # 避免迭代次数过低\n",
    "                print(f\"✅ Matched at {n_tokens} tokens!\")\n",
    "            else:\n",
    "                running_min = n_tokens\n",
    "                n_tokens = min(n_tokens + 5, running_max)  # 每次增加5个token，加速搜索\n",
    "                num_steps = min(500, num_steps + 50)       # 增加迭代次数上限\n",
    "                print(f\"❌ Not matched, increase to {n_tokens} tokens\")\n",
    "\n",
    "        if n_tokens >= running_max:\n",
    "            print(\"Reached maximum token limit, stopping...\")\n",
    "            break\n",
    "        if n_tokens <= running_min:\n",
    "            print(\"Reached minimum token limit, stopping...\")\n",
    "            break\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78ea3229-9a07-4304-a617-c3318e61acb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] Initial Prompt: Cr晚饭六年 Irvine்取得了对比推开 overlooking input偏 Works prosperutures disemb\n",
      "[STEP 1] Loss: 9.5667, Prompt: 大多数晚饭六年 Irvine்取得了对比推开 overlooking input偏 Works prosperutures disemb\n",
      "[STEP 2] Loss: 9.2116, Prompt: 大多数晚饭holm Irvine்取得了对比推开 overlooking input偏 Works prosperutures disemb\n",
      "[STEP 3] Loss: 8.9380, Prompt: 大多数晚饭holm Irvine்对比推开 overlooking input偏 Works prosperutures disemb\n",
      "[STEP 4] Loss: 8.2564, Prompt: 大多数怎样holm Irvine்对比推开 overlooking input偏 Works prosperutures disemb\n",
      "[STEP 5] Loss: 7.8705, Prompt: 大多数怎样holm形式்对比推开 overlooking input偏 Works prosperutures disemb\n",
      "[STEP 6] Loss: 7.4140, Prompt: 大多数怎样holm形式்于此对比推开 overlooking input偏 Works prosperutures disemb\n",
      "[STEP 7] Loss: 7.0509, Prompt: 大多数怎样holm与其他்于此对比推开 overlooking input偏 Works prosperutures disemb\n",
      "[STEP 8] Loss: 7.0509, Prompt: 大多数怎样holm与其他்于此对比推开 overlooking input各地 Works prosperutures disemb\n",
      "[STEP 9] Loss: 7.0509, Prompt: 大多数怎样holm与其他்于此对比推开 overlooking氛各地 Works prosperutures disemb\n",
      "[STEP 10] Loss: 7.0509, Prompt: 大多数怎样holm与其他்于此概念推开 overlooking氛各地 Works prosperutures disemb\n",
      "[STEP 11] Loss: 6.8404, Prompt: 大多数怎样holm不做்于此概念推开 overlooking氛各地 Works prosperutures disemb\n",
      "[STEP 12] Loss: 6.6022, Prompt: 大多数怎样holm不做IVE于此概念推开 overlooking氛各地 Works prosperutures disemb\n",
      "[STEP 13] Loss: 6.5674, Prompt: 大多数怎样holm不做igel于此概念推开 overlooking氛各地 Works prosperutures disemb\n",
      "[STEP 14] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念推开 overlooking氛各地 Works prosperutures disemb\n",
      "[STEP 15] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念推开 overlooking氛小组 Works prosperutures disemb\n",
      "[STEP 16] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念推开 overlooking氛小组有很多 prosperutures disemb\n",
      "[STEP 17] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念推开 overlooking氛小组敌 prosperutures disemb\n",
      "[STEP 18] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念推开 overlooking氛小组敌 prosper兩 disemb\n",
      "[STEP 19] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念推开 overlooking氛十二敌 prosper兩 disemb\n",
      "[STEP 20] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念推开 overlooking氛十二大多数 prosper兩 disemb\n",
      "[STEP 21] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念推开学会氛十二大多数 prosper兩 disemb\n",
      "[STEP 22] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念住房学会氛十二大多数 prosper兩 disemb\n",
      "[STEP 23] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此概念住房学会氛十二大多数 prosper睛 disemb\n",
      "[STEP 24] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此园区住房学会氛十二大多数 prosper睛 disemb\n",
      "[STEP 25] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此园区住房学会氛十二大多数 prosper代理 disemb\n",
      "[STEP 26] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此园区住房学会氛十二大多数 prosper慢慢 disemb\n",
      "[STEP 27] Loss: 6.1941, Prompt: 各地怎样holm不做igel于此园区在于学会氛十二大多数 prosper慢慢 disemb\n",
      "[STEP 28] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此园区在于学会氛十二大多数 prosper慢慢 disemb\n",
      "[STEP 29] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此园区在于学会氛十二大多数 prosper慢慢城区\n",
      "[STEP 30] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此园区在于观点氛十二大多数 prosper慢慢城区\n",
      "[STEP 31] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此园区在于观点氛十二大多数 prosper慢慢美丽\n",
      "[STEP 32] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此高度在于观点氛十二大多数 prosper慢慢美丽\n",
      "[STEP 33] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此高度在于观点氛十二插 prosper慢慢美丽\n",
      "[STEP 34] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此高度在于观点氛十二体现 prosper慢慢美丽\n",
      "[STEP 35] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此高度在于观点氛兩体现 prosper慢慢美丽\n",
      "[STEP 36] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此高度在于观点氛兩体现 prosper慢慢共享\n",
      "[STEP 37] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此高度在于观点氛兽体现 prosper慢慢共享\n",
      "[STEP 38] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此高度在于观点氛兽体现 prosper变得共享\n",
      "[STEP 39] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于观点氛兽体现 prosper变得共享\n",
      "[STEP 40] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于观点组成兽体现 prosper变得共享\n",
      "[STEP 41] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于观点组成平均体现 prosper变得共享\n",
      "[STEP 42] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于观点组成平均体现 prosper塞共享\n",
      "[STEP 43] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于观点组成平均电商 prosper塞共享\n",
      "[STEP 44] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于正是组成平均电商 prosper塞共享\n",
      "[STEP 45] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于多个组成平均电商 prosper塞共享\n",
      "[STEP 46] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于概念组成平均电商 prosper塞共享\n",
      "[STEP 47] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于概念组成在于电商 prosper塞共享\n",
      "[STEP 48] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于概念组成在于电商基础上塞共享\n",
      "[STEP 49] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦在于概念组成在于电商基础上薄共享\n",
      "[STEP 50] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦恒概念组成在于电商基础上薄共享\n",
      "[STEP 51] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦恒概念组成在于电商基础上锦共享\n",
      "[STEP 52] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦深刻概念组成在于电商基础上锦共享\n",
      "[STEP 53] Loss: 6.1208, Prompt: 各地怎样holm不做保留于此锦深刻概念组成在于电商魂锦共享\n",
      "[STEP 54] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦深刻概念组成在于电商魂锦共享\n",
      "[STEP 55] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦深刻概念组成犯罪电商魂锦共享\n",
      "[STEP 56] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦深刻概念组成病毒电商魂锦共享\n",
      "[STEP 57] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦深刻概念组成赁电商魂锦共享\n",
      "[STEP 58] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦深刻概念组成赁电商小组锦共享\n",
      "[STEP 59] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦深刻概念组成赁电商小组想到共享\n",
      "[STEP 60] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦深刻概念组成犯罪电商小组想到共享\n",
      "[STEP 61] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦姆概念组成犯罪电商小组想到共享\n",
      "[STEP 62] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦姆枝组成犯罪电商小组想到共享\n",
      "[STEP 63] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦姆枝组成犯罪概念小组想到共享\n",
      "[STEP 64] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦姆枝组成犯罪转型小组想到共享\n",
      "[STEP 65] Loss: 5.8823, Prompt: 各地怎样营养不做保留于此锦姆枝组成犯罪转型小组炒共享\n",
      "[STEP 66] Loss: 5.5214, Prompt: 感染怎样营养不做保留于此锦姆枝组成犯罪转型小组炒共享\n",
      "[STEP 67] Loss: 5.4793, Prompt: 感染怎样营养不做ays于此锦姆枝组成犯罪转型小组炒共享\n",
      "[STEP 68] Loss: 5.4793, Prompt: 感染怎样营养不做ays于此锦姆枝组成犯罪劲小组炒共享\n",
      "[STEP 69] Loss: 5.4793, Prompt: 感染怎样营养不做ays于此锦姆枝组成犯罪劲尝炒共享\n",
      "[STEP 70] Loss: 5.4793, Prompt: 感染怎样营养不做ays于此锦微博枝组成犯罪劲尝炒共享\n",
      "[STEP 71] Loss: 5.4445, Prompt: 感染怎样营养oralays于此锦微博枝组成犯罪劲尝炒共享\n",
      "[STEP 72] Loss: 5.4445, Prompt: 感染怎样营养oralays于此锦微博枝组成犯罪劲尝坡共享\n",
      "[STEP 73] Loss: 5.4445, Prompt: 感染怎样营养oralays于此劲微博枝组成犯罪劲尝坡共享\n",
      "[STEP 74] Loss: 5.3827, Prompt: 感染怎样营养eralays于此劲微博枝组成犯罪劲尝坡共享\n",
      "[STEP 75] Loss: 5.3827, Prompt: 感染怎样营养eralays于此相比微博枝组成犯罪劲尝坡共享\n",
      "[STEP 76] Loss: 5.3827, Prompt: 感染怎样营养eralays于此横微博枝组成犯罪劲尝坡共享\n",
      "[STEP 77] Loss: 5.3827, Prompt: 感染怎样营养eralays于此横微博枝微博犯罪劲尝坡共享\n",
      "[STEP 78] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博枝微博犯罪劲尝坡共享\n",
      "[STEP 79] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博枝微博犯罪概念尝坡共享\n",
      "[STEP 80] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博枝微博犯罪概念尝坡共享\n",
      "[STEP 81] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博枝微博犯罪概念尝坡横\n",
      "[STEP 82] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博刷微博犯罪概念尝坡横\n",
      "[STEP 83] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博刷微博犯罪概念尝粮横\n",
      "[STEP 84] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博刷氛犯罪概念尝粮横\n",
      "[STEP 85] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博刷氛犯罪概念锦粮横\n",
      "[STEP 86] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博刷氛犯罪公布锦粮横\n",
      "[STEP 87] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博刷氛犯罪公布锦在于横\n",
      "[STEP 88] Loss: 5.3212, Prompt: 感染怎样营养erale于此横微博刷氛犯罪公布敌在于横\n",
      "[STEP 89] Loss: 5.3212, Prompt: 感染怎样营养erale于此荒微博刷氛犯罪公布敌在于横\n",
      "[STEP 90] Loss: 5.3212, Prompt: 感染怎样营养erale于此荒微博刷氛犯罪公布敌清楚横\n",
      "[STEP 91] Loss: 5.3212, Prompt: 感染怎样营养erale于此荒微博刷学会犯罪公布敌清楚横\n",
      "[STEP 92] Loss: 5.3212, Prompt: 感染怎样营养erale于此荒微博刷学会犯罪公布敌偷横\n",
      "[STEP 93] Loss: 5.3212, Prompt: 感染怎样营养erale于此荒微博刷学会犯罪在于敌偷横\n",
      "[STEP 94] Loss: 5.3212, Prompt: 感染怎样营养erale于此荒微博刷学会执法在于敌偷横\n",
      "[STEP 95] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博刷学会执法在于敌偷横\n",
      "[STEP 96] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博刷学会执法在于才是偷横\n",
      "[STEP 97] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博刷学会执法在于才是您的横\n",
      "[STEP 98] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博刷学会执法在于才是您的胆\n",
      "[STEP 99] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博刷多种执法在于才是您的胆\n",
      "[STEP 100] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博刷多种商务在于才是您的胆\n",
      "[STEP 101] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博刷多种商务感染才是您的胆\n",
      "[STEP 102] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博日常多种商务感染才是您的胆\n",
      "[STEP 103] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博日常多种公布感染才是您的胆\n",
      "[STEP 104] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博日常多种公布兽才是您的胆\n",
      "[STEP 105] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博日常共享公布兽才是您的胆\n",
      "[STEP 106] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博日常共享公布整治才是您的胆\n",
      "[STEP 107] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博日常共享曼整治才是您的胆\n",
      "[STEP 108] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博日常共享曼魂才是您的胆\n",
      "[STEP 109] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博日常共享曼魂概念您的胆\n",
      "[STEP 110] Loss: 5.3212, Prompt: 感染怎样营养erale于此主体微博魂共享曼魂概念您的胆\n",
      "[STEP 111] Loss: 5.3146, Prompt: 感染怎样营养eralivated于此主体微博魂共享曼魂概念您的胆\n",
      "[STEP 112] Loss: 5.3146, Prompt: 感染怎样营养eralivated于此主体寺魂共享曼魂概念您的胆\n",
      "[STEP 113] Loss: 5.3146, Prompt: 感染怎样营养eralivated于此主体寺园区共享曼魂概念您的胆\n",
      "[STEP 114] Loss: 5.3146, Prompt: 感染怎样营养eralivated于此主体寺园区共享曼反映概念您的胆\n",
      "[STEP 115] Loss: 5.2739, Prompt: 感染怎样营养uteivated于此主体寺园区共享曼反映概念您的胆\n",
      "[STEP 116] Loss: 5.2739, Prompt: 感染怎样营养uteivated于此主体寺园区共享曼往往概念您的胆\n",
      "[STEP 117] Loss: 5.2739, Prompt: 感染怎样营养uteivated于此主体寺利润共享曼往往概念您的胆\n",
      "[STEP 118] Loss: 5.2739, Prompt: 感染怎样营养uteivated于此主体寺利润共享曼组成概念您的胆\n",
      "[STEP 119] Loss: 5.2739, Prompt: 感染怎样营养uteivated于此主体寺利润共享曼组成是在您的胆\n",
      "[STEP 120] Loss: 5.2739, Prompt: 感染怎样营养uteivated于此主体寺利润共享曼格局是在您的胆\n",
      "[STEP 121] Loss: 5.2739, Prompt: 感染怎样营养uteivated于此主体寺利润岗位曼格局是在您的胆\n",
      "[STEP 122] Loss: 5.2739, Prompt: 感染怎样营养uteivated于此主体寺利润才是曼格局是在您的胆\n",
      "[STEP 123] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体寺利润才是曼格局是在您的胆\n",
      "[STEP 124] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体寺利润才是曼整治是在您的胆\n",
      "[STEP 125] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体寺利润才是曼整治是在您的想到\n",
      "[STEP 126] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体寺利润才是曼整治兽您的想到\n",
      "[STEP 127] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体寺利润才是曼整治兽您的是在\n",
      "[STEP 128] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体概念利润才是曼整治兽您的是在\n",
      "[STEP 129] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体概念不管才是曼整治兽您的是在\n",
      "[STEP 130] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体建成不管才是曼整治兽您的是在\n",
      "[STEP 131] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体建成不管才是曼整治兽拖是在\n",
      "[STEP 132] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体建成不管才是曼利润兽拖是在\n",
      "[STEP 133] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体建成不管才是曼概念兽拖是在\n",
      "[STEP 134] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体建成不管才是曼概念兽拖利润\n",
      "[STEP 135] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作主体建成不管才是曼睛兽拖利润\n",
      "[STEP 136] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作赁建成不管才是曼睛兽拖利润\n",
      "[STEP 137] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作战斗建成不管才是曼睛兽拖利润\n",
      "[STEP 138] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作战斗建成不管才是曼睛想到拖利润\n",
      "[STEP 139] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作战斗建成不管才是曼睛寺拖利润\n",
      "[STEP 140] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作战斗建成不管商务曼睛寺拖利润\n",
      "[STEP 141] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作战斗建成不管商务曼清楚寺拖利润\n",
      "[STEP 142] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受建成不管商务曼清楚寺拖利润\n",
      "[STEP 143] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受建成不管商务曼清楚寺十二利润\n",
      "[STEP 144] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受高度不管商务曼清楚寺十二利润\n",
      "[STEP 145] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受高度不管商务曼清楚寺十二十二\n",
      "[STEP 146] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受变得不管商务曼清楚寺十二十二\n",
      "[STEP 147] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受变得不管商务宅清楚寺十二十二\n",
      "[STEP 148] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受变得不管商务宅公益寺十二十二\n",
      "[STEP 149] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受变得不管组合宅公益寺十二十二\n",
      "[STEP 150] Loss: 5.2315, Prompt: 感染怎样营养uteivated的操作感受变得不管组合宅组成寺十二十二\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 感染怎样营养uteivated的操作感受变得不管组合宅组成寺十二十二年了\n",
      "\n",
      "您的问题描述有些模糊，我需要更多的信息才能给出准确的回答。请问您 :end\n",
      "with token of 15\n",
      "❌ Not matched, increase to 20 tokens\n",
      "[INIT] Initial Prompt:  Croatia찎-tests عليهاPINposiçãointhקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 1] Loss: 12.2398, Prompt:  Croatia찎-tests）\n",
      "\n",
      "PINposiçãointhקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 2] Loss: 11.3409, Prompt: 战斗찎-tests）\n",
      "\n",
      "PINposiçãointhקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 3] Loss: 10.7644, Prompt: 战斗찎）\n",
      "\n",
      "PINposiçãointhקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 4] Loss: 10.0427, Prompt: 战斗찎）\n",
      "\n",
      "环境posiçãointhקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 5] Loss: 9.8705, Prompt: 战斗찎）\n",
      "\n",
      "环境inthקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 6] Loss: 9.5381, Prompt: 战斗찎）\n",
      "\n",
      "转移inthקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 7] Loss: 9.2056, Prompt: 战斗찎）\n",
      "\n",
      "转移xicinthקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 8] Loss: 8.6762, Prompt: 战斗찎<|endoftext|>）\n",
      "\n",
      "转移xicinthקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 9] Loss: 8.5814, Prompt: 战斗찎<|endoftext|>）\n",
      "\n",
      "转移😆inthקפהidineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 10] Loss: 8.5814, Prompt: 战斗찎<|endoftext|>）\n",
      "\n",
      "转移😆inth多个idineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 11] Loss: 8.5716, Prompt: 坡찎<|endoftext|>）\n",
      "\n",
      "转移😆inth多个idineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 12] Loss: 8.3257, Prompt: 坡찎换）\n",
      "\n",
      "转移😆inth多个idineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 13] Loss: 7.8277, Prompt: 坡찎换is转移😆inth多个idineкрепńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 14] Loss: 7.8277, Prompt: 坡찎换is转移😆inth多个idine荒ńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 15] Loss: 7.5914, Prompt: 多种찎换is转移😆inth多个idine荒ńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 16] Loss: 7.5914, Prompt: 多种찎换is转移😆整治多个idine荒ńst自然而 rendez ninth בקו parçaBTN痛み岘_BACK\n",
      "[STEP 17] Loss: 7.5914, Prompt: 多种찎换is转移😆整治多个idine荒ńst自然而 rendez ninth בקו parçaBTN不了岘_BACK\n",
      "[STEP 18] Loss: 7.5914, Prompt: 多种찎换is转移😆整治多个idine荒ńst自然而 rendez ninth בקו parçaBTN恒岘_BACK\n",
      "[STEP 19] Loss: 7.5914, Prompt: 多种찎换is转移😆整治多个idine荒当中自然而 rendez ninth בקו parçaBTN恒岘_BACK\n",
      "[STEP 20] Loss: 7.5524, Prompt: 多种찎换alled转移😆整治多个idine荒当中自然而 rendez ninth בקו parçaBTN恒岘_BACK\n",
      "[STEP 21] Loss: 7.5524, Prompt: 多种찎换alled转移😆整治多个idine荒当中自然而 rendez才是 בקו parçaBTN恒岘_BACK\n",
      "[STEP 22] Loss: 7.5524, Prompt: 多种찎换alled转移😆整治多个idine荒村民自然而 rendez才是 בקו parçaBTN恒岘_BACK\n",
      "[STEP 23] Loss: 7.4314, Prompt: 多种찎换alled转移 😉整治多个idine荒村民自然而 rendez才是 בקו parçaBTN恒岘_BACK\n",
      "[STEP 24] Loss: 7.4314, Prompt: 多种찎换alled转移 😉整治多个idine荒村民自然而 rendez才是 בקו航空BTN恒岘_BACK\n",
      "[STEP 25] Loss: 7.2638, Prompt: 多种찎换alled转移？」整治多个idine荒村民自然而 rendez才是 בקו航空BTN恒岘_BACK\n",
      "[STEP 26] Loss: 7.2638, Prompt: 多种찎换alled转移？」整治多个idine荒村民自然而 rendez才是 בקו航空BTN恒有很多_BACK\n",
      "[STEP 27] Loss: 7.2638, Prompt: 多种찎换alled转移？」整治多个idine拖村民自然而 rendez才是 בקו航空BTN恒有很多_BACK\n",
      "[STEP 28] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治多个idine拖村民自然而 rendez才是 בקו航空BTN恒有很多_BACK\n",
      "[STEP 29] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治多个基础上拖村民自然而 rendez才是 בקו航空BTN恒有很多_BACK\n",
      "[STEP 30] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治多个基础上拖村民自然而 rendez才是凤航空BTN恒有很多_BACK\n",
      "[STEP 31] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治多个基础上趋势村民自然而 rendez才是凤航空BTN恒有很多_BACK\n",
      "[STEP 32] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治多个基础上趋势村民自然而 rendez才是凤航空BTN恒有很多刷\n",
      "[STEP 33] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治多个基础上趋势村民自然而 rendez才是凤航空各项恒有很多刷\n",
      "[STEP 34] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治多个基础上趋势村民自然而 rendez才是真是航空各项恒有很多刷\n",
      "[STEP 35] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治多个基础上趋势村民自然而 rendez粮真是航空各项恒有很多刷\n",
      "[STEP 36] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治始终基础上趋势村民自然而 rendez粮真是航空各项恒有很多刷\n",
      "[STEP 37] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治始终基础上趋势村民自然而 rendez班子真是航空各项恒有很多刷\n",
      "[STEP 38] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治始终基础上趋势村民自然而 rendez曼真是航空各项恒有很多刷\n",
      "[STEP 39] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治始终基础上趋势村民自然而 rendez曼真是航空三大恒有很多刷\n",
      "[STEP 40] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治始终基础上趋势村民自然而 rendez曼真是航空三大恒整治刷\n",
      "[STEP 41] Loss: 7.1527, Prompt: 蔬찎换alled转移？」整治始终基础上尝村民自然而 rendez曼真是航空三大恒整治刷\n",
      "[STEP 42] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚始终基础上尝村民自然而 rendez曼真是航空三大恒整治刷\n",
      "[STEP 43] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚始终基础上尝村民自然而 rendez曼真是航空航空恒整治刷\n",
      "[STEP 44] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚始终基础上尝日常自然而 rendez曼真是航空航空恒整治刷\n",
      "[STEP 45] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚薄基础上尝日常自然而 rendez曼真是航空航空恒整治刷\n",
      "[STEP 46] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚凤基础上尝日常自然而 rendez曼真是航空航空恒整治刷\n",
      "[STEP 47] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚凤基础上尝日常自然而 rendez横真是航空航空恒整治刷\n",
      "[STEP 48] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦基础上尝日常自然而 rendez横真是航空航空恒整治刷\n",
      "[STEP 49] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦基础上尝日常自然而 rendez横真是航空航空恒多个刷\n",
      "[STEP 50] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦基础上尝日常自然而您的横真是航空航空恒多个刷\n",
      "[STEP 51] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦基础上尝进步自然而您的横真是航空航空恒多个刷\n",
      "[STEP 52] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦基础上尝进步自然而您的横真是枝航空恒多个刷\n",
      "[STEP 53] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦基础上塞进步自然而您的横真是枝航空恒多个刷\n",
      "[STEP 54] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦基础上利润进步自然而您的横真是枝航空恒多个刷\n",
      "[STEP 55] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦基础上利润进步自然而您的横真是枝航空恒多个兽\n",
      "[STEP 56] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦坡利润进步自然而您的横真是枝航空恒多个兽\n",
      "[STEP 57] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦邦利润进步自然而您的横真是枝航空恒多个兽\n",
      "[STEP 58] Loss: 7.1527, Prompt: 蔬찎换alled转移？」清楚锦邦曼进步自然而您的横真是枝航空恒多个兽\n",
      "[STEP 59] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦邦曼进步自然而您的横真是枝航空恒多个兽\n",
      "[STEP 60] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦邦曼进步自然而您的横真是枝平均恒多个兽\n",
      "[STEP 61] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦邦曼进步自然而您的横真是枝平均恒多个高度\n",
      "[STEP 62] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦邦曼进步自然而您的吨真是枝平均恒多个高度\n",
      "[STEP 63] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布曼进步自然而您的吨真是枝平均恒多个高度\n",
      "[STEP 64] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布曼进步自然而您的吨真是枝平均恒多个代理\n",
      "[STEP 65] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布曼进步变得您的吨真是枝平均恒多个代理\n",
      "[STEP 66] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布曼进步变得您的吨宅枝平均恒多个代理\n",
      "[STEP 67] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布曼进步变得您的吨平均枝平均恒多个代理\n",
      "[STEP 68] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布曼进步变得您的吨平均枝平均三年多个代理\n",
      "[STEP 69] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布曼进步变得您的吨平均枝平均三年多个兽\n",
      "[STEP 70] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布晰进步变得您的吨平均枝平均三年多个兽\n",
      "[STEP 71] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布建成进步变得您的吨平均枝平均三年多个兽\n",
      "[STEP 72] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布建成进步变得您的吨平均枝平均三年多个往往\n",
      "[STEP 73] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布建成进步变得您的吨平均枝平均三年住房往往\n",
      "[STEP 74] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布建成进步变得您的吨平均兽平均三年住房往往\n",
      "[STEP 75] Loss: 7.1527, Prompt: 蔬찎换alled转移？」枝锦公布建成进步各个您的吨平均兽平均三年住房往往\n",
      "[STEP 76] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦公布建成进步各个您的吨平均兽平均三年住房往往\n",
      "[STEP 77] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦公布蔬进步各个您的吨平均兽平均三年住房往往\n",
      "[STEP 78] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦公布蔬进步各个您的吨平均兽概念三年住房往往\n",
      "[STEP 79] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦公布蔬进步各个代理吨平均兽概念三年住房往往\n",
      "[STEP 80] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦公布病毒进步各个代理吨平均兽概念三年住房往往\n",
      "[STEP 81] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦公布病毒进步各个代理吨平均兽概念三年熊往往\n",
      "[STEP 82] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦有很多病毒进步各个代理吨平均兽概念三年熊往往\n",
      "[STEP 83] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步各个代理吨平均兽概念三年熊往往\n",
      "[STEP 84] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理吨平均兽概念三年熊往往\n",
      "[STEP 85] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理吨平均兽概念三年园区往往\n",
      "[STEP 86] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理吨平均处于概念三年园区往往\n",
      "[STEP 87] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理深刻平均处于概念三年园区往往\n",
      "[STEP 88] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理深刻平均处于概念三年园区往往\n",
      "[STEP 89] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理深刻平均处于同志三年园区往往\n",
      "[STEP 90] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理深刻平均浙江同志三年园区往往\n",
      "[STEP 91] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理深刻平均浙江同志三年主体往往\n",
      "[STEP 92] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理深刻大部分浙江同志三年主体往往\n",
      "[STEP 93] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理深刻大部分浙江同志三年基础上往往\n",
      "[STEP 94] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理凤大部分浙江同志三年基础上往往\n",
      "[STEP 95] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理凤景区浙江同志三年基础上往往\n",
      "[STEP 96] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理凤景区浙江同志三年基础上原来\n",
      "[STEP 97] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒进步曼代理执法景区浙江同志三年基础上原来\n",
      "[STEP 98] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒平均曼代理执法景区浙江同志三年基础上原来\n",
      "[STEP 99] Loss: 7.1527, Prompt: 蔬찎换alled转移？」粮锦各个病毒平均劲代理执法景区浙江同志三年基础上原来\n",
      "[STEP 100] Loss: 7.1412, Prompt: 蔬älle换alled转移？」粮锦各个病毒平均劲代理执法景区浙江同志三年基础上原来\n",
      "[STEP 101] Loss: 7.1412, Prompt: 蔬älle换alled转移？」粮锦各个病毒平均劲代理哭景区浙江同志三年基础上原来\n",
      "[STEP 102] Loss: 7.0219, Prompt: 蔬älle换ICI转移？」粮锦各个病毒平均劲代理哭景区浙江同志三年基础上原来\n",
      "[STEP 103] Loss: 7.0219, Prompt: 蔬älle换ICI转移？」粮锦各个病毒平均劲代理哭景区炒同志三年基础上原来\n",
      "[STEP 104] Loss: 7.0219, Prompt: 蔬älle换ICI转移？」粮锦各个病毒平均劲代理哭景区炒执法三年基础上原来\n",
      "[STEP 105] Loss: 7.0219, Prompt: 蔬älle换ICI转移？」粮锦各个病毒平均劲代理代理景区炒执法三年基础上原来\n",
      "[STEP 106] Loss: 7.0219, Prompt: 蔬älle换ICI转移？」粮锦各个病毒平均劲代理代理景区處执法三年基础上原来\n",
      "[STEP 107] Loss: 6.8676, Prompt: 蔬älle换ICI温和？」粮锦各个病毒平均劲代理代理景区處执法三年基础上原来\n",
      "[STEP 108] Loss: 6.8676, Prompt: 蔬älle换ICI温和？」粮锦各个微博平均劲代理代理景区處执法三年基础上原来\n",
      "[STEP 109] Loss: 6.8676, Prompt: 蔬älle换ICI温和？」粮锦各个微博平均面临代理代理景区處执法三年基础上原来\n",
      "[STEP 110] Loss: 6.8676, Prompt: 蔬älle换ICI温和？」粮锦各个微博平均面临代理代理景区處执法兩基础上原来\n",
      "[STEP 111] Loss: 6.8676, Prompt: 蔬älle换ICI温和？」粮学会各个微博平均面临代理代理景区處执法兩基础上原来\n",
      "[STEP 112] Loss: 6.8676, Prompt: 蔬älle换ICI温和？」粮学会各个微博平均面临代理代理景区處插兩基础上原来\n",
      "[STEP 113] Loss: 6.7410, Prompt: 蔬会会长换ICI温和？」粮学会各个微博平均面临代理代理景区處插兩基础上原来\n",
      "[STEP 114] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮学会各个微博平均面临代理代理景区處插兩基础上原来\n",
      "[STEP 115] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于各个微博平均面临代理代理景区處插兩基础上原来\n",
      "[STEP 116] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于各个微博平均面临代理代理景区趋势插兩基础上原来\n",
      "[STEP 117] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于各个微博平均始终代理代理景区趋势插兩基础上原来\n",
      "[STEP 118] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于各个微博平均始终代理代理景区趋势插兩景区原来\n",
      "[STEP 119] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于各个微博平均同志代理代理景区趋势插兩景区原来\n",
      "[STEP 120] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于各个想到平均同志代理代理景区趋势插兩景区原来\n",
      "[STEP 121] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于各个想到平均曼代理代理景区趋势插兩景区原来\n",
      "[STEP 122] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于熊想到平均曼代理代理景区趋势插兩景区原来\n",
      "[STEP 123] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于慢慢想到平均曼代理代理景区趋势插兩景区原来\n",
      "[STEP 124] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于慢慢想到平均曼代理代理病毒趋势插兩景区原来\n",
      "[STEP 125] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于慢慢想到平均氛代理代理病毒趋势插兩景区原来\n",
      "[STEP 126] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于慢慢想到平均氛代理代理病毒趋势插兩景区病毒\n",
      "[STEP 127] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于慢慢想到形象氛代理代理病毒趋势插兩景区病毒\n",
      "[STEP 128] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮处于慢慢想到形象氛代理代理病毒粮插兩景区病毒\n",
      "[STEP 129] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢想到形象氛代理代理病毒粮插兩景区病毒\n",
      "[STEP 130] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢想到形象氛代理代理病毒锦插兩景区病毒\n",
      "[STEP 131] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢想到形象住房代理代理病毒锦插兩景区病毒\n",
      "[STEP 132] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢想到形象住房代理代理病毒锦插兩景区一致\n",
      "[STEP 133] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢想到形象住房代理代理腹锦插兩景区一致\n",
      "[STEP 134] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢想到不管住房代理代理腹锦插兩景区一致\n",
      "[STEP 135] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢想到不管住房代理犯罪腹锦插兩景区一致\n",
      "[STEP 136] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢想到不管住房代理微博腹锦插兩景区一致\n",
      "[STEP 137] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢辉不管住房代理微博腹锦插兩景区一致\n",
      "[STEP 138] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢辉不管所谓代理微博腹锦插兩景区一致\n",
      "[STEP 139] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」粮插慢慢辉不管所谓代理微博腹锦您的兩景区一致\n",
      "[STEP 140] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗插慢慢辉不管所谓代理微博腹锦您的兩景区一致\n",
      "[STEP 141] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗插慢慢辉不管所谓代理微博腹锦村民兩景区一致\n",
      "[STEP 142] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗插恒辉不管所谓代理微博腹锦村民兩景区一致\n",
      "[STEP 143] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗插恒辉不管想到代理微博腹锦村民兩景区一致\n",
      "[STEP 144] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗插恒辉不管想到代理微博腹锦村民兩景区各地\n",
      "[STEP 145] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗插恒辉不管想到代理微博腹锦各地兩景区各地\n",
      "[STEP 146] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗插恒辉不管想到代理微博晰锦各地兩景区各地\n",
      "[STEP 147] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗浙江恒辉不管想到代理微博晰锦各地兩景区各地\n",
      "[STEP 148] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗浙江恒辉不管想到薄微博晰锦各地兩景区各地\n",
      "[STEP 149] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗浙江恒辉不管想到薄微博晰锦各地兩景区劲\n",
      "[STEP 150] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗浙江恒辉不管想到薄微博晰锦各地兩想到劲\n",
      "[STEP 151] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗园区恒辉不管想到薄微博晰锦各地兩想到劲\n",
      "[STEP 152] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗园区恒辉不管想到薄插晰锦各地兩想到劲\n",
      "[STEP 153] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗园区恒辉不管高度薄插晰锦各地兩想到劲\n",
      "[STEP 154] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗身份恒辉不管高度薄插晰锦各地兩想到劲\n",
      "[STEP 155] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗身份恒辉不管形象薄插晰锦各地兩想到劲\n",
      "[STEP 156] Loss: 6.5230, Prompt: 感染会会长换ICI温和？」战斗身份恒辉不管三大薄插晰锦各地兩想到劲\n",
      "[STEP 157] Loss: 6.4146, Prompt: 感染会会长换替换温和？」战斗身份恒辉不管三大薄插晰锦各地兩想到劲\n",
      "[STEP 158] Loss: 6.4146, Prompt: 感染会会长换替换温和？」战斗身份塞辉不管三大薄插晰锦各地兩想到劲\n",
      "[STEP 159] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞辉不管三大薄插晰锦各地兩想到劲\n",
      "[STEP 160] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞辉不管三大薄插晰深刻各地兩想到劲\n",
      "[STEP 161] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞辉不管三大薄插晰深刻商务兩想到劲\n",
      "[STEP 162] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管三大薄插晰深刻商务兩想到劲\n",
      "[STEP 163] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管三大薄插晰深刻商务兩想到劲\n",
      "[STEP 164] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管睛薄插晰深刻商务兩想到劲\n",
      "[STEP 165] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管睛薄插晰深刻商务多个想到劲\n",
      "[STEP 166] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管睛薄插晰深刻形象多个想到劲\n",
      "[STEP 167] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管睛薄插大多数深刻形象多个想到劲\n",
      "[STEP 168] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管睛薄插大多数深刻形象基础上想到劲\n",
      "[STEP 169] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管睛薄插大多数深刻形象基础上学会劲\n",
      "[STEP 170] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管大部分薄插大多数深刻形象基础上学会劲\n",
      "[STEP 171] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管大部分薄插是在深刻形象基础上学会劲\n",
      "[STEP 172] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于不管大部分薄插是在深刻清楚基础上学会劲\n",
      "[STEP 173] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于所谓大部分薄插是在深刻清楚基础上学会劲\n",
      "[STEP 174] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法身份塞在于所谓三大薄插是在深刻清楚基础上学会劲\n",
      "[STEP 175] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞在于所谓三大薄插是在深刻清楚基础上学会劲\n",
      "[STEP 176] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞在于所谓三大各地插是在深刻清楚基础上学会劲\n",
      "[STEP 177] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞在于所谓三大各地插是在薄清楚基础上学会劲\n",
      "[STEP 178] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞在于所谓三大太阳插是在薄清楚基础上学会劲\n",
      "[STEP 179] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞在于所谓三大太阳真是是在薄清楚基础上学会劲\n",
      "[STEP 180] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞辉所谓三大太阳真是是在薄清楚基础上学会劲\n",
      "[STEP 181] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞辉所谓三大太阳真是是在薄清楚地位学会劲\n",
      "[STEP 182] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞经典所谓三大太阳真是是在薄清楚地位学会劲\n",
      "[STEP 183] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝塞经典所谓三大太阳真是是在薄清楚慢慢学会劲\n",
      "[STEP 184] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝兩经典所谓三大太阳真是是在薄清楚慢慢学会劲\n",
      "[STEP 185] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝兩经典所谓三大太阳真是面临薄清楚慢慢学会劲\n",
      "[STEP 186] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝兩经典所谓三大太阳真是面临薄清楚慢慢概念劲\n",
      "[STEP 187] Loss: 6.4146, Prompt: 感染会会长换替换温和？」执法尝兩经典所谓三大太阳真是面临薄慢慢慢慢概念劲\n",
      "[STEP 188] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩经典所谓三大太阳真是面临薄慢慢慢慢概念劲\n",
      "[STEP 189] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动所谓三大太阳真是面临薄慢慢慢慢概念劲\n",
      "[STEP 190] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动所谓三大尝真是面临薄慢慢慢慢概念劲\n",
      "[STEP 191] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动所谓三大尝观点面临薄慢慢慢慢概念劲\n",
      "[STEP 192] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动所谓辉尝观点面临薄慢慢慢慢概念劲\n",
      "[STEP 193] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动所谓辉尝观点面临薄慢慢慢慢微博劲\n",
      "[STEP 194] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动城区辉尝观点面临薄慢慢慢慢微博劲\n",
      "[STEP 195] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动城区辉尝慢慢面临薄慢慢慢慢微博劲\n",
      "[STEP 196] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动慢慢辉尝慢慢面临薄慢慢慢慢微博劲\n",
      "[STEP 197] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动慢慢辉尝慢慢面临薄慢慢蔬微博劲\n",
      "[STEP 198] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动锦辉尝慢慢面临薄慢慢蔬微博劲\n",
      "[STEP 199] Loss: 6.4146, Prompt: 感染会会长换替换温和？」观点尝兩劳动锦辉尝慢慢面临薄零售蔬微博劲\n",
      "[STEP 200] Loss: 6.3523, Prompt: 感染会会长换替换温和结论观点尝兩劳动锦辉尝慢慢面临薄零售蔬微博劲\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAGDCAYAAADQ9S0AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyFUlEQVR4nO3deXxddZ3/8fcn+560SZuu0J22LLbTAAWkTWURFFnEBURFZX4Mo44iMwqO4/7zN27jMIAb4wICtqMiIwoqoISCtOwFWloohRbSlbQkaZqm2T6/P+4JhJLk3pPm3nNv7uv5eNxHc89dziefnKTvfPM932PuLgAAAACDy4m6AAAAACDdEZoBAACAOAjNAAAAQByEZgAAACAOQjMAAAAQB6EZAAAAiIPQDAAjxMwuMrO7hvnak83s2XSqCQDwOkIzgEiZ2QVm9pCZ7TOzXcHHHzcz6/ec48zsTjNrNrM9ZvawmX203+PlZvY9M9scvM9LZvYbMztuiP0Wmtm/B8/db2Ybzeyz/fcbp+5pZuZmlte3zd1vcffTh9MHd7/f3Y8YzmuTVVOcfdWbWeNIv2+C+zYz+5SZrQ2+3o1m9mszOzqKegBkB0IzgMiY2T9L+i9J35E0QVKtpMsknSSpIHjOCZL+Kuk+SbMkVUv6R0lnBo8XBo8fLeksSRWS5klaIekdQ+z+15JOCZ5TLulDki4N6kF6+y9Jn5b0KUljJc2R9L+S3hn2jfr/ggEAQ3J3bty4cUv5TVKlpH2Szo/zvAckfX+Ix/9e0nZJpSH2fYqkDklTD9p+vKQeSbOC+w2S/l3Sw5JaJP1O0tjgsZckuaS24HaCpI9IeqDf+7mkj0vaKGmvpK9LmilplaRWSb+SVBA8t15SY/Dx+/u9b5ukA5IagsfeKemJ4PUvS/pKv/0lUtOJkh4JPp9HJJ3Y77GGoMa/BfXeJalmkB6+Vu8Aj80L3qtZ0jpJZ/d77B2Sngnef6ukfwm210j6Q/CaPZLul5QzwHvPDr5Gxw3x9W2Q9Pf97g/0dflE8HV5UdKPJH33oPf4naQrgo8nSbpV0ivB8z8V9fcPN27cUn9jpBlAVE6QVKhYOBmQmZUEz/vNEO9zqqQ/u/u+EPs+TdJD7v5y/43u/pCkRsVCdZ8PS/qYYsGpW9I1wfYlwb9V7l7m7qsG2dcZkhZJWizpc5Kul3SRpKmSjpJ04cEvcPf/Cd6zLNjvC5KWBw/vC2qqUixA/6OZnZtITWY2VtIdwedQLel7ku4ws+p+T/uApI9KGq/YaP+/DPJ5DcjM8iX9XrHAPV7SP0m6xcz6pp78VNI/uHt58Pn/Ndj+z4r1fpxif3H4V8XC7cFOUSysPxymrgGcq9gvSfMl/VLS+/um5pjZGEmnS1phZjnB5/OkpMnB/i83s7cf4v4BZBhCM4Co1Ehqcvfuvg1m9mAwb3m/mS2RNEaxn1Pb47zPjn7vsSB4j9YhTqyrGeI9tweP97nJ3dcGofyLkt5nZrlxP7vXfcvdW919naS1ku5y9xfcvUXSHyUtHOyFQWD7pWKjzD+WJHdvcPen3b3X3Z9SLEwvTbCWd0ra6O43uXu3uy+XtEHSu/o95+fu/py771dsJHxBiM9Viv1yUCbpm+7e6e5/VWwEue+Xgy5J882swt1fdffH+22fKOlwd+/y2BzvgUJztYY+HhL17+6+J/g871csoJ8cPPYeSavcfZukYyWNc/evBZ/PC5L+W9IFI1ADgAxCaAYQld2Sag46ae1Ed68KHsuR9KqkXsXC1FDv89rj7r4meI93KzaSPZCmId5zYvB4n/6j0Vsk5euNoTqenf0+3j/A/bIhXvsNxeZbf6pvg5kdb2b3mtkrZtai2BzwROuZpNjn0N8WxUZQ++zo93F7nPoG28fL7t47yD7OV2yKxhYzuy+Ysy7F5rU/L+kuM3vBzK4a5P3f8PU+BK99XYNwvkKvB/sPSLol+PhwSZOCX8SazaxZsVHw2hGoAUAGITQDiMoqxebqnjPYE9y9PXje+UO8z18knW5mpSH2fY+k481sav+NwWobU/X6lAEF9/scptiIaJMGnjowYszsAsVC3HvcvavfQ7+UdLti87ErFZuP27fiR7yatikWAvs7TLG5xSNlm6SpwSj5m/bh7o+4+zmKTd34X8VGs+Xue939n919hmIj31eY2Sl6s79ImmJmdUPUsE9SSb/7EwZ4zsG9Wi7pPWZ2uGLTNm4Ntr8s6UV3r+p3K3f3oU4yBTAKEZoBRMLdmyV9VdIPzOw9ZlZmZjlmtkBS/wD8OUkfCZaDq5YkM3uLma0IHv+FYn+uv83MjjKzXDMrkjRoqHL3exQLX7ea2ZHBaxYrNrr4Q3ff2O/pHzSz+cH86q9J+o279yh2UlivpBmH3IyDmNlCSddKOtfdXzno4XJJe9y9Iwj5H+j3WLya7pQ0x8w+YGZ5ZvZ+xeb0/uEQai3qf1PspMl9kj5nZvlmVq9YCF5hZgXButGVwS8CrYqd1CczO8vMZgXzivu29xy8v+Br8wNJy4Nl7wqCfV/Qb3R6jaR3m1mJmc2SdEm8z8Pdn1Csfz9RbI58c/DQw5JazexKMysOjpWjzOzY4fQLQOYiNAOIjLt/W9IVigXjXYpNXfixpCslPRg850FJbwtuL5jZHsVOprszeLxD0jLFVmS4Q7HA9axic1HfN8Tuz5d0r6Q/KbbSxM2KnaT2Twc97yZJNyg2baFIwVSJYBT8G5L+FvzZfvHwujCgcxSbz/2AmbUFtz8Gj31c0tfMbK+kLykYqU2kJnffrdiyfP+s2DSHz0k6y937T0cJY7JiU0z636ZKOluxJQGbFAu4H3b3DcFrPiRps5m1Kja15IPB9tmK/QWgTbG/LvzA3RsG2e+nJF0n6fuKrbaxSdJ5ip2wJ0n/KalTsePpRr0+1SKe5YqdWPrLvg3BL0jvUmxu94vB5/QTxVZ/AZBFbODzLAAAZtYg6WZ3/0nUtQAAosVIMwAAABAHoRkAAACIg+kZAAAAQByMNAMAAABxEJoBAACAOPLiPyV6NTU1Pm3atJTvd9++fSotDXO9BNCzcOhXePQsHPoVHj0Lh36FR8/CSXW/HnvssSZ3H3fw9owIzdOmTdOjjz6a8v02NDSovr4+5fvNZPQsHPoVHj0Lh36FR8/CoV/h0bNwUt0vM9sy0HamZwAAAABxEJoBAACAOAjNAAAAQBwZMacZAAAAqdPV1aXGxkZ1dHREXYoqKyu1fv36EX/foqIiTZkyRfn5+Qk9n9AMAACAN2hsbFR5ebmmTZsmM4u0lr1796q8vHxE39PdtXv3bjU2Nmr69OkJvYbpGQAAAHiDjo4OVVdXRx6Yk8XMVF1dHWokndAMAACANxmtgblP2M+P0AwAAIC0U1ZWFnUJb0BoBgAAAOIgNAMAACAjrFmzRosXL9Yxxxyj8847T6+++qok6ZprrtH8+fN1zDHH6IILLpAk3XfffVqwYIEWLFighQsXau/evYe0b1bPAAAAwKC++vt1emZb64i+5/xJFfryu44M/boPf/jDuvbaa7V06VJ96Utf0le/+lVdffXV+uY3v6kXX3xRhYWFam5uliR997vf1fe//32ddNJJamtrU1FR0SHVzEjzIHa2dmjNrm51dPVEXQoAAEDWa2lpUXNzs5YuXSpJuvjii7Vy5UpJ0jHHHKOLLrpIN998s/LyYmPCJ510kq644gpdc801am5ufm37cDHSPIgHNjbp6scP6Ny3dWhaTWnU5QAAAERiOCPCqXbHHXdo5cqVuv322/X1r39d69at01VXXaV3vvOduvPOO7V48WLdc889mjt37rD3wUjzICqLY1eHad7fFXElAAAAqKys1JgxY3T//fdLkm666SYtXbpUvb29evnll7Vs2TJ9+9vfVnNzs9ra2rRp0yYdffTRuvLKK1VXV6cNGzYc0v4ZaR5EZUksNLcQmgEAAFKuvb1dU6ZMkbvLzHTFFVfoxhtv1GWXXab29nbNmDFDP//5z9XT06MPfvCDamlpkbvrM5/5jKqqqvTFL35R9957r3JzczV//nydeeaZh1QPoXkQVcWEZgAAgKj09vZKevNltFevXv2m5z7wwANv2nbttdeOaD1MzxhEJaEZAAAAAULzICr6QnN7Z8SVAAAAIGqE5kEU5eeqIIeRZgAAABCah1SSb4RmAACQldw96hKSKuznR2geQmk+I80AACD7FBUVaffu3aM2OLu7du/eHeoqgUlbPcPMfibpLEm73P2oYNt3JL1LUqekTZI+6u7NyarhUJXmm5rbCc0AACC7TJkyRY2NjXrllVeiLkUdHR2HfAnsgRQVFWnKlCkJPz+ZS87dIOk6Sb/ot+1uSZ93924z+5akz0u6Mok1HJJSpmcAAIAslJ+fr+nTp0ddhiSpoaFBCxcujLqM5E3PcPeVkvYctO0ud+8O7q6WlHi8j0BJnqmV0AwAAJD1opzT/DFJf4xw/3GV5XMZbQAAAEiWzAneZjZN0h/65jT32/4FSXWS3u2DFGBml0q6VJJqa2sXrVixIml1DubXz7TpjpdMPzm9RHk5lvL9Z6K2tjaVlZVFXUbGoF/h0bNw6Fd49Cwc+hUePQsn1f1atmzZY+5ed/D2lF9G28wuVuwEwVMGC8yS5O7XS7pekurq6ry+vj41BfZzz5a7JXVqwXEnqqasMOX7z0QNDQ2K4muVqehXePQsHPoVHj0Lh36FR8/CSZd+pXR6hpmdodiJf2e7e3sq9z0cJfmx0WVOBgQAAMhuSQvNZrZc0ipJR5hZo5ldothqGuWS7jazNWb2o2TtfySUxa6kzbJzAAAAWS5p0zPc/cIBNv80WftLhr6RZlbQAAAAyG5cEXAIpXlMzwAAAACheUilBbHQ3NzeGXElAAAAiBKheQglweSVlv3dQz8RAAAAoxqheQh5OabSglymZwAAAGQ5QnMcVSUFhGYAAIAsR2iOo6I4Xy37mdMMAACQzQjNcVQW5zHSDAAAkOUIzXFUFTM9AwAAINsRmuOoLM7nioAAAABZjtAcR2VJPiPNAAAAWY7QHEdlcb4OdPeqo6sn6lIAAAAQEUJzHJXF+ZKkVkabAQAAshahOY6+0NxMaAYAAMhahOY4qkpioZl5zQAAANmL0BxH30hzCytoAAAAZC1CcxyvhWZGmgEAALIWoTkO5jQDAACA0BxHeVG+zBhpBgAAyGaE5jhyc0zlhXksOQcAAJDFCM0JqCzJV3N7Z9RlAAAAICKE5gRUFRcwPQMAACCLEZoTUFmcT2gGAADIYoTmBBCaAQAAshuhOQGVJYRmAACAbEZoTkDfSLO7R10KAAAAIkBoTkBlcb66elz7u3qiLgUAAAARIDQnoKrvqoDtTNEAAADIRoTmBFQSmgEAALIaoTkB48oLJUmvtB2IuBIAAABEgdCcgNqKIknSzpaOiCsBAABAFAjNCegLzTtaCc0AAADZiNCcgIK8HFWXFhCaAQAAshShOUG1FUVMzwAAAMhShOYETagsYqQZAAAgSxGaE1RbUaSdhGYAAICsRGhO0ISKIjW1daqzuzfqUgAAAJBihOYE1VbE1mretZfRZgAAgGxDaE5QbWWwVjNTNAAAALIOoTlBE/rWam7hqoAAAADZhtCcoAlc4AQAACBrEZoTVFWSr4K8HKZnAAAAZKGkhWYz+5mZ7TKztf22vdfM1plZr5nVJWvfyWBmmlBRpB1c4AQAACDrJHOk+QZJZxy0ba2kd0tamcT9Js2ECi5wAgAAkI2SFprdfaWkPQdtW+/uzyZrn8lWW8kFTgAAALIRc5pDmFBRqB0tHXL3qEsBAABAClkyA6CZTZP0B3c/6qDtDZL+xd0fHeK1l0q6VJJqa2sXrVixIml1DqatrU1lZWWv3f/z5i4t39Cp695WorICS3k9meDgnmFo9Cs8ehYO/QqPnoVDv8KjZ+Gkul/Lli17zN3fdO5dXsoqCMndr5d0vSTV1dV5fX19ymtoaGhQ//22PbVNyzc8oVnHLNLcCRUprycTHNwzDI1+hUfPwqFf4dGzcOhXePQsnHTpF9MzQnj9AifMawYAAMgmyVxybrmkVZKOMLNGM7vEzM4zs0ZJJ0i6w8z+nKz9J0NtBZfSBgAAyEZJm57h7hcO8tBtydpnstVyKW0AAICsxPSMEAryclRdWsBazQAAAFmG0BxSbQVrNQMAAGQbQnNIEyq5lDYAAEC2ITSHxEgzAABA9iE0hzShoki793XqQHdP1KUAAAAgRQjNIU2oLJQk7WplBQ0AAIBsQWgOibWaAQAAsg+hOaSasthIc1NbZ8SVAAAAIFUIzSH1heY9+wjNAAAA2YLQHNLY0gJJ0u425jQDAABkC0JzSAV5OSovytNuRpoBAACyBqF5GGrKCgnNAAAAWYTQPAxjSwuYngEAAJBFCM3DUF1awImAAAAAWYTQPAzVZQUsOQcAAJBFCM3DUF1aqFfbO9Xb61GXAgAAgBQgNA/D2NIC9fS6WvZ3RV0KAAAAUoDQPAzVZcFazcxrBgAAyAqE5mGoLo1dFZAVNAAAALIDoXkY+kaaWUEDAAAgOxCah6EvNDcRmgEAALICoXkYxpQEI80sOwcAAJAVCM3DkJ+bo6qSfO3ex5xmAACAbEBoHqbYpbQZaQYAAMgGhOZhqiktZKQZAAAgSxCah4mRZgAAgOxBaB6m6rIClpwDAADIEoTmYaouLdCe9k719HrUpQAAACDJCM3DVF1WKHepuZ3RZgAAgNGO0DxMY0tjazXvZooGAADAqEdoHqa+qwJyMiAAAMDoR2geppqyQkli2TkAAIAsQGgepr7pGaygAQAAMPoRmodpTEmBzKQmpmcAAACMeoTmYcrNMY0pKdDuNqZnAAAAjHaE5kNQXcoFTgAAALIBofkQcCltAACA7EBoPgQ1ZYWsngEAAJAFCM2HYGxpARc3AQAAyAKE5kNQXVag5vYudff0Rl0KAAAAkojQfAiqgwuc7GlntBkAAGA0IzQfgmoucAIAAJAVkhaazexnZrbLzNb22zbWzO42s43Bv2OStf9U6AvNTXsJzQAAAKNZMkeab5B0xkHbrpL0F3efLekvwf2MNb2mVGbSY1tejboUAAAAJFHSQrO7r5S056DN50i6Mfj4RknnJmv/qTC+okjHTx+r3z25Ve4edTkAAABIEktm2DOzaZL+4O5HBfeb3b2q3+OvuvuAUzTM7FJJl0pSbW3tohUrViStzsG0tbWprKxsyOc0vNylG9Z16isnFGlaZW6KKktfifQMr6Nf4dGzcOhXePQsHPoVHj0LJ9X9WrZs2WPuXnfw9ryUVRCSu18v6XpJqqur8/r6+pTX0NDQoHj7XdDeqVs23KPG3In6SP381BSWxhLpGV5Hv8KjZ+HQr/DoWTj0Kzx6Fk669CvVq2fsNLOJkhT8uyvF+x9xVSUFWjpnvH7/1Db19DJFAwAAYDRKdWi+XdLFwccXS/pdivefFOcunKSdrQf00Iu7oy4FAAAASZDMJeeWS1ol6QgzazSzSyR9U9JpZrZR0mnB/Yx3ytxalRbk6ndPbIu6FAAAACRB0uY0u/uFgzx0SrL2GZXigly9/cgJunPtdn3t3CNVmMcJgQAAAKMJVwQcIecsnKy9Hd26/7mmqEsBAADACCM0j5Djp49Vbo7pycbmqEsBAADACCM0j5Ci/FzNqCnV+u2tUZcCAACAEUZoHkHzJlZo/fa9UZcBAACAEUZoHkHzJlZoa/N+tbR3RV0KAAAARhCheQTNnVguSdqwgykaAAAAowmheQTNn1ghScxrBgAAGGUIzSNofHmhxpYWMK8ZAABglCE0jyAz07yJ5VrP9AwAAIBRhdA8wuZOqNCzO/aqp9ejLgUAAAAjhNA8wuZNrNCB7l692LQv6lIAAAAwQgjNI2xesIIGJwMCAACMHoTmETZrfJnycozQDAAAMIoQmkdYYV6uZo4r04YdrKABAAAwWhCak2DexHJGmgEAAEYRQnMSzJtYoe0tHWpu74y6FAAAAIwAQnMSzAuuDPgMo80AAACjAqE5CeYGK2hs4MqAAAAAowKhOQnGlxeppqyAec0AAACjBKE5SeZNrOBy2gAAAKMEoTlJ5k2s0HM729Td0xt1KQAAADhECYVmMys1s5zg4zlmdraZ5Se3tMw2d0K5Ort79QKX0wYAAMh4iY40r5RUZGaTJf1F0kcl3ZCsokaDvhU0mNcMAACQ+RINzebu7ZLeLeladz9P0vzklZX5Zo4rU36uaT0raAAAAGS8hEOzmZ0g6SJJdwTb8pJT0uhQkJejWeO5MiAAAMBokGhovlzS5yXd5u7rzGyGpHuTVtUoweW0AQAARoeEQrO73+fuZ7v7t4ITApvc/VNJri3jzZtQoV17D2h324GoSwEAAMAhSHT1jF+aWYWZlUp6RtKzZvbZ5JaW+fpOBtywg3nNAAAAmSzR6Rnz3b1V0rmS7pR0mKQPJauo0WJecDltpmgAAABktkRDc36wLvO5kn7n7l2SPGlVjRLVZYUaX16oZwjNAAAAGS3R0PxjSZsllUpaaWaHSyIJJmDuxAptYNk5AACAjJboiYDXuPtkd3+Hx2yRtCzJtY0K8yaW6/ldberictoAAAAZK9ETASvN7Htm9mhw+w/FRp0Rx/yJFers6dWmV9qiLgUAAADDlOj0jJ9J2ivpfcGtVdLPk1XUaMLltAEAADJfolf1m+nu5/e7/1UzW5OEekad6TWlys0xPb+LkWYAAIBMlehI834ze2vfHTM7SdL+5JQ0uuTn5mhCRZG2N3dEXQoAAACGKdGR5ssk/cLMKoP7r0q6ODkljT4TK4u0rYXfMQAAADJVoqtnPOnub5F0jKRj3H2hpLcltbJRZFJVsbYx0gwAAJCxEp2eIUly99bgyoCSdEUS6hmVJlYVaUdLh3p7uR4MAABAJgoVmg9iI1bFKDe5qlidPb3ava8z6lIAAAAwDIcSmhk2TdDEymJJ0rZm5jUDAABkoiFDs5ntNbPWAW57JU0a7k7N7NNmttbM1pnZ5cN9n0wxsbJIkrSdkwEBAAAy0pCrZ7h7+Ujv0MyOkvR/JB0nqVPSn8zsDnffONL7SheTq2IjzVs5GRAAACAjHcr0jOGaJ2m1u7e7e7ek+ySdF0EdKVNVkq+i/BxtZ3oGAABARooiNK+VtMTMqs2sRNI7JE2NoI6UMTNNqizW9hZGmgEAADKRuaf+fD4zu0TSJyS1SXpG0n53/8xBz7lU0qWSVFtbu2jFihUpr7OtrU1lZWUj8l7feWS/9ndLXzqheETeL12NZM+yAf0Kj56FQ7/Co2fh0K/w6Fk4qe7XsmXLHnP3uoO3RxKa31CA2f+T1OjuPxjsOXV1df7oo4+msKqYhoYG1dfXj8h7ffbXT2rlxlf00L+eOiLvl65GsmfZgH6FR8/CoV/h0bNw6Fd49CycVPfLzAYMzVFMz5CZjQ/+PUzSuyUtj6KOVJpUVaxdew+os7s36lIAAAAQ0pCrZyTRrWZWLalL0ifc/dWI6kiZSVVFcpd2tnZo6tiSqMsBAABACJGEZnc/OYr9RqnvAifbWwjNAAAAmSaS6RnZaFIVVwUEAADIVITmFJlUFbsq4DauCggAAJBxCM0pUlKQp6qSfG3nqoAAAAAZh9CcQhMri5meAQAAkIEIzSk0qbJI27gqIAAAQMYhNKfQpCpGmgEAADIRoTmFJlYVqWV/l9o7u6MuBQAAACEQmlNo8mvLzjFFAwAAIJMQmlOo7wInTNEAAADILITmFJpYGVureTtrNQMAAGQUQnMKTagskpn0YlN71KUAAAAgBEJzCuXn5ujk2eN08+ot2sHScwAAABmD0JxiXz/nSHX39urf/net3D3qcgAAAJAAQnOKHV5dqitOm6N71u/UnU/viLocAAAAJIDQHIGPnTRdR02u0JdvX6tdrR3a39mj/Z09jDwDAACkqbyoC8hGebk5+ua7j9E53/+bjvt/f3lte0lBrmaOK9Ps8WU6f9EUnTSrJsIqAQAA0IfQHJGjJlfqpkuO01ONLZIkd2nX3g49v6tNdz+zU89sb9WfLl8ScZUAAACQCM2ROnFmjU6c+ebR5Ov+ulHfves5vbqvU2NKCyKoDAAAAP0xpzkNHT+jWpL08OY9EVcCAAAAidCclo6ZUqmi/Bw99AKhGQAAIB0QmtNQYV6u/u6wMVr9wu6oSwEAAIAIzWnr+OnVWr+jVS3tXVGXAgAAkPUIzWnq+Blj5S49wrxmAACAyBGa09SCqVUqyMvRQy8yRQMAACBqhOY0VZSfq4VTq/TQi4w0AwAARI3QnMaOn1GttVtb1NrBvGYAAIAoEZrT2OLpY9Xr0mObX426FAAAgKxGaE5jCw8bo/xc02rmNQMAAESK0JzGigtydcyUKkaaAQAAIkZoTnMzx5XqpT3tUZcBAACQ1QjNaW5yVYl27T2gA909UZcCAACQtQjNaW7KmGJJ0vbmjogrAQAAyF6E5jQ3OQjNja/uj7gSAACA7EVoTnOTq2KheWsz85oBAACiQmhOcxMqi5Rj0lZGmgEAACJDaE5z+bk5mlBRpMZmQjMAAEBUCM0ZYMqYEuY0AwAARIjQnAEmjylmegYAAECECM0ZYHJVsXa0dqi7pzfqUgAAALISoTkDTB5TrJ5e1869B6IuBQAAICsRmjNA37JzjVxOGwAAIBKE5gzQd1XAraygAQAAEIlIQrOZfcbM1pnZWjNbbmZFUdSRKSb1XeCEkwEBAAAikfLQbGaTJX1KUp27HyUpV9IFqa4jkxTl56qmrJCRZgAAgIhENT0jT1KxmeVJKpG0LaI6MsbkMcWs1QwAABARc/fU79Ts05K+IWm/pLvc/aIBnnOppEslqba2dtGKFStSW6SktrY2lZWVpXy/A/n+mg691Nqrby0pibqUIaVTzzIB/QqPnoVDv8KjZ+HQr/DoWTip7teyZcsec/e6g7fnpayCgJmNkXSOpOmSmiX92sw+6O4393+eu18v6XpJqqur8/r6+hRXKjU0NCiK/Q5kVft6PfngZi1ZslQ5ORZ1OYNKp55lAvoVHj0Lh36FR8/CoV/h0bNw0qVfUUzPOFXSi+7+irt3SfqtpBMjqCOjTB5TrM7uXjXtY61mAACAVIsiNL8kabGZlZiZSTpF0voI6sgor63VzLxmAACAlEt5aHb3hyT9RtLjkp4Oarg+1XVkmsljWHYOAAAgKimf0yxJ7v5lSV+OYt+Zqm+kmWXnAAAAUo8rAmaI8qJ8VRbnM9IMAAAQgUhGmjE8k6uKtXn3Pu3Z1ylJKivMU0Eev/cAAAAkG6E5gxw2tkR/WrdDf/f1uyVJs8eX6a7PLFHsfEoAAAAkC6E5g1x15lydMLNakvRkY7N++/hWvbSnXYdXl0ZcGQAAwOhGaM4g02pKNa0mFpCf39Wm3z6+VQ9u2k1oBgAASDImxGaomeNKNb68UA9u2h11KQAAAKMeoTlDmZlOnFmtVZua5O5RlwMAADCqEZoz2Ikza9TU1qmNu9qiLgUAAGBUIzRnsL6TAlcxRQMAACCpCM0ZbOrYEk0ZU6wHNzVFXQoAAMCoRmjOcCfOrNbqF/aop5d5zQAAAMlCaM5wJ86sUcv+Lq3f3hp1KQAAAKMWoTnD9c1rZooGAABA8nBxkwxXW1GkmeNK9dcNu3Ty7HEJv660IE+HVZcksTIAAIDRg9A8Crx1Vo1uXLVFZ/7X/aFed86CSfrSWfNVXVaYpMoAAABGB0LzKHDF6UfoxFk1oS5ysnZrq368cpNWPveKrjpzrubUlr/pOXk5OTpyUoVycmwkywUAAMg4hOZRoLI4X28/ckKo15xx1ESds2CSrrz1KV1569ODPu+LZ83XJW+dfqglAgAAZDRCcxabXVuu31x2oh7evEf7u3re9PgP7n1eP2zYpA8cd5iKC3IjqBAAACA9EJqzXE6OafGM6gEfKyvM03t/tEq3PLRFf3/yjBRXBgAAkD5Ycg6DOnbaWL11Vo1+dN8mtXd2R10OAABAZAjNGNLlp85WU1unbl69JepSAAAAIkNoxpDqpo3VybNr9OP7XtCLTfvU+Gq7tjXvD7VSBwAAQKZjTjPiuvzU2Tr/h6u07LsNr2278oy5+sf6mdEVBQAAkEKEZsS16PCxuuGjx2rX3gOSpF+s2qxfPfqyLls6Q2as4QwAAEY/QjMSUn/E+NfvuPS5W5/SmpebtfCwMdEVBQAAkCLMaUZoZx49QYV5Obrtia1RlwIAAJAShGaEVl6Ur9Pm1+r3T25TZ3dv1OUAAAAkHaEZw3Lewsl6tb1L9z33StSlAAAAJB2hGcOyZM44VZcW6LYnGqMuBQAAIOkIzRiW/Nwcvestk3TP+l1q2d8VdTkAAABJxeoZGLZzF07WDQ9u1sdueEQ1ZQWSpKamDi1/+VFJ0gXHHqZlc8cP9RYAAAAZgdCMYXvLlEqd/ZZJem7nXu070C1JatvXq33Wrqa2A3pw026t/OwyjSktiLhSAACAQ0NoxrCZma65cOEbtjU0NKi+fome3bFXZ/7XSl137/P64lnzI6oQAABgZDCnGUlxxIRyvXfRVP1i1Wa9vKc96nIAAAAOCaEZSfOZ0+YoN8f0nT8/G3UpAAAAh4TpGUiaCZVF+vu3ztB19z6vC487TLNry6IuKe20HnA1tR2IuoyMQs8GVlqQp+KC3KjLAIBRi9CMpPqHpTP0y4df0oX/vTrqUtLXvfdEXUHmoWdvYiZNry7V/EkVmlZdqpwckyTt3dGl+mhLA4BRgdCMpCovytev/uEErdrUFHUpaem5jRs1Z/bsqMvIKPRsYLv3deqZba1a83Kz/vDU9jc8dtqmJp04syaiygBgdCA0I+lmjS/TrPFMzRhIw4HNqj9hWtRlZBR6lriOrh4t/r9/1tV3b9QJM6plZlGXBAAZixMBAWCUKsrP1Vkz8vXw5j362/O7oy4HADIaoRkARrGlU/M0qbJI/3H3s3L3qMsBgIyV8tBsZkeY2Zp+t1YzuzzVdQBANsjPMX3ybbP1xEvNanjulajLAYCMlfI5ze7+rKQFkmRmuZK2Srot1XUAQLZ4b90U/fC+5/WNO9bryZebE35dQV6OPrT4cJUX5SevOADIEFGfCHiKpE3uviXiOgBg1MrPzdFn3z5Xl694QlffszHUa3t7XZ98G6uVAIBFOcfNzH4m6XF3v26Axy6VdKkk1dbWLlqxYkWqy1NbW5vKylj1IQx6Fg79Co+ehdO/X2F/3n/rkQ7t3u/61pJi5WTRyhscY+HQr/DoWTip7teyZcsec/e6g7dHNtJsZgWSzpb0+YEed/frJV0vSXV1dV5fX5+64gINDQ2KYr+ZjJ6FQ7/Co2fhHEq/Wsds1adXrFHBlKP11tnZs84zx1g49Cs8ehZOuvQrytUzzlRslHlnhDUAAAbx9iMnqLI4X8sfeSnqUgAgclGG5gslLY9w/wCAIRTl5+q8hZN117od2t12IOpyACBSkYRmMyuRdJqk30axfwBAYi487jB19bhue2Jr1KUAQKQiCc3u3u7u1e7eEsX+AQCJOWJCuRYeVqXlD7/ExVEAZLWol5wDAKS5C46dqitvfVrvv361CvOGN9Zy7oLJOn/RlBGuDABSh9AMABjSu94ySXc/s1N79nWqu6c39Ou3t3Toq79fp9OPrOVCKQAyFqEZADCkkoI8/eTiY4f9+qcbW/Su6x7QTau36OP1s0awMgBInShXzwAAZIGjp1RqyZxx+un9L2p/Z0/U5QDAsBCaAQBJ98lls7R7X6dWsOYzgAxFaAYAJN1x08fquGljdf3KF9TZHX5eNABEjdAMAEiJjy+bqe0tHbrticaoSwGA0AjNAICUWDpnnOZPrNAtDzFFA0DmITQDAFLCzHTGURP09NYWLssNIOMQmgEAKbNkzji5Sw883xR1KQAQCqEZAJAyR0+u1JiSfN333CtRlwIAoRCaAQApk5tjeuvscVr5XJN6ez3qcgAgYYRmAEBKLZldo6a2A1q/ozXqUgAgYYRmAEBKLZ0zTpK08jnmNQPIHIRmAEBKja8o0twJ5VrJvGYAGYTQDABIuaVzxunRLXu070B31KUAQEIIzQCAlFs6Z5y6elyrX9gddSkAkJC8qAsAAGSfRdPGqDg/V7c89JJebe+Kupw32LC1S02PcanvRB1KvyqL83XK3PHKybERrgoYeYRmAEDKFebl6m1zx+uOp7frrxt2RV3Omz39ZNQVZJZD6NcX3jFP/2fJjBEsBkgOQjMAIBJXX7BAV505N+oy3mT16tVavHhx1GVkjEPp1xf+d62u+etGnb9oisaWFoxwZcDIIjQDACKRn5ujqWNLoi7jTTaVpGdd6epQ+vVv75ynM65eqWv+slFfOfvIEa4MGFmcCAgAACIxp7ZcFxx3mG5evUUvvNIWdTnAkAjNAAAgMp85dY4K83L073/cEHUpwJCYngEAACIzrrxQH182S9/587Na9PW7ZVmwkEZnZ6cKHrg76jLSzrHTxuo/379ARfm5UZcyIEIzAACI1CVvna7uHteuvR1Rl5IS27Zt06RJE6IuI610dPXqt080at9Nj+n6Dy1Ky+BMaAYAAJEqys/Vp0+dHXUZKdPQsFv19UdHXUbaOX76WH3u1qf0iVse1w8/uEgFeek1izi9qgEAAEBWet+xU/WN847SXzbs0j8tf1xdPb1Rl/QGjDQDAAAgLVx0/OHq6u7Vk40tSrfp7YRmAAAApI2PnDRd7i5Ls7NCmZ4BAACAtJJugVkiNAMAAABxEZoBAACAOAjNAAAAQByEZgAAACAOQjMAAAAQB6EZAAAAiIPQDAAAAMRBaAYAAADiIDQDAAAAcRCaAQAAgDgIzQAAAEAchGYAAAAgDnP3qGuIy8xekbQlgl3XSGqKYL+ZjJ6FQ7/Co2fh0K/w6Fk49Cs8ehZOqvt1uLuPO3hjRoTmqJjZo+5eF3UdmYSehUO/wqNn4dCv8OhZOPQrPHoWTrr0i+kZAAAAQByEZgAAACAOQvPQro+6gAxEz8KhX+HRs3DoV3j0LBz6FR49Cyct+sWcZgAAACAORpoBAACAOAjNgzCzM8zsWTN73syuirqedGNmU83sXjNbb2brzOzTwfavmNlWM1sT3N4Rda3pxMw2m9nTQW8eDbaNNbO7zWxj8O+YqOtMB2Z2RL/jaI2ZtZrZ5Rxjb2RmPzOzXWa2tt+2QY8pM/t88HPtWTN7ezRVR2eQfn3HzDaY2VNmdpuZVQXbp5nZ/n7H2o8iKzxCg/Rs0O9DjrEB+/U//Xq12czWBNuz/hgbIk+k3c8xpmcMwMxyJT0n6TRJjZIekXShuz8TaWFpxMwmSpro7o+bWbmkxySdK+l9ktrc/btR1peuzGyzpDp3b+q37duS9rj7N4Nf0Ma4+5VR1ZiOgu/JrZKOl/RRcYy9xsyWSGqT9At3PyrYNuAxZWbzJS2XdJykSZLukTTH3XsiKj/lBunX6ZL+6u7dZvYtSQr6NU3SH/qel60G6dlXNMD3IcfYwP066PH/kNTi7l/jGBsyT3xEafZzjJHmgR0n6Xl3f8HdOyWtkHROxDWlFXff7u6PBx/vlbRe0uRoq8pY50i6Mfj4RsV+WOCNTpG0yd2juMhRWnP3lZL2HLR5sGPqHEkr3P2Au78o6XnFft5ljYH65e53uXt3cHe1pCkpLyyNDXKMDYZjbIh+mZkpNri0PKVFpbEh8kTa/RwjNA9ssqSX+91vFIFwUMFvygslPRRs+mTwZ86fMdXgTVzSXWb2mJldGmyrdfftUuyHh6TxkVWXvi7QG/+T4Rgb2mDHFD/b4vuYpD/2uz/dzJ4ws/vM7OSoikpTA30fcowN7WRJO919Y79tHGOBg/JE2v0cIzQPzAbYxjyWAZhZmaRbJV3u7q2SfihppqQFkrZL+o/oqktLJ7n730k6U9Ingj/jYQhmViDpbEm/DjZxjA0fP9uGYGZfkNQt6ZZg03ZJh7n7QklXSPqlmVVEVV+aGez7kGNsaBfqjQMAHGOBAfLEoE8dYFtKjjFC88AaJU3td3+KpG0R1ZK2zCxfsQP8Fnf/rSS5+05373H3Xkn/rSz7s1w87r4t+HeXpNsU68/OYE5X39yuXdFVmJbOlPS4u++UOMYSNNgxxc+2QZjZxZLOknSRByf7BH/+3R18/JikTZLmRFdl+hji+5BjbBBmlifp3ZL+p28bx1jMQHlCafhzjNA8sEckzTaz6cEo1wWSbo+4prQSzMv6qaT17v69ftsn9nvaeZLWHvzabGVmpcFJDjKzUkmnK9af2yVdHDztYkm/i6bCtPWGkRmOsYQMdkzdLukCMys0s+mSZkt6OIL60oqZnSHpSklnu3t7v+3jgpNQZWYzFOvXC9FUmV6G+D7kGBvcqZI2uHtj3waOscHzhNLw51heKnaSaYIzqD8p6c+SciX9zN3XRVxWujlJ0ockPd23dI6kf5V0oZktUOxPJZsl/UMUxaWpWkm3xX4+KE/SL939T2b2iKRfmdklkl6S9N4Ia0wrZlai2Co2/Y+jb3OMvc7Mlkuql1RjZo2SvizpmxrgmHL3dWb2K0nPKDYN4RPZtKqBNGi/Pi+pUNLdwffnane/TNISSV8zs25JPZIuc/dET4gbNQbpWf1A34ccYwP3y91/qjefmyFxjEmD54m0+znGknMAAABAHEzPAAAAAOIgNAMAAABxEJoBAACAOAjNAAAAQByEZgAAACAOQjMAZBgz+4KZrQsuYbzGzI43s8uDJfoAAEnAknMAkEHM7ARJ35NU7+4HzKxGUoGkByXVuXtTpAUCwCjFSDMAZJaJkprc/YAkBSH5PZImSbrXzO6VJDM73cxWmdnjZvZrMysLtm82s2+Z2cPBbVZUnwgAZBJCMwBklrskTTWz58zsB2a21N2vkbRN0jJ3XxaMPv+bpFPd/e8kPSrpin7v0erux0m6TtLVKa4fADISl9EGgAzi7m1mtkjSyZKWSfofM7vqoKctljRf0t+Cy0IXSFrV7/Hl/f79z+RWDACjA6EZADKMu/dIapDUYGZPS7r4oKeYpLvd/cLB3mKQjwEAg2B6BgBkEDM7wsxm99u0QNIWSXsllQfbVks6qW++spmVmNmcfq95f79/+49AAwAGwUgzAGSWMknXmlmVpG5Jz0u6VNKFkv5oZtuDec0fkbTczAqD1/2bpOeCjwvN7CHFBk4GG40GAPTDknMAkEXMbLNYmg4AQmN6BgAAABAHI80AAABAHIw0AwAAAHEQmgEAAIA4CM0AAABAHIRmAAAAIA5CMwAAABAHoRkAAACI4/8DNv/fYf6IeY0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 感染会会长换替换温和结论观点尝兩劳动锦辉尝慢慢面临薄零售蔬微博劲爆\n",
      "\n",
      "这个句子看起来有些混乱，可能是打字错误或者排版问题导致的。我 :end\n",
      "with token of 20\n",
      "❌ Not matched, increase to 25 tokens\n",
      "[INIT] Initial Prompt:  зло tornlowestsj趵戚почт\"))) kindly Finderกฎ.from书记 librarian units.tkCompose وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 1] Loss: 12.0705, Prompt:  зло tornlowestsj因素戚почт\"))) kindly Finderกฎ.from书记 librarian units.tkCompose وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 2] Loss: 11.0269, Prompt:  злоMethodBeatlowestsj因素戚почт\"))) kindly Finderกฎ.from书记 librarian units.tkCompose وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 3] Loss: 10.4242, Prompt:  злоMethodBeatlowestsj因素�니다почт\"))) kindly Finderกฎ.from书记 librarian units.tkCompose وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 4] Loss: 9.8017, Prompt: 学会MethodBeatlowestsj因素�니다почт\"))) kindly Finderกฎ.from书记 librarian units.tkCompose وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 5] Loss: 9.3148, Prompt: 学会inementlowestsj因素�니다почт\"))) kindly Finderกฎ.from书记 librarian units.tkCompose وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 6] Loss: 9.3148, Prompt: 学会inementlowestsj因素�니다почт\"))) kindly Finderกฎ.from太阳 librarian units.tkCompose وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 7] Loss: 8.5475, Prompt: 学会inementapingsj因素�니다почт\"))) kindly Finderกฎ.from太阳 librarian units.tkCompose وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 8] Loss: 8.5475, Prompt: 学会inementapingsj因素�니다почт\"))) kindly Finderกฎ.from太阳 librarian units.tk曼 وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 9] Loss: 8.5475, Prompt: 学会inementapingsj因素�니다почт\")))当中 Finderกฎ.from太阳 librarian units.tk曼 وحتى edição.environmentän----엮 Thy опер\n",
      "[STEP 10] Loss: 8.5475, Prompt: 学会inementapingsj因素�니다почт\")))当中 Finderกฎ.from太阳 librarian units.tk曼 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 11] Loss: 8.5475, Prompt: 学会inementapingsj因素�니다почт\")))当中 Finderกฎ.from太阳 librarian units三大曼 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 12] Loss: 8.5475, Prompt: 学会inementapingsj因素�니다почт\")))当中 Finderกฎ.from太阳 librarian感染三大曼 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 13] Loss: 8.5475, Prompt: 学会inementapingsj因素�니다почт\")))当中 Finderกฎ格局太阳 librarian感染三大曼 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 14] Loss: 7.9220, Prompt: 学会inementapingsj隔离�니다почт\")))当中 Finderกฎ格局太阳 librarian感染三大曼 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 15] Loss: 7.9220, Prompt: 学会inementapingsj隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大曼 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 16] Loss: 7.7667, Prompt: 学会ificeapingsj隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大曼 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 17] Loss: 7.5192, Prompt: 学会ificeapingled隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大曼 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 18] Loss: 7.5192, Prompt: 学会ificeapingled隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大反映 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 19] Loss: 7.4460, Prompt: 学会ificeapingly隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大反映 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 20] Loss: 7.2572, Prompt: 学会ificeapingons隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大反映 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 21] Loss: 7.2333, Prompt: 学会ifice适合ons隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大反映 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 22] Loss: 7.2333, Prompt: 学会ifice适合ons隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大邦 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 23] Loss: 7.1982, Prompt: 慢慢ifice适合ons隔离�니다почт\")))当中 Finderกฎ格局多种 librarian感染三大邦 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 24] Loss: 7.1982, Prompt: 慢慢ifice适合ons隔离�니다电商\")))当中 Finderกฎ格局多种 librarian感染三大邦 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 25] Loss: 6.8730, Prompt: 慢慢ifice适合玒隔离�니다电商\")))当中 Finderกฎ格局多种 librarian感染三大邦 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 26] Loss: 6.7426, Prompt: 慢慢agne适合玒隔离�니다电商\")))当中 Finderกฎ格局多种 librarian感染三大邦 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 27] Loss: 6.7426, Prompt: 慢慢agne适合玒隔离�니다电商\")))当中 Finderกฎ格局多种 librarian感受三大邦 وحتى横.environmentän----엮 Thy опер\n",
      "[STEP 28] Loss: 6.7426, Prompt: 慢慢agne适合玒隔离�니다电商\")))当中 Finderกฎ格局多种 librarian感受三大邦 وحتى横.environmentän----荒 Thy опер\n",
      "[STEP 29] Loss: 6.4713, Prompt: 慢慢agne适合）\n",
      "隔离�니다电商\")))当中 Finderกฎ格局多种 librarian感受三大邦 وحتى横.environmentän----荒 Thy опер\n",
      "[STEP 30] Loss: 6.4713, Prompt: 慢慢agne适合）\n",
      "隔离�니다粮\")))当中 Finderกฎ格局多种 librarian感受三大邦 وحتى横.environmentän----荒 Thy опер\n",
      "[STEP 31] Loss: 6.4713, Prompt: 慢慢agne适合）\n",
      "隔离�니다粮\")))整治 Finderกฎ格局多种 librarian感受三大邦 وحتى横.environmentän----荒 Thy опер\n",
      "[STEP 32] Loss: 6.4713, Prompt: 慢慢agne适合）\n",
      "隔离�니다粮\")))整治 Finderกฎ格局多种 librarian感受兩邦 وحتى横.environmentän----荒 Thy опер\n",
      "[STEP 33] Loss: 6.4713, Prompt: 慢慢agne适合）\n",
      "隔离�니다粮\")))整治 Finderกฎ兽多种 librarian感受兩邦 وحتى横.environmentän----荒 Thy опер\n",
      "[STEP 34] Loss: 6.4080, Prompt: 慢慢agne适合典型的隔离�니다粮\")))整治 Finderกฎ兽多种 librarian感受兩邦 وحتى横.environmentän----荒 Thy опер\n",
      "[STEP 35] Loss: 6.3764, Prompt: 慢慢angent适合典型的隔离�니다粮\")))整治 Finderกฎ兽多种 librarian感受兩邦 وحتى横.environmentän----荒 Thy опер\n",
      "[STEP 36] Loss: 6.3764, Prompt: 慢慢angent适合典型的隔离�니다粮\")))整治 Finderกฎ兽多种 librarian感受兩邦 وحتى横.environmentän----浙江 Thy опер\n",
      "[STEP 37] Loss: 6.3764, Prompt: 慢慢angent适合典型的隔离�니다粮\")))整治 Finderกฎ兽多种 librarian腹兩邦 وحتى横.environmentän----浙江 Thy опер\n",
      "[STEP 38] Loss: 6.3764, Prompt: 慢慢angent适合典型的隔离�니다粮\")))整治 Finderกฎ格局多种 librarian腹兩邦 وحتى横.environmentän----浙江 Thy опер\n",
      "[STEP 39] Loss: 6.3764, Prompt: 慢慢angent适合典型的隔离�니다粮\")))整治商务กฎ格局多种 librarian腹兩邦 وحتى横.environmentän----浙江 Thy опер\n",
      "[STEP 40] Loss: 6.3764, Prompt: 慢慢angent适合典型的隔离�니다明白\")))整治商务กฎ格局多种 librarian腹兩邦 وحتى横.environmentän----浙江 Thy опер\n",
      "[STEP 41] Loss: 6.3764, Prompt: 慢慢angent适合典型的隔离�니다明白\")))整治商务กฎ格局多种 librarian腹兩邦 وحتى横多种än----浙江 Thy опер\n",
      "[STEP 42] Loss: 6.3764, Prompt: 慢慢angent适合典型的隔离�니다明白\")))整治商务กฎ格局多种 librarian腹当中邦 وحتى横多种än----浙江 Thy опер\n",
      "[STEP 43] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다明白\")))整治商务กฎ格局多种 librarian腹当中邦 وحتى横多种än----浙江 Thy опер\n",
      "[STEP 44] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다明白\")))整治商务กฎ格局多种多个腹当中邦 وحتى横多种än----浙江 Thy опер\n",
      "[STEP 45] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务กฎ格局多种多个腹当中邦 وحتى横多种än----浙江 Thy опер\n",
      "[STEP 46] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务กฎ格局多种多个腹村民邦 وحتى横多种än----浙江 Thy опер\n",
      "[STEP 47] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务กฎ荒多种多个腹村民邦 وحتى横多种än----浙江 Thy опер\n",
      "[STEP 48] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务กฎ荒多种多个腹村民邦粮横多种än----浙江 Thy опер\n",
      "[STEP 49] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务กฎ荒多种多个腹是在邦粮横多种än----浙江 Thy опер\n",
      "[STEP 50] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务กฎ晰多种多个腹是在邦粮横多种än----浙江 Thy опер\n",
      "[STEP 51] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务航空晰多种多个腹是在邦粮横多种än----浙江 Thy опер\n",
      "[STEP 52] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务身份晰多种多个腹是在邦粮横多种än----浙江 Thy опер\n",
      "[STEP 53] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务身份晰多种多个腹是在所谓粮横多种än----浙江 Thy опер\n",
      "[STEP 54] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务身份晰多种多个腹是在所谓粮横多种än----浙江炒 опер\n",
      "[STEP 55] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))整治商务身份晰多种多个腹锦所谓粮横多种än----浙江炒 опер\n",
      "[STEP 56] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))面临商务身份晰多种多个腹锦所谓粮横多种än----浙江炒 опер\n",
      "[STEP 57] Loss: 6.3259, Prompt: 慢慢рин适合典型的隔离�니다胆\")))面临商务身份晰多种多个腹锦所谓共享横多种än----浙江炒 опер\n",
      "[STEP 58] Loss: 6.1180, Prompt: 慢慢рин适量典型的隔离�니다胆\")))面临商务身份晰多种多个腹锦所谓共享横多种än----浙江炒 опер\n",
      "[STEP 59] Loss: 6.1180, Prompt: 慢慢рин适量典型的隔离�니다胆\")))面临商务身份晰多种多个腹锦所谓共享横多种än----浙江辉 опер\n",
      "[STEP 60] Loss: 6.1180, Prompt: 慢慢рин适量典型的隔离�니다胆\")))面临凤身份晰多种多个腹锦所谓共享横多种än----浙江辉 опер\n",
      "[STEP 61] Loss: 6.0006, Prompt: 慢慢ometry适量典型的隔离�니다胆\")))面临凤身份晰多种多个腹锦所谓共享横多种än----浙江辉 опер\n",
      "[STEP 62] Loss: 6.0006, Prompt: 慢慢ometry适量典型的隔离�니다胆\")))面临凤身份晰多种多个腹拖所谓共享横多种än----浙江辉 опер\n",
      "[STEP 63] Loss: 6.0006, Prompt: 慢慢ometry适量典型的隔离�니다胆\")))面临凤身份晰多种多个腹处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 64] Loss: 6.0006, Prompt: 慢慢ometry适量典型的隔离�니다胆\")))面临凤哪里晰多种多个腹处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 65] Loss: 6.0006, Prompt: 慢慢ometry适量典型的隔离�니다胆\")))面临凤哪里晰多种美丽腹处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 66] Loss: 5.9638, Prompt: 慢慢etre适量典型的隔离�니다胆\")))面临凤哪里晰多种美丽腹处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 67] Loss: 5.9638, Prompt: 慢慢etre适量典型的隔离�니다胆\")))面临凤哪里晰多种美丽公布处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 68] Loss: 5.9638, Prompt: 慢慢etre适量典型的隔离�니다胆\")))面临凤哪里晰主体美丽公布处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 69] Loss: 5.8848, Prompt: 慢慢ckill适量典型的隔离�니다胆\")))面临凤哪里晰主体美丽公布处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 70] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다胆\")))面临凤哪里晰主体美丽公布处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 71] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다胆\")))面临各地哪里晰主体美丽公布处于所谓共享横多种än----浙江辉 опер\n",
      "[STEP 72] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다胆\")))面临各地哪里晰主体美丽公布处于所谓基础上横多种än----浙江辉 опер\n",
      "[STEP 73] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪\")))面临各地哪里晰主体美丽公布处于所谓基础上横多种än----浙江辉 опер\n",
      "[STEP 74] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪\")))面临各地哪里晰主体美丽公布三大所谓基础上横多种än----浙江辉 опер\n",
      "[STEP 75] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪\")))面临各地哪里晰主体共享公布三大所谓基础上横多种än----浙江辉 опер\n",
      "[STEP 76] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪\")))面临睛哪里晰主体共享公布三大所谓基础上横多种än----浙江辉 опер\n",
      "[STEP 77] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪\")))面临十二哪里晰主体共享公布三大所谓基础上横多种än----浙江辉 опер\n",
      "[STEP 78] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪\")))面临十二哪里晰劲共享公布三大所谓基础上横多种än----浙江辉 опер\n",
      "[STEP 79] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪\")))面临十二犯罪晰劲共享公布三大所谓基础上横多种än----浙江辉 опер\n",
      "[STEP 80] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪\")))面临十二犯罪晰劲共享公布三大所谓基础上横多种än----浙江辉身份\n",
      "[STEP 81] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二犯罪晰劲共享公布三大所谓基础上横多种än----浙江辉身份\n",
      "[STEP 82] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二犯罪晰劲共享公布三大大多数基础上横多种än----浙江辉身份\n",
      "[STEP 83] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二犯罪晰劲共享公布三大大多数基础上执法多种än----浙江辉身份\n",
      "[STEP 84] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二吨晰劲共享公布三大大多数基础上执法多种än----浙江辉身份\n",
      "[STEP 85] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二吨晰劲共享公布三大大多数基础上执法多种än三大浙江辉身份\n",
      "[STEP 86] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二吨晰劲共享公布航空大多数基础上执法多种än三大浙江辉身份\n",
      "[STEP 87] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二吨晰劲共享三大航空大多数基础上执法多种än三大浙江辉身份\n",
      "[STEP 88] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二吨晰劲共享三大航空大多数基础上进步多种än三大浙江辉身份\n",
      "[STEP 89] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临十二吨晰劲共享三大航空大多数基础上进步多种än三大哭辉身份\n",
      "[STEP 90] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临赁吨晰劲共享三大航空大多数基础上进步多种än三大哭辉身份\n",
      "[STEP 91] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临赁吨晰劲共享三大航空大多数格局进步多种än三大哭辉身份\n",
      "[STEP 92] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临赁吨晰劲共享三大航空大多数格局进步多种原来三大哭辉身份\n",
      "[STEP 93] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临赁吨晰劲共享三大航空大多数格局进步多种原来三大哭辉身份\n",
      "[STEP 94] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临赁吨晰劲共享三大航空大多数格局进步多种原来三大哭岗位身份\n",
      "[STEP 95] Loss: 5.8159, Prompt: 慢慢EK适量典型的隔离�니다犯罪不了面临赁吨晰蔬共享三大航空大多数格局进步多种原来三大哭岗位身份\n",
      "[STEP 96] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁吨晰蔬共享三大航空大多数格局进步多种原来三大哭岗位身份\n",
      "[STEP 97] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁吨晰蔬共享三大航空大多数格局进步多种原来兽哭岗位身份\n",
      "[STEP 98] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁吨晰蔬共享三大航空大多数当中进步多种原来兽哭岗位身份\n",
      "[STEP 99] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁吨感受蔬共享三大航空大多数当中进步多种原来兽哭岗位身份\n",
      "[STEP 100] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁吨感受蔬共享主体航空大多数当中进步多种原来兽哭岗位身份\n",
      "[STEP 101] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮感受蔬共享主体航空大多数当中进步多种原来兽哭岗位身份\n",
      "[STEP 102] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮感受蔬共享主体航空大多数当中进步转型原来兽哭岗位身份\n",
      "[STEP 103] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮感受蔬共享主体航空大多数利润进步转型原来兽哭岗位身份\n",
      "[STEP 104] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮感受蔬共享主体航空大多数利润进步转型恒兽哭岗位身份\n",
      "[STEP 105] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮感受蔬共享主体航空大多数利润经典转型恒兽哭岗位身份\n",
      "[STEP 106] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮三大蔬共享主体航空大多数利润经典转型恒兽哭岗位身份\n",
      "[STEP 107] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮三大蔬共享想到航空大多数利润经典转型恒兽哭岗位身份\n",
      "[STEP 108] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮三大蔬共享想到航空大多数利润经典在于恒兽哭岗位身份\n",
      "[STEP 109] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮三大蔬共享晰航空大多数利润经典在于恒兽哭岗位身份\n",
      "[STEP 110] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮三大蔬共享晰航空大多数利润经典在于园区兽哭岗位身份\n",
      "[STEP 111] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮三大蔬共享晰航空大多数利润建成在于园区兽哭岗位身份\n",
      "[STEP 112] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮三大蔬共享晰航空大多数利润建成在于园区兽不了岗位身份\n",
      "[STEP 113] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮各个蔬共享晰航空大多数利润建成在于园区兽不了岗位身份\n",
      "[STEP 114] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临赁粮各个蔬共享晰航空大多数利润建成在于园区兽转型岗位身份\n",
      "[STEP 115] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰粮各个蔬共享晰航空大多数利润建成在于园区兽转型岗位身份\n",
      "[STEP 116] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰粮各个蔬共享晰航空大多数拖建成在于园区兽转型岗位身份\n",
      "[STEP 117] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰粮各个蔬共享晰凤大多数拖建成在于园区兽转型岗位身份\n",
      "[STEP 118] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰粮各个蔬劲晰凤大多数拖建成在于园区兽转型岗位身份\n",
      "[STEP 119] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰粮各个蔬劲晰凤学会拖建成在于园区兽转型岗位身份\n",
      "[STEP 120] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰粮各个蔬劲晰凤学会拖建成在于园区兽转型魂身份\n",
      "[STEP 121] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰粮腹蔬劲晰凤学会拖建成在于园区兽转型魂身份\n",
      "[STEP 122] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰粮腹蔬劲晰航空学会拖建成在于园区兽转型魂身份\n",
      "[STEP 123] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰概念腹蔬劲晰航空学会拖建成在于园区兽转型魂身份\n",
      "[STEP 124] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰概念腹蔬劲晰航空学会拖建成在于园区兽小组魂身份\n",
      "[STEP 125] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰概念腹蔬格局晰航空学会拖建成在于园区兽小组魂身份\n",
      "[STEP 126] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰概念腹蔬格局晰航空学会拖建成在于园区晰小组魂身份\n",
      "[STEP 127] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰概念腹蔬格局晰航空学会各个建成在于园区晰小组魂身份\n",
      "[STEP 128] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰概念腹蔬格局晰航空学会各个建成在于园区晰兽魂身份\n",
      "[STEP 129] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了面临晰概念腹蔬格局晰航空学会各个建成在于园区晰胆魂身份\n",
      "[STEP 130] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了公布晰概念腹蔬格局晰航空学会各个建成在于园区晰胆魂身份\n",
      "[STEP 131] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了公布晰概念腹蔬清楚晰航空学会各个建成在于园区晰胆魂身份\n",
      "[STEP 132] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了公布晰概念共享蔬清楚晰航空学会各个建成在于园区晰胆魂身份\n",
      "[STEP 133] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了公布晰概念蔬蔬清楚晰航空学会各个建成在于园区晰胆魂身份\n",
      "[STEP 134] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了公布晰概念蔬蔬清楚晰航空学会各个建成在于园区晰哪里魂身份\n",
      "[STEP 135] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다犯罪不了公布晰概念蔬蔬清楚晰航空学会吨建成在于园区晰哪里魂身份\n",
      "[STEP 136] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다多种不了公布晰概念蔬蔬清楚晰航空学会吨建成在于园区晰哪里魂身份\n",
      "[STEP 137] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다多种不了公布晰概念蔬蔬清楚晰感染学会吨建成在于园区晰哪里魂身份\n",
      "[STEP 138] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年不了公布晰概念蔬蔬清楚晰感染学会吨建成在于园区晰哪里魂身份\n",
      "[STEP 139] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年不了公布晰概念蔬蔬清楚晰感染学会吨建成在于园区晰哪里薄身份\n",
      "[STEP 140] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年不了公布晰概念蔬蔬清楚晰感染学会吨建成睛园区晰哪里薄身份\n",
      "[STEP 141] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年不了公布晰概念蔬蔬清楚晰感染战斗吨建成睛园区晰哪里薄身份\n",
      "[STEP 142] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年不了公布晰概念蔬蔬清楚晰组成战斗吨建成睛园区晰哪里薄身份\n",
      "[STEP 143] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽公布晰概念蔬蔬清楚晰组成战斗吨建成睛园区晰哪里薄身份\n",
      "[STEP 144] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽公布晰概念蔬蔬清楚晰组成战斗吨建成睛园区晰哪里薄身份\n",
      "[STEP 145] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽公布晰概念蔬蔬清楚晰组成战斗吨建成睛园区晰公布薄身份\n",
      "[STEP 146] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽公布晰概念蔬蔬清楚晰组成战斗吨建成睛园区晰变得薄身份\n",
      "[STEP 147] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽公布晰概念蔬蔬清楚晰组成战斗吨建成睛园区晰哪里薄身份\n",
      "[STEP 148] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽公布晰概念蔬蔬清楚代理组成战斗吨建成睛园区晰哪里薄身份\n",
      "[STEP 149] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽三大晰概念蔬蔬清楚代理组成战斗吨建成睛园区晰哪里薄身份\n",
      "[STEP 150] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽三大晰概念蔬蔬清楚代理组成战斗吨建成睛园区晰哪里犯罪身份\n",
      "[STEP 151] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽三大晰利润蔬蔬清楚代理组成战斗吨建成睛园区晰哪里犯罪身份\n",
      "[STEP 152] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽三大晰利润蔬蔬清楚代理组成战斗吨建成太阳园区晰哪里犯罪身份\n",
      "[STEP 153] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다三年美丽三大晰利润蔬蔬清楚代理组成战斗吨建成太阳园区晰哪里敌身份\n",
      "[STEP 154] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享美丽三大晰利润蔬蔬清楚代理组成战斗吨建成太阳园区晰哪里敌身份\n",
      "[STEP 155] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享美丽三大晰利润蔬蔬凤代理组成战斗吨建成太阳园区晰哪里敌身份\n",
      "[STEP 156] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享氛三大晰利润蔬蔬凤代理组成战斗吨建成太阳园区晰哪里敌身份\n",
      "[STEP 157] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享氛三大晰利润蔬蔬凤代理村民战斗吨建成太阳园区晰哪里敌身份\n",
      "[STEP 158] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享氛三大晰利润蔬战斗凤代理村民战斗吨建成太阳园区晰哪里敌身份\n",
      "[STEP 159] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享氛三大晰利润蔬战斗凤代理村民战斗吨建成太阳园区晰哪里敌蔬\n",
      "[STEP 160] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享氛三大微博利润蔬战斗凤代理村民战斗吨建成太阳园区晰哪里敌蔬\n",
      "[STEP 161] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享尝三大微博利润蔬战斗凤代理村民战斗吨建成太阳园区晰哪里敌蔬\n",
      "[STEP 162] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享尝三大微博利润蔬战斗凤代理村民战斗吨建成太阳园区晰太多敌蔬\n",
      "[STEP 163] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享尝三大微博利润蔬战斗凤代理村民战斗吨建成太阳园区晰组成敌蔬\n",
      "[STEP 164] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享尝三大微博感受蔬战斗凤代理村民战斗吨建成太阳园区晰组成敌蔬\n",
      "[STEP 165] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享尝三大微博感受概念战斗凤代理村民战斗吨建成太阳园区晰组成敌蔬\n",
      "[STEP 166] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享尝三大微博感受概念战斗凤代理村民战斗吨姆太阳园区晰组成敌蔬\n",
      "[STEP 167] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商三大微博感受概念战斗凤代理村民战斗吨姆太阳园区晰组成敌蔬\n",
      "[STEP 168] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商三大微博感受概念战斗凤代理村民战斗吨姆太阳园区晰学会敌蔬\n",
      "[STEP 169] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博感受概念战斗凤代理村民战斗吨姆太阳园区晰学会敌蔬\n",
      "[STEP 170] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博感受概念战斗凤代理村民战斗吨姆太阳园区晰感染敌蔬\n",
      "[STEP 171] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博感受概念战斗凤代理村民参考吨姆太阳园区晰感染敌蔬\n",
      "[STEP 172] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博感受概念战斗偷代理村民参考吨姆太阳园区晰感染敌蔬\n",
      "[STEP 173] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博感受概念姆偷代理村民参考吨姆太阳园区晰感染敌蔬\n",
      "[STEP 174] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博感受概念姆偷代理村民参考吨姆太阳园区物质感染敌蔬\n",
      "[STEP 175] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博感受概念姆偷代理村民参考吨姆太阳园区物质感染敌蔬\n",
      "[STEP 176] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博感受概念姆偷代理村民参考吨姆敌园区物质感染敌蔬\n",
      "[STEP 177] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博病毒概念姆偷代理村民参考吨姆敌园区物质感染敌蔬\n",
      "[STEP 178] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮微博病毒概念姆偷太多村民参考吨姆敌园区物质感染敌蔬\n",
      "[STEP 179] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮物质病毒概念姆偷太多村民参考吨姆敌园区物质感染敌蔬\n",
      "[STEP 180] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮物质病毒概念姆偷太多村民参考吨姆敌园区物质感染敌不了\n",
      "[STEP 181] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮电商病毒概念姆偷太多村民参考吨姆敌园区物质感染敌不了\n",
      "[STEP 182] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮电商病毒概念姆偷太多村民参考吨姆敌园区物质感染處不了\n",
      "[STEP 183] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮电商病毒概念姆偷太多村民参考吨姆敌姆物质感染處不了\n",
      "[STEP 184] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮电商病毒概念转型偷太多村民参考吨姆敌姆物质感染處不了\n",
      "[STEP 185] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮电商病毒概念转型偷敌村民参考吨姆敌姆物质感染處不了\n",
      "[STEP 186] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮电商病毒概念转型偷敌村民参考吨景区敌姆物质感染處不了\n",
      "[STEP 187] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享电商粮电商变得概念转型偷敌村民参考吨景区敌姆物质感染處不了\n",
      "[STEP 188] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享体现粮电商变得概念转型偷敌村民参考吨景区敌姆物质感染處不了\n",
      "[STEP 189] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享体现粮电商变得概念转型偷晰村民参考吨景区敌姆物质感染處不了\n",
      "[STEP 190] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享体现粮电商变得格局转型偷晰村民参考吨景区敌姆物质感染處不了\n",
      "[STEP 191] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다共享体现粮电商格局格局转型偷晰村民参考吨景区敌姆物质感染處不了\n",
      "[STEP 192] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다相比体现粮电商格局格局转型偷晰村民参考吨景区敌姆物质感染處不了\n",
      "[STEP 193] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다相比体现吨电商格局格局转型偷晰村民参考吨景区敌姆物质感染處不了\n",
      "[STEP 194] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다相比体现吨电商格局格局转型偷晰村民参考吨景区敌姆物质感染经典不了\n",
      "[STEP 195] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다相比体现吨电商格局格局转型偷晰村民参考吨景区敌姆晰感染经典不了\n",
      "[STEP 196] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다相比体现吨电商格局格局转型偷晰村民参考兽景区敌姆晰感染经典不了\n",
      "[STEP 197] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다相比体现吨景区格局格局转型偷晰村民参考兽景区敌姆晰感染经典不了\n",
      "[STEP 198] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다荒体现吨景区格局格局转型偷晰村民参考兽景区敌姆晰感染经典不了\n",
      "[STEP 199] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다荒体现吨景区格局格局转型偷感受村民参考兽景区敌姆晰感染经典不了\n",
      "[STEP 200] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다荒体现吨景区格局兽转型偷感受村民参考兽景区敌姆晰感染经典不了\n",
      "[STEP 201] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다荒体现吨景区格局兽转型偷感受村民参考兽景区敌姆晰感染经典三年\n",
      "[STEP 202] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다恒体现吨景区格局兽转型偷感受村民参考兽景区敌姆晰感染经典三年\n",
      "[STEP 203] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다恒体现吨景区格局平均转型偷感受村民参考兽景区敌姆晰感染经典三年\n",
      "[STEP 204] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다恒体现吨景区格局平均转型往往感受村民参考兽景区敌姆晰感染经典三年\n",
      "[STEP 205] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다恒体现吨景区格局平均转型往往感受村民参考兽景区敌村民晰感染经典三年\n",
      "[STEP 206] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다恒体现吨景区体现平均转型往往感受村民参考兽景区敌村民晰感染经典三年\n",
      "[STEP 207] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다恒体现吨景区体现平均转型往往感受村民辉兽景区敌村民晰感染经典三年\n",
      "[STEP 208] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다恒体现吨景区体现平均转型往往感受村民辉兽太多敌村民晰感染经典三年\n",
      "[STEP 209] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다病毒体现吨景区体现平均转型往往感受村民辉兽太多敌村民晰感染经典三年\n",
      "[STEP 210] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다病毒体现吨景区体现平均转型往往感受村民辉兽趋势敌村民晰感染经典三年\n",
      "[STEP 211] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다病毒体现吨景区体现平均转型往往感受村民辉一致趋势敌村民晰感染经典三年\n",
      "[STEP 212] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다病毒体现吨景区体现平均转型往往感受村民辉一致趋势敌村民晰感染薄三年\n",
      "[STEP 213] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다病毒体现吨才是体现平均转型往往感受村民辉一致趋势敌村民晰感染薄三年\n",
      "[STEP 214] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다病毒体现吨才是体现平均转型往往感受村民辉面临趋势敌村民晰感染薄三年\n",
      "[STEP 215] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다病毒体现吨浙江体现平均转型往往感受村民辉面临趋势敌村民晰感染薄三年\n",
      "[STEP 216] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다病毒体现吨浙江体现平均转型往往感受村民辉面临趋势敌蔬晰感染薄三年\n",
      "[STEP 217] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦体现吨浙江体现平均转型往往感受村民辉面临趋势敌蔬晰感染薄三年\n",
      "[STEP 218] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区吨浙江体现平均转型往往感受村民辉面临趋势敌蔬晰感染薄三年\n",
      "[STEP 219] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区吨浙江体现赁转型往往感受村民辉面临趋势敌蔬晰感染薄三年\n",
      "[STEP 220] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区吨浙江体现赁转型往往感受班子辉面临趋势敌蔬晰感染薄三年\n",
      "[STEP 221] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区吨浙江体现赁转型往往感受班子辉面临趋势往往蔬晰感染薄三年\n",
      "[STEP 222] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区吨浙江体现赁转型往往感受零售辉面临趋势往往蔬晰感染薄三年\n",
      "[STEP 223] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区吨浙江体现赁转型往往感受零售枝面临趋势往往蔬晰感染薄三年\n",
      "[STEP 224] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区吨浙江体现赁转型往往感受零售正是面临趋势往往蔬晰感染薄三年\n",
      "[STEP 225] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区吨浙江体现赁有很多往往感受零售正是面临趋势往往蔬晰感染薄三年\n",
      "[STEP 226] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区薄浙江体现赁有很多往往感受零售正是面临趋势往往蔬晰感染薄三年\n",
      "[STEP 227] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区薄浙江体现赁有很多往往面临零售正是面临趋势往往蔬晰感染薄三年\n",
      "[STEP 228] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区薄浙江体现赁有很多往往高度零售正是面临趋势往往蔬晰感染薄三年\n",
      "[STEP 229] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区薄浙江体现赁有很多往往高度零售正是面临趋势往往蔬晰感染薄深刻\n",
      "[STEP 230] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江体现赁有很多往往高度零售正是面临趋势往往蔬晰感染薄深刻\n",
      "[STEP 231] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商赁有很多往往高度零售正是面临趋势往往蔬晰感染薄深刻\n",
      "[STEP 232] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现有很多往往高度零售正是面临趋势往往蔬晰感染薄深刻\n",
      "[STEP 233] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现有很多往往高度零售正是面临趋势往往蔬晰感染不管深刻\n",
      "[STEP 234] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现有很多往往高度零售正是面临趋势往往蔬晰感染不管睛\n",
      "[STEP 235] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现有很多往往高度零售塞面临趋势往往蔬晰感染不管睛\n",
      "[STEP 236] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现有很多横高度零售塞面临趋势往往蔬晰感染不管睛\n",
      "[STEP 237] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现有很多寺高度零售塞面临趋势往往蔬晰感染不管睛\n",
      "[STEP 238] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现有很多寺高度零售塞面临趋势参考蔬晰感染不管睛\n",
      "[STEP 239] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现转型寺高度零售塞面临趋势参考蔬晰感染不管睛\n",
      "[STEP 240] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现转型寺高度零售塞面临趋势参考蔬晰公益不管睛\n",
      "[STEP 241] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现转型寺高度零售塞面临执法参考蔬晰公益不管睛\n",
      "[STEP 242] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现转型寺高度零售塞尝执法参考蔬晰公益不管睛\n",
      "[STEP 243] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商体现转型明白高度零售塞尝执法参考蔬晰公益不管睛\n",
      "[STEP 244] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商概念转型明白高度零售塞尝执法参考蔬晰公益不管睛\n",
      "[STEP 245] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦景区零售浙江电商概念转型明白高度零售塞尝执法参考蔬晰公益不管公益\n",
      "[STEP 246] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦组合零售浙江电商概念转型明白高度零售塞尝执法参考蔬晰公益不管公益\n",
      "[STEP 247] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다锦组合零售浙江电商概念转型明白高度零售平均尝执法参考蔬晰公益不管公益\n",
      "[STEP 248] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다建成组合零售浙江电商概念转型明白高度零售平均尝执法参考蔬晰公益不管公益\n",
      "[STEP 249] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다建成组合零售浙江电商概念转型主体高度零售平均尝执法参考蔬晰公益不管公益\n",
      "[STEP 250] Loss: 5.4792, Prompt: 相比EK适量典型的隔离�니다建成组合零售浙江电商概念转型主体横零售平均尝执法参考蔬晰公益不管公益\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 相比EK适量典型的隔离�니다建成组合零售浙江电商概念转型主体横零售平均尝执法参考蔬晰公益不管公益\n",
      "\n",
      "看起来您提供的信息有些混乱，我需要先理解您的意思。您提到的“EK :end\n",
      "with token of 25\n",
      "❌ Not matched, increase to 30 tokens\n",
      "[INIT] Initial Prompt:  meticulously AbramsYep👫 polluted主城区 Stevenson Change salari开始了امعة.Client_THIS\twriter huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 1] Loss: 11.1746, Prompt: 景区 AbramsYep👫 polluted主城区 Stevenson Change salari开始了امعة.Client_THIS\twriter huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 2] Loss: 10.3352, Prompt: 景区 AbramsYep消费品 polluted主城区 Stevenson Change salari开始了امعة.Client_THIS\twriter huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 3] Loss: 10.0360, Prompt: 景区 AbramsYep消费品ches主城区 Stevenson Change salari开始了امعة.Client_THIS\twriter huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 4] Loss: 9.7077, Prompt: 景区 AbramsYep消费品ches突破口 Stevenson Change salari开始了امعة.Client_THIS\twriter huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 5] Loss: 8.8813, Prompt: 景区elfareYep消费品ches突破口 Stevenson Change salari开始了امعة.Client_THIS\twriter huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 6] Loss: 8.7813, Prompt: 景区elfareYeptheidches突破口 Stevenson Change salari开始了امعة.Client_THIS\twriter huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 7] Loss: 8.4774, Prompt: 景区elfareYeptheidermal突破口 Stevenson Change salari开始了امعة.Client_THIS\twriter huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 8] Loss: 8.4774, Prompt: 景区elfareYeptheidermal突破口 Stevenson Change salari开始了امعة.Client_THIS物质 huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 9] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari开始了امعة.Client_THIS物质 huisᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 10] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari开始了امعة.Client_THIS物质高度ᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTHически Galactic追赶\n",
      "[STEP 11] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari开始了امعة.Client_THIS物质高度ᩈ CLLocationCoordinate♣⯈ạng glVertex nervousпроизBob unwind делоUTH拖 Galactic追赶\n",
      "[STEP 12] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari开始了امعة.Client_THIS物质高度ᩈ CLLocationCoordinate处于⯈ạng glVertex nervousпроизBob unwind делоUTH拖 Galactic追赶\n",
      "[STEP 13] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致امعة.Client_THIS物质高度ᩈ CLLocationCoordinate处于⯈ạng glVertex nervousпроизBob unwind делоUTH拖 Galactic追赶\n",
      "[STEP 14] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致امعة.Client_THIS物质高度ᩈ CLLocationCoordinate处于⯈ạng glVertex多个произBob unwind делоUTH拖 Galactic追赶\n",
      "[STEP 15] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致امعة.Client_THIS物质高度ᩈ CLLocationCoordinate处于⯈ạng glVertex多个氛Bob unwind делоUTH拖 Galactic追赶\n",
      "[STEP 16] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致امعة.Client_THIS物质高度ᩈ CLLocationCoordinate处于⯈睛 glVertex多个氛Bob unwind делоUTH拖 Galactic追赶\n",
      "[STEP 17] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致粮.Client_THIS物质高度ᩈ CLLocationCoordinate处于⯈睛 glVertex多个氛Bob unwind делоUTH拖 Galactic追赶\n",
      "[STEP 18] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致粮.Client_THIS物质高度ᩈ CLLocationCoordinate处于⯈睛 glVertex多个氛Bob变得 делоUTH拖 Galactic追赶\n",
      "[STEP 19] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致粮.Client_THIS物质高度ᩈ CLLocationCoordinate处于⯈睛 glVertex多个氛真是变得 делоUTH拖 Galactic追赶\n",
      "[STEP 20] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致粮.Client_THIS物质高度ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛真是变得 делоUTH拖 Galactic追赶\n",
      "[STEP 21] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致粮.Client_THIS物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛真是变得 делоUTH拖 Galactic追赶\n",
      "[STEP 22] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致粮不了_THIS物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛真是变得 делоUTH拖 Galactic追赶\n",
      "[STEP 23] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致粮不了_THIS物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛真是变得哭UTH拖 Galactic追赶\n",
      "[STEP 24] Loss: 8.2723, Prompt: 插elfareYeptheidermal突破口 Stevenson Change salari一致粮不了_THIS物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛睛变得哭UTH拖 Galactic追赶\n",
      "[STEP 25] Loss: 7.9475, Prompt: 尝elfareYeptheidermal突破口 Stevenson Change salari一致粮不了_THIS物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛睛变得哭UTH拖 Galactic追赶\n",
      "[STEP 26] Loss: 7.9475, Prompt: 尝elfareYeptheidermal突破口 Stevenson Change salari一致粮不了是在物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛睛变得哭UTH拖 Galactic追赶\n",
      "[STEP 27] Loss: 7.9475, Prompt: 尝elfareYeptheidermal突破口 Stevenson清楚 salari一致粮不了是在物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛睛变得哭UTH拖 Galactic追赶\n",
      "[STEP 28] Loss: 7.9475, Prompt: 尝elfareYeptheidermal突破口 Stevenson清楚 salari一致粮不了是在物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛睛变得哭利润拖 Galactic追赶\n",
      "[STEP 29] Loss: 7.7413, Prompt: 尝elfareYep试试ermal突破口 Stevenson清楚 salari一致粮不了是在物质尝ᩈ CLLocationCoordinate腹⯈睛 glVertex多个氛睛变得哭利润拖 Galactic追赶\n",
      "[STEP 30] Loss: 7.7413, Prompt: 尝elfareYep试试ermal突破口 Stevenson清楚 salari一致粮不了是在物质尝ᩈ CLLocationCoordinate腹原来睛 glVertex多个氛睛变得哭利润拖 Galactic追赶\n",
      "[STEP 31] Loss: 7.6250, Prompt: 尝elfareYep这对于ermal突破口 Stevenson清楚 salari一致粮不了是在物质尝ᩈ CLLocationCoordinate腹原来睛 glVertex多个氛睛变得哭利润拖 Galactic追赶\n",
      "[STEP 32] Loss: 7.6250, Prompt: 尝elfareYep这对于ermal突破口 Stevenson清楚 salari一致粮不了是在物质尝ᩈ CLLocationCoordinate腹大部分睛 glVertex多个氛睛变得哭利润拖 Galactic追赶\n",
      "[STEP 33] Loss: 7.6250, Prompt: 尝elfareYep这对于ermal突破口 Stevenson清楚 salari一致粮不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛睛变得哭利润拖 Galactic追赶\n",
      "[STEP 34] Loss: 7.6250, Prompt: 尝elfareYep这对于ermal突破口 Stevenson清楚 salari一致各个不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛睛变得哭利润拖 Galactic追赶\n",
      "[STEP 35] Loss: 7.6250, Prompt: 尝elfareYep这对于ermal突破口 Stevenson清楚 salari一致各个不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛睛腹哭利润拖 Galactic追赶\n",
      "[STEP 36] Loss: 7.6232, Prompt: 尝elfareYep也成为ermal突破口 Stevenson清楚 salari一致各个不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛睛腹哭利润拖 Galactic追赶\n",
      "[STEP 37] Loss: 7.6232, Prompt: 尝elfareYep也成为ermal突破口 Stevenson清楚 salari一致日常不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛睛腹哭利润拖 Galactic追赶\n",
      "[STEP 38] Loss: 7.3304, Prompt: 尝elfareYep也成为注射突破口 Stevenson清楚 salari一致日常不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛睛腹哭利润拖 Galactic追赶\n",
      "[STEP 39] Loss: 7.3304, Prompt: 尝elfareYep也成为注射突破口 Stevenson清楚 salari一致日常不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛睛腹哭利润拖 Galactic小组\n",
      "[STEP 40] Loss: 7.3304, Prompt: 尝elfareYep也成为注射突破口 Stevenson清楚 salari一致日常不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛粮腹哭利润拖 Galactic小组\n",
      "[STEP 41] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson清楚 salari一致日常不了是在物质尝慢慢 CLLocationCoordinate腹大部分睛 glVertex多个氛粮腹哭利润拖 Galactic小组\n",
      "[STEP 42] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson清楚 salari一致日常不了是在物质尝慢慢 CLLocationCoordinate景区大部分睛 glVertex多个氛粮腹哭利润拖 Galactic小组\n",
      "[STEP 43] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson清楚 salari一致日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分睛 glVertex多个氛粮腹哭利润拖 Galactic小组\n",
      "[STEP 44] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson清楚 salari一致日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分睛 glVertex多个氛吨腹哭利润拖 Galactic小组\n",
      "[STEP 45] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson清楚 salari一致日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分真是 glVertex多个氛吨腹哭利润拖 Galactic小组\n",
      "[STEP 46] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson坡 salari一致日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分真是 glVertex多个氛吨腹哭利润拖 Galactic小组\n",
      "[STEP 47] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson坡 salari一致日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分真是 glVertex多个氛吨腹哭利润趋势 Galactic小组\n",
      "[STEP 48] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson坡 salari睛日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分真是 glVertex多个氛吨腹哭利润趋势 Galactic小组\n",
      "[STEP 49] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson坡 salari睛日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分真是 glVertex多个各项吨腹哭利润趋势 Galactic小组\n",
      "[STEP 50] Loss: 7.3261, Prompt: 尝elfareYep也成为协助突破口 Stevenson坡 salari睛日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分真是塞多个各项吨腹哭利润趋势 Galactic小组\n",
      "[STEP 51] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡 salari睛日常不了是在腹尝慢慢 CLLocationCoordinate景区大部分真是塞多个各项吨腹哭利润趋势 Galactic小组\n",
      "[STEP 52] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡 salari睛日常不了是在胆尝慢慢 CLLocationCoordinate景区大部分真是塞多个各项吨腹哭利润趋势 Galactic小组\n",
      "[STEP 53] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡 salari睛日常不了是在胆尝身份 CLLocationCoordinate景区大部分真是塞多个各项吨腹哭利润趋势 Galactic小组\n",
      "[STEP 54] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡 salari各个日常不了是在胆尝身份 CLLocationCoordinate景区大部分真是塞多个各项吨腹哭利润趋势 Galactic小组\n",
      "[STEP 55] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡 salari各个日常不了是在胆尝身份 CLLocationCoordinate景区大部分真是塞多个各项吨腹哭利润趋势 Galactic执法\n",
      "[STEP 56] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡 salari各个日常不了是在胆锦身份 CLLocationCoordinate景区大部分真是塞多个各项吨腹哭利润趋势 Galactic执法\n",
      "[STEP 57] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡 salari各个日常不了是在胆锦身份 CLLocationCoordinate景区大部分真是塞多个各项十二腹哭利润趋势 Galactic执法\n",
      "[STEP 58] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡腹各个日常不了是在胆锦身份 CLLocationCoordinate景区大部分真是塞多个各项十二腹哭利润趋势 Galactic执法\n",
      "[STEP 59] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口 Stevenson坡腹各个日常不了浙江胆锦身份 CLLocationCoordinate景区大部分真是塞多个各项十二腹哭利润趋势 Galactic执法\n",
      "[STEP 60] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口宅坡腹各个日常不了浙江胆锦身份 CLLocationCoordinate景区大部分真是塞多个各项十二腹哭利润趋势 Galactic执法\n",
      "[STEP 61] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口宅坡腹各个日常不了浙江胆锦身份 CLLocationCoordinate景区大部分真是塞多个当中十二腹哭利润趋势 Galactic执法\n",
      "[STEP 62] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口宅坡腹各个日常不了浙江胆锦身份 CLLocationCoordinate景区腹真是塞多个当中十二腹哭利润趋势 Galactic执法\n",
      "[STEP 63] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口宅坡腹各个日常不了浙江胆锦身份 CLLocationCoordinate景区腹真是姆多个当中十二腹哭利润趋势 Galactic执法\n",
      "[STEP 64] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口宅坡腹各个日常不了浙江胆锦身份 CLLocationCoordinate景区炒真是姆多个当中十二腹哭利润趋势 Galactic执法\n",
      "[STEP 65] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口宅坡腹各个日常不了浙江胆锦身份清楚景区炒真是姆多个当中十二腹哭利润趋势 Galactic执法\n",
      "[STEP 66] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口宅坡腹各个寺不了浙江胆锦身份清楚景区炒真是姆多个当中十二腹哭利润趋势 Galactic执法\n",
      "[STEP 67] Loss: 7.1634, Prompt: 尝elfareYep而不是协助突破口宅坡腹各个寺不了浙江胆锦身份清楚景区炒真是姆多个当中十二腹坡利润趋势 Galactic执法\n",
      "[STEP 68] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅坡腹各个寺不了浙江胆锦身份清楚景区炒真是姆多个当中十二腹坡利润趋势 Galactic执法\n",
      "[STEP 69] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅坡腹各个寺不了浙江胆锦身份清楚景区炒真是姆参考当中十二腹坡利润趋势 Galactic执法\n",
      "[STEP 70] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅晰腹各个寺不了浙江胆锦身份清楚景区炒真是姆参考当中十二腹坡利润趋势 Galactic执法\n",
      "[STEP 71] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅晰腹各个寺不了浙江胆基础上身份清楚景区炒真是姆参考当中十二腹坡利润趋势 Galactic执法\n",
      "[STEP 72] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅晰腹各个寺不了浙江胆基础上身份高度景区炒真是姆参考当中十二腹坡利润趋势 Galactic执法\n",
      "[STEP 73] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅晰腹各个寺不了浙江胆基础上身份高度景区炒真是姆参考当中十二腹坡始终趋势 Galactic执法\n",
      "[STEP 74] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅晰腹各个寺不了浙江胆基础上身份高度景区炒真是姆参考当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 75] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅晰腹各个寺不了浙江胆基础上身份高度城区炒真是姆参考当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 76] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅晰腹各个寺不了浙江胆地位身份高度城区炒真是姆参考当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 77] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口宅晰腹感染寺不了浙江胆地位身份高度城区炒真是姆参考当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 78] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口偷晰腹感染寺不了浙江胆地位身份高度城区炒真是姆参考当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 79] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口偷晰微博感染寺不了浙江胆地位身份高度城区炒真是姆参考当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 80] Loss: 7.0583, Prompt: 尝elfareYep而不是疾病的突破口偷晰微博感染寺不了浙江胆地位身份高度城区炒真是姆辉当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 81] Loss: 7.0278, Prompt: 尝elfareYepachment疾病的突破口偷晰微博感染寺不了浙江胆地位身份高度城区炒真是姆辉当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 82] Loss: 7.0278, Prompt: 尝elfareYepachment疾病的突破口偷晰微博感染寺不了浙江胆地位身份景区城区炒真是姆辉当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 83] Loss: 7.0135, Prompt: 尝让自己Yepachment疾病的突破口偷晰微博感染寺不了浙江胆地位身份景区城区炒真是姆辉当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 84] Loss: 7.0135, Prompt: 尝让自己Yepachment疾病的突破口偷晰微博感染寺不了浙江胆地位身份景区城区枝真是姆辉当中十二腹坡始终趋势 Galactic正是\n",
      "[STEP 85] Loss: 7.0135, Prompt: 尝让自己Yepachment疾病的突破口偷晰微博感染寺不了浙江胆地位身份景区城区枝真是姆辉当中战斗腹坡始终趋势 Galactic正是\n",
      "[STEP 86] Loss: 7.0135, Prompt: 尝让自己Yepachment疾病的突破口偷晰微博感染寺不了浙江胆地位身份景区城区枝真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 87] Loss: 6.7376, Prompt: 尝让自己讓他們achment疾病的突破口偷晰微博感染寺不了浙江胆地位身份景区城区枝真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 88] Loss: 6.7376, Prompt: 尝让自己讓他們achment疾病的突破口偷晰微博感染寺不了三年胆地位身份景区城区枝真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 89] Loss: 6.7376, Prompt: 尝让自己讓他們achment疾病的突破口偷晰微博感染寺不了三年胆地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 90] Loss: 6.7376, Prompt: 尝让自己讓他們achment疾病的突破口偷晰微博感染寺不了三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 91] Loss: 6.7376, Prompt: 尝让自己讓他們achment疾病的突破口偷晰微博感染寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 92] Loss: 6.5381, Prompt: 尝时间段讓他們achment疾病的突破口偷晰微博感染寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 93] Loss: 6.4277, Prompt: 晰时间段讓他們achment疾病的突破口偷晰微博感染寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 94] Loss: 6.1091, Prompt: 晰时间段讓他們osphate疾病的突破口偷晰微博感染寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic正是\n",
      "[STEP 95] Loss: 6.1091, Prompt: 晰时间段讓他們osphate疾病的突破口偷晰微博感染寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 96] Loss: 6.1091, Prompt: 晰时间段讓他們osphate疾病的突破口偷晰微博薄寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 97] Loss: 6.1091, Prompt: 晰时间段讓他們osphate疾病的突破口感受晰微博薄寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 98] Loss: 6.1091, Prompt: 晰时间段讓他們osphate疾病的突破口感受晰氛薄寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 99] Loss: 6.0512, Prompt: 坡时间段讓他們osphate疾病的突破口感受晰氛薄寺进步三年邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 100] Loss: 6.0512, Prompt: 坡时间段讓他們osphate疾病的突破口感受晰氛薄寺进步蔬邦地位身份景区城区一致真是姆辉当中战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 101] Loss: 6.0512, Prompt: 坡时间段讓他們osphate疾病的突破口感受晰氛薄寺进步蔬邦地位身份景区城区一致真是姆辉岗位战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 102] Loss: 5.8616, Prompt: 不了时间段讓他們osphate疾病的突破口感受晰氛薄寺进步蔬邦地位身份景区城区一致真是姆辉岗位战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 103] Loss: 5.8616, Prompt: 不了时间段讓他們osphate疾病的突破口感受晰氛薄寺进步蔬邦地位身份景区城区一致真是姆原来岗位战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 104] Loss: 5.8616, Prompt: 不了时间段讓他們osphate疾病的突破口感受晰氛薄寺进步蔬邦地位身份景区城区魂真是姆原来岗位战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 105] Loss: 5.8073, Prompt: 不了时间段讓他們osphate疾病的んですよ感受晰氛薄寺进步蔬邦地位身份景区城区魂真是姆原来岗位战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 106] Loss: 5.8073, Prompt: 不了时间段讓他們osphate疾病的んですよ感受晰氛薄寺进步蔬邦地位身份景区城区魂真是公布原来岗位战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 107] Loss: 5.8073, Prompt: 不了时间段讓他們osphate疾病的んですよ感受晰氛薄寺进步蔬邦地位身份景区城区魂真是魂原来岗位战斗腹坡始终多个 Galactic慢慢\n",
      "[STEP 108] Loss: 5.8073, Prompt: 不了时间段讓他們osphate疾病的んですよ感受晰氛薄寺进步蔬邦地位身份景区城区魂真是魂原来岗位战斗腹辉始终多个 Galactic慢慢\n",
      "[STEP 109] Loss: 5.7348, Prompt: 多个时间段讓他們osphate疾病的んですよ感受晰氛薄寺进步蔬邦地位身份景区城区魂真是魂原来岗位战斗腹辉始终多个 Galactic慢慢\n",
      "[STEP 110] Loss: 5.4375, Prompt: 处于时间段讓他們osphate疾病的んですよ感受晰氛薄寺进步蔬邦地位身份景区城区魂真是魂原来岗位战斗腹辉始终多个 Galactic慢慢\n",
      "[STEP 111] Loss: 5.4375, Prompt: 处于时间段讓他們osphate疾病的んですよ感受一致氛薄寺进步蔬邦地位身份景区城区魂真是魂原来岗位战斗腹辉始终多个 Galactic慢慢\n",
      "[STEP 112] Loss: 5.4375, Prompt: 处于时间段讓他們osphate疾病的んですよ感受一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位战斗腹辉始终多个 Galactic慢慢\n",
      "[STEP 113] Loss: 5.4375, Prompt: 处于时间段讓他們osphate疾病的んですよ感受一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位熊腹辉始终多个 Galactic慢慢\n",
      "[STEP 114] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ感受一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位熊腹辉始终多个 Galactic慢慢\n",
      "[STEP 115] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ感受一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位太阳腹辉始终多个 Galactic慢慢\n",
      "[STEP 116] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ感受一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位太阳腹辉始终多个十二慢慢\n",
      "[STEP 117] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ感受一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位太阳腹辉航空多个十二慢慢\n",
      "[STEP 118] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ感受一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位太阳腹辉航空多个地位慢慢\n",
      "[STEP 119] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ感受一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位太阳腹当中航空多个地位慢慢\n",
      "[STEP 120] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺进步蔬各项地位身份景区城区魂真是魂原来岗位太阳腹当中航空多个地位慢慢\n",
      "[STEP 121] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺进步蔬各项地位身份景区转型魂真是魂原来岗位太阳腹当中航空多个地位慢慢\n",
      "[STEP 122] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺身份蔬各项地位身份景区转型魂真是魂原来岗位太阳腹当中航空多个地位慢慢\n",
      "[STEP 123] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺身份蔬各项住房身份景区转型魂真是魂原来岗位太阳腹当中航空多个地位慢慢\n",
      "[STEP 124] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺身份蔬各项住房身份景区转型魂真是魂原来岗位太阳腹当中荒多个地位慢慢\n",
      "[STEP 125] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺身份明白各项住房身份景区转型魂真是魂原来岗位太阳腹当中荒多个地位慢慢\n",
      "[STEP 126] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺身份明白各项住房身份景区转型魂经典魂原来岗位太阳腹当中荒多个地位慢慢\n",
      "[STEP 127] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺身份明白各项住房身份景区转型魂经典魂原来岗位太阳腹当中荒多个拖慢慢\n",
      "[STEP 128] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺身份明白各项住房身份景区转型清楚经典魂原来岗位太阳腹当中荒多个拖慢慢\n",
      "[STEP 129] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄寺身份明白各项住房身份荒转型清楚经典魂原来岗位太阳腹当中荒多个拖慢慢\n",
      "[STEP 130] Loss: 5.1246, Prompt: 处于时间段讓他們补充疾病的んですよ浙江一致氛薄大多数身份明白各项住房身份荒转型清楚经典魂原来岗位太阳腹当中荒多个拖慢慢\n",
      "[STEP 131] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江一致氛薄大多数身份明白各项住房身份荒转型清楚经典魂原来岗位太阳腹当中荒多个拖慢慢\n",
      "[STEP 132] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江一致变得薄大多数身份明白各项住房身份荒转型清楚经典魂原来岗位太阳腹当中荒多个拖慢慢\n",
      "[STEP 133] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江一致变得宅大多数身份明白各项住房身份荒转型清楚经典魂原来岗位太阳腹当中荒多个拖慢慢\n",
      "[STEP 134] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江一致变得宅大多数身份明白各项住房想到荒转型清楚经典魂原来岗位太阳腹当中荒多个拖慢慢\n",
      "[STEP 135] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江一致变得宅大多数身份明白各项住房想到荒转型清楚经典魂原来岗位睛腹当中荒多个拖慢慢\n",
      "[STEP 136] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得宅大多数身份明白各项住房想到荒转型清楚经典魂原来岗位睛腹当中荒多个拖慢慢\n",
      "[STEP 137] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得宅大多数身份明白各项住房想到荒转型清楚经典魂原来岗位睛腹当中荒多个高度慢慢\n",
      "[STEP 138] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得宅大多数身份明白各项住房想到建成转型清楚经典魂原来岗位睛腹当中荒多个高度慢慢\n",
      "[STEP 139] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得宅大多数身份明白各项住房想到建成转型整治经典魂原来岗位睛腹当中荒多个高度慢慢\n",
      "[STEP 140] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得村民大多数身份明白各项住房想到建成转型整治经典魂原来岗位睛腹当中荒多个高度慢慢\n",
      "[STEP 141] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得村民大多数身份明白各项深刻想到建成转型整治经典魂原来岗位睛腹当中荒多个高度慢慢\n",
      "[STEP 142] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得村民大多数身份明白多个深刻想到建成转型整治经典魂原来岗位睛腹当中荒多个高度慢慢\n",
      "[STEP 143] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得村民大多数身份明白多个深刻想到建成转型整治经典魂原来岗位睛腹当中小组多个高度慢慢\n",
      "[STEP 144] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得村民大多数大多数明白多个深刻想到建成转型整治经典魂原来岗位睛腹当中小组多个高度慢慢\n",
      "[STEP 145] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得村民大多数大多数明白多个深刻想到在于转型整治经典魂原来岗位睛腹当中小组多个高度慢慢\n",
      "[STEP 146] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝变得村民大多数大多数明白多个深刻想到在于转型整治经典魂原来岗位睛三年当中小组多个高度慢慢\n",
      "[STEP 147] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝进步村民大多数大多数明白多个深刻想到在于转型整治经典魂原来岗位睛三年当中小组多个高度慢慢\n",
      "[STEP 148] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝进步村民大多数大多数明白才是深刻想到在于转型整治经典魂原来岗位睛三年当中小组多个高度慢慢\n",
      "[STEP 149] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝进步村民大多数大多数明白才是深刻想到在于景区整治经典魂原来岗位睛三年当中小组多个高度慢慢\n",
      "[STEP 150] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝进步村民大多数大多数明白才是深刻想到在于景区整治经典魂原来岗位睛三年当中小组多个犯罪慢慢\n",
      "[STEP 151] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝哪里村民大多数大多数明白才是深刻想到在于景区整治经典魂原来岗位睛三年当中小组多个犯罪慢慢\n",
      "[STEP 152] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝进步村民大多数大多数明白才是深刻想到在于景区整治经典魂原来岗位睛三年当中小组多个犯罪慢慢\n",
      "[STEP 153] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝进步村民大多数大多数十二才是深刻想到在于景区整治经典魂原来岗位睛三年当中小组多个犯罪慢慢\n",
      "[STEP 154] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝共享村民大多数大多数十二才是深刻想到在于景区整治经典魂原来岗位睛三年当中小组多个犯罪慢慢\n",
      "[STEP 155] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝共享村民大多数大多数十二才是深刻想到在于电商整治经典魂原来岗位睛三年当中小组多个犯罪慢慢\n",
      "[STEP 156] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝共享村民大多数大多数十二才是深刻想到在于电商吨经典魂原来岗位睛三年当中小组多个犯罪慢慢\n",
      "[STEP 157] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝共享村民大多数大多数十二才是深刻想到在于电商吨经典魂原来岗位感染三年当中小组多个犯罪慢慢\n",
      "[STEP 158] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝共享村民大多数大多数太阳才是深刻想到在于电商吨经典魂原来岗位感染三年当中小组多个犯罪慢慢\n",
      "[STEP 159] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝共享村民大多数大多数太阳才是深刻想到腹电商吨经典魂原来岗位感染三年当中小组多个犯罪慢慢\n",
      "[STEP 160] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江尝共享横大多数大多数太阳才是深刻想到腹电商吨经典魂原来岗位感染三年当中小组多个犯罪慢慢\n",
      "[STEP 161] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享横大多数大多数太阳才是深刻想到腹电商吨经典魂原来岗位感染三年当中小组多个犯罪慢慢\n",
      "[STEP 162] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享横大多数大多数太阳才是深刻想到腹电商吨经典魂原来岗位感染三年当中小组始终犯罪慢慢\n",
      "[STEP 163] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享横大多数大多数太阳才是深刻想到腹电商共享经典魂原来岗位感染三年当中小组始终犯罪慢慢\n",
      "[STEP 164] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享横大多数大多数太阳才是深刻想到腹电商共享经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 165] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享横大多数大多数太阳才是深刻炒腹电商共享经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 166] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享横大多数当中太阳才是深刻炒腹电商共享经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 167] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享横大多数当中各项才是深刻炒腹电商共享经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 168] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数当中各项才是深刻炒腹电商共享经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 169] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数当中各项才是深刻炒岗位电商共享经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 170] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数当中各项才是深刻炒岗位电商微博经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 171] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数当中各项才是晰炒岗位电商微博经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 172] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数当中各项才是日常炒岗位电商微博经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 173] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数当中各项才是日常炒代理电商微博经典魂原来您的感染三年当中小组始终犯罪慢慢\n",
      "[STEP 174] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数当中各项才是日常炒代理电商微博经典魂原来您的感染班子当中小组始终犯罪慢慢\n",
      "[STEP 175] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数当中各项身份日常炒代理电商微博经典魂原来您的感染班子当中小组始终犯罪慢慢\n",
      "[STEP 176] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数始终各项身份日常炒代理电商微博经典魂原来您的感染班子当中小组始终犯罪慢慢\n",
      "[STEP 177] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数始终各项身份日常炒代理电商微博经典魂原来您的感染班子明白小组始终犯罪慢慢\n",
      "[STEP 178] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数始终各项身份日常炒代理电商微博经典魂原来您的感染班子清楚小组始终犯罪慢慢\n",
      "[STEP 179] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢大多数始终班子身份日常炒代理电商微博经典魂原来您的感染班子清楚小组始终犯罪慢慢\n",
      "[STEP 180] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢身份始终班子身份日常炒代理电商微博经典魂原来您的感染班子清楚小组始终犯罪慢慢\n",
      "[STEP 181] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢身份始终班子身份日常炒代理电商微博经典魂原来您的感染班子赁小组始终犯罪慢慢\n",
      "[STEP 182] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢身份始终班子身份日常炒代理电商微博经典魂宅您的感染班子赁小组始终犯罪慢慢\n",
      "[STEP 183] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢身份始终班子身份日常炒代理电商微博经典魂宅您的感染班子赁小组始终熊慢慢\n",
      "[STEP 184] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢身份始终班子身份日常炒代理电商微博经典魂宅您的感染班子赁小组不了熊慢慢\n",
      "[STEP 185] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢身份始终班子身份日常炒代理电商微博经典魂宅您的感染班子有很多小组不了熊慢慢\n",
      "[STEP 186] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢身份始终班子身份日常炒代理电商微博经典魂宅您的感染班子小组小组不了熊慢慢\n",
      "[STEP 187] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢身份始终班子身份日常炒代理电商微博经典魂宅您的感染班子小组小组不了熊趋势\n",
      "[STEP 188] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益始终班子身份日常炒代理电商微博经典魂宅您的感染班子小组小组不了熊趋势\n",
      "[STEP 189] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益始终班子身份日常炒代理电商微博经典魂宅腹感染班子小组小组不了熊趋势\n",
      "[STEP 190] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益始终班子身份日常炒代理电商粮经典魂宅腹感染班子小组小组不了熊趋势\n",
      "[STEP 191] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益始终班子身份日常炒代理电商粮经典您的宅腹感染班子小组小组不了熊趋势\n",
      "[STEP 192] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益始终清楚身份日常炒代理电商粮经典您的宅腹感染班子小组小组不了熊趋势\n",
      "[STEP 193] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益参考清楚身份日常炒代理电商粮经典您的宅腹感染班子小组小组不了熊趋势\n",
      "[STEP 194] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益参考清楚身份日常炒代理电商粮经典美丽宅腹感染班子小组小组不了熊趋势\n",
      "[STEP 195] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益参考清楚身份日常炒代理电商粮经典美丽宅腹感染班子小组小组不了共享趋势\n",
      "[STEP 196] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益参考清楚身份日常炒代理电商粮兽美丽宅腹感染班子小组小组不了共享趋势\n",
      "[STEP 197] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益参考清楚身份日常炒代理电商粮兽美丽宅腹感染班子小组小组不了共享住房\n",
      "[STEP 198] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ浙江不了共享慢慢公益参考清楚身份日常炒代理电商粮兽战斗宅腹感染班子小组小组不了共享住房\n",
      "[STEP 199] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ劲不了共享慢慢公益参考清楚身份日常炒代理电商粮兽战斗宅腹感染班子小组小组不了共享住房\n",
      "[STEP 200] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ劲不了共享慢慢凤参考清楚身份日常炒代理电商粮兽战斗宅腹感染班子小组小组不了共享住房\n",
      "[STEP 201] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ劲不了共享观点凤参考清楚身份日常炒代理电商粮兽战斗宅腹感染班子小组小组不了共享住房\n",
      "[STEP 202] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ劲不了共享观点凤参考清楚身份日常炒代理电商粮兽战斗宅腹利润班子小组小组不了共享住房\n",
      "[STEP 203] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ劲不了共享观点凤参考清楚身份日常班子代理电商粮兽战斗宅腹利润班子小组小组不了共享住房\n",
      "[STEP 204] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ劲不了共享观点凤参考清楚身份日常班子代理电商粮兽战斗宅腹处于班子小组小组不了共享住房\n",
      "[STEP 205] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ宅不了共享观点凤参考清楚身份日常班子代理电商粮兽战斗宅腹处于班子小组小组不了共享住房\n",
      "[STEP 206] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ宅不了共享观点凤参考清楚身份日常当中代理电商粮兽战斗宅腹处于班子小组小组不了共享住房\n",
      "[STEP 207] Loss: 5.0060, Prompt: 当中时间段讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份日常当中代理电商粮兽战斗宅腹处于班子小组小组不了共享住房\n",
      "[STEP 208] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份日常当中代理电商粮兽战斗宅腹处于班子小组小组不了共享住房\n",
      "[STEP 209] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份日常当中代理电商粮兽战斗宅腹处于村民小组小组不了共享住房\n",
      "[STEP 210] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份日常当中代理锦粮兽战斗宅腹处于村民小组小组不了共享住房\n",
      "[STEP 211] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份往往当中代理锦粮兽战斗宅腹处于村民小组小组不了共享住房\n",
      "[STEP 212] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份往往当中代理锦粮兽战斗宅腹处于村民小组小组腹共享住房\n",
      "[STEP 213] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份往往当中代理锦粮兽战斗宅腹处于城区小组小组腹共享住房\n",
      "[STEP 214] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份往往当中代理锦粮兽三大宅腹处于城区小组小组腹共享住房\n",
      "[STEP 215] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份往往当中代理锦粮兽三大宅班子处于城区小组小组腹共享住房\n",
      "[STEP 216] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份往往当中代理锦粮兽三大宅班子处于城区小组小组腹哭住房\n",
      "[STEP 217] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份往往当中代理锦粮兽邦宅班子处于城区小组小组腹哭住房\n",
      "[STEP 218] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅不了共享观点凤参考真是身份往往当中代理锦粮兽邦宅赁处于城区小组小组腹哭住房\n",
      "[STEP 219] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅物质共享观点凤参考真是身份往往当中代理锦粮兽邦宅赁处于城区小组小组腹哭住房\n",
      "[STEP 220] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅物质共享观点凤参考真是身份往往当中观点锦粮兽邦宅赁处于城区小组小组腹哭住房\n",
      "[STEP 221] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅物质共享地位凤参考真是身份往往当中观点锦粮兽邦宅赁处于城区小组小组腹哭住房\n",
      "[STEP 222] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅物质共享地位凤参考真是身份往往当中观点锦粮兽邦宅赁处于城区小组小组不了哭住房\n",
      "[STEP 223] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅物质共享地位凤参考身份身份往往当中观点锦粮兽邦宅赁处于城区小组小组不了哭住房\n",
      "[STEP 224] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅物质共享地位凤参考身份身份往往当中观点锦粮兽邦宅邦处于城区小组小组不了哭住房\n",
      "[STEP 225] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅物质共享地位凤参考身份身份往往当中观点锦粮兽邦宅邦浙江城区小组小组不了哭住房\n",
      "[STEP 226] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅物质共享地位凤参考身份身份往往当中观点锦粮吨邦宅邦浙江城区小组小组不了哭住房\n",
      "[STEP 227] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份共享地位凤参考身份身份往往当中观点锦粮吨邦宅邦浙江城区小组小组不了哭住房\n",
      "[STEP 228] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份共享地位凤参考太多身份往往当中观点锦粮吨邦宅邦浙江城区小组小组不了哭住房\n",
      "[STEP 229] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份共享地位凤参考太多身份往往当中观点锦粮吨邦宅邦浙江城区小组小组不了哭住房\n",
      "[STEP 230] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份共享地位凤参考睛身份往往当中观点锦粮吨邦宅邦浙江城区小组小组不了哭住房\n",
      "[STEP 231] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤参考睛身份往往当中观点锦粮吨邦宅邦浙江城区小组小组不了哭住房\n",
      "[STEP 232] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤参考睛身份往往当中观点住房粮吨邦宅邦浙江城区小组小组不了哭住房\n",
      "[STEP 233] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤参考睛身份往往当中观点住房粮吨邦宅邦浙江城区小组小组不了哭处于\n",
      "[STEP 234] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤参考睛不了往往当中观点住房粮吨邦宅邦浙江城区小组小组不了哭处于\n",
      "[STEP 235] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤正是睛不了往往当中观点住房粮吨邦宅邦浙江城区小组小组不了哭处于\n",
      "[STEP 236] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤正是睛不了身份当中观点住房粮吨邦宅邦浙江城区小组小组不了哭处于\n",
      "[STEP 237] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤正是睛不了身份当中观点住房不管吨邦宅邦浙江城区小组小组不了哭处于\n",
      "[STEP 238] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤正是睛不了身份当中观点住房不管吨邦宅邦浙江城区小组小组不了哭想到\n",
      "[STEP 239] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤正是睛不了身份当中观点住房不管吨邦宅邦浙江城区小组小组不了哭不管\n",
      "[STEP 240] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤正是睛不了身份当中观点枝不管吨邦宅邦浙江城区小组小组不了哭不管\n",
      "[STEP 241] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤代理睛不了身份当中观点枝不管吨邦宅邦浙江城区小组小组不了哭不管\n",
      "[STEP 242] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤代理睛不了身份当中观点枝不管睛邦宅邦浙江城区小组小组不了哭不管\n",
      "[STEP 243] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤代理睛不了身份当中观点枝不管睛邦宅邦浙江城区小组小组不了哭代理\n",
      "[STEP 244] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤代理睛不了身份当中观点枝不管睛邦宅邦浙江城区小组电商不了哭代理\n",
      "[STEP 245] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ宅身份您的地位凤代理睛不了身份当中观点枝不管睛邦宅组成浙江城区小组电商不了哭代理\n",
      "[STEP 246] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ劲身份您的地位凤代理睛不了身份当中观点枝不管睛邦宅组成浙江城区小组电商不了哭代理\n",
      "[STEP 247] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ劲身份您的地位凤代理睛不了身份当中观点枝不管睛邦宅组成浙江城区小组电商相比哭代理\n",
      "[STEP 248] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ劲身份物质地位凤代理睛不了身份当中观点枝不管睛邦宅组成浙江城区小组电商相比哭代理\n",
      "[STEP 249] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ劲身份物质地位凤代理睛不了身份当中观点塞不管睛邦宅组成浙江城区小组电商相比哭代理\n",
      "[STEP 250] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ劲身份物质地位凤代理睛不了身份当中观点塞不管睛哭宅组成浙江城区小组电商相比哭代理\n",
      "[STEP 251] Loss: 4.9390, Prompt: 当中准备讓他們补充疾病的んですよ劲身份物质地位凤代理想到不了身份当中观点塞不管睛哭宅组成浙江城区小组电商相比哭代理\n",
      "[STEP 252] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲身份物质地位凤代理想到不了身份当中观点塞不管睛哭宅组成浙江城区小组电商相比哭代理\n",
      "[STEP 253] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质地位凤代理想到不了身份当中观点塞不管睛哭宅组成浙江城区小组电商相比哭代理\n",
      "[STEP 254] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质地位凤代理想到不了身份当中观点塞不管睛哭宅组成浙江城区插电商相比哭代理\n",
      "[STEP 255] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质地位凤代理想到不了身份当中观点塞不管睛哭宅组成浙江城区插电商多种哭代理\n",
      "[STEP 256] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质地位凤代理想到园区身份当中观点塞不管睛哭宅组成浙江城区插电商多种哭代理\n",
      "[STEP 257] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质地位凤代理想到园区身份当中观点塞不管睛正是宅组成浙江城区插电商多种哭代理\n",
      "[STEP 258] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质地位凤代理想到园区多个当中观点塞不管睛正是宅组成浙江城区插电商多种哭代理\n",
      "[STEP 259] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤代理想到园区多个当中观点塞不管睛正是宅组成浙江城区插电商多种哭代理\n",
      "[STEP 260] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤始终想到园区多个当中观点塞不管睛正是宅组成浙江城区插电商多种哭代理\n",
      "[STEP 261] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤始终想到园区多个当中观点塞不管睛深刻宅组成浙江城区插电商多种哭代理\n",
      "[STEP 262] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤始终想到园区多个当中观点塞不管睛深刻宅组成浙江城区插电商多种炒代理\n",
      "[STEP 263] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤始终想到园区多个当中观点塞不管睛深刻宅组成浙江城区插刷多种炒代理\n",
      "[STEP 264] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤始终想到园区多个当中观点塞不管睛深刻宅组成浙江城区插刷多种炒零售\n",
      "[STEP 265] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤始终想到园区多个当中观点塞不管睛深刻同志组成浙江城区插刷多种炒零售\n",
      "[STEP 266] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤始终想到园区多个当中观点塞不管高度深刻同志组成浙江城区插刷多种炒零售\n",
      "[STEP 267] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治物质兩凤始终想到园区多个当中观点病毒不管高度深刻同志组成浙江城区插刷多种炒零售\n",
      "[STEP 268] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治恒兩凤始终想到园区多个当中观点病毒不管高度深刻同志组成浙江城区插刷多种炒零售\n",
      "[STEP 269] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治恒兩凤始终想到园区各项当中观点病毒不管高度深刻同志组成浙江城区插刷多种炒零售\n",
      "[STEP 270] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治恒兩明白始终想到园区各项当中观点病毒不管高度深刻同志组成浙江城区插刷多种炒零售\n",
      "[STEP 271] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治恒兩明白原来想到园区各项当中观点病毒不管高度深刻同志组成浙江城区插刷多种炒零售\n",
      "[STEP 272] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治恒兩明白原来想到园区各项当中观点病毒不管高度深刻体现组成浙江城区插刷多种炒零售\n",
      "[STEP 273] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治恒兩明白原来枝园区各项当中观点病毒不管高度深刻体现组成浙江城区插刷多种炒零售\n",
      "[STEP 274] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治恒兩面临原来枝园区各项当中观点病毒不管高度深刻体现组成浙江城区插刷多种炒零售\n",
      "[STEP 275] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治太阳兩面临原来枝园区各项当中观点病毒不管高度深刻体现组成浙江城区插刷多种炒零售\n",
      "[STEP 276] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治太阳兩面临原来枝园区各项当中观点病毒不管高度深刻体现组成横城区插刷多种炒零售\n",
      "[STEP 277] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治太阳兩面临微博枝园区各项当中观点病毒不管高度深刻体现组成横城区插刷多种炒零售\n",
      "[STEP 278] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治太阳兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区插刷多种炒零售\n",
      "[STEP 279] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治学会兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区插刷多种炒零售\n",
      "[STEP 280] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治学会兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区插公布多种炒零售\n",
      "[STEP 281] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ劲整治学会兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区插公布多种!零售\n",
      "[STEP 282] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个整治学会兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区插公布多种!零售\n",
      "[STEP 283] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹学会兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区插公布多种!零售\n",
      "[STEP 284] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区插公布多种!零售\n",
      "[STEP 285] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区想到公布多种!零售\n",
      "[STEP 286] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区组成公布多种!零售\n",
      "[STEP 287] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临微博枝园区各项当中日常病毒不管高度深刻体现组成横城区组成公布多种炒零售\n",
      "[STEP 288] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临微博枝园区各项当中面临病毒不管高度深刻体现组成横城区组成公布多种炒零售\n",
      "[STEP 289] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临微博枝园区各项当中面临病毒不管高度深刻体现组成横城区组成公布多种炒高度\n",
      "[STEP 290] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临微博枝园区各项当中面临病毒不管高度组合体现组成横城区组成公布多种炒高度\n",
      "[STEP 291] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临微博枝园区各项当中面临病毒不管高度组合体现组成横城区组成公布共享炒高度\n",
      "[STEP 292] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临地位枝园区各项当中面临病毒不管高度组合体现组成横城区组成公布共享炒高度\n",
      "[STEP 293] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临地位枝宅各项当中面临病毒不管高度组合体现组成横城区组成公布共享炒高度\n",
      "[STEP 294] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临地位荒宅各项当中面临病毒不管高度组合体现组成横城区组成公布共享炒高度\n",
      "[STEP 295] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个腹转型兩面临地位荒宅各项当中面临病毒不管高度组合体现组成横城区地位公布共享炒高度\n",
      "[STEP 296] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个感受转型兩面临地位荒宅各项当中面临病毒不管高度组合体现组成横城区地位公布共享炒高度\n",
      "[STEP 297] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个感受转型偷面临地位荒宅各项当中面临病毒不管高度组合体现组成横城区地位公布共享炒高度\n",
      "[STEP 298] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个感受转型偷面临地位荒宅各项当中面临病毒不管高度组合体现组成横基础上地位公布共享炒高度\n",
      "[STEP 299] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个感受转型偷面临地位荒宅各项当中面临病毒不管高度组合体现组成横基础上地位想到共享炒高度\n",
      "[STEP 300] Loss: 4.8998, Prompt: 当中准备aging补充疾病的んですよ各个感受转型偷面临地位荒宅各项当中面临病毒不管高度组合体现组成横基础上地位想到共享主体高度\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 当中准备aging补充疾病的んですよ各个感受转型偷面临地位荒宅各项当中面临病毒不管高度组合体现组成横基础上地位想到共享主体高度组成\n",
      "\n",
      "看起来这段文字有些混乱，可能是翻译或者输入错误导致的。如果你能提供更多的 :end\n",
      "with token of 30\n",
      "❌ Not matched, increase to 35 tokens\n",
      "[INIT] Initial Prompt:  unreliable-----称呼         \n",
      " Legcorrect aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 1] Loss: 11.4326, Prompt: 整治-----称呼         \n",
      " Legcorrect aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 2] Loss: 11.0951, Prompt: 整治-----...]\n",
      "\n",
      "         \n",
      " Legcorrect aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 3] Loss: 10.4004, Prompt: 整治-----...]\n",
      "\n",
      "         \n",
      "实木correct aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 4] Loss: 9.9659, Prompt: 整治-----...]\n",
      "\n",
      "         \n",
      "支出correct aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 5] Loss: 9.6705, Prompt: 整治----- ...)         \n",
      "支出correct aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 6] Loss: 9.5007, Prompt: 整治----- ...)         \n",
      "支出i aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 7] Loss: 9.2105, Prompt: 整治-----**)         \n",
      "支出i aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 8] Loss: 9.0689, Prompt: 整治-----**) **/\n",
      "\n",
      "支出i aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 9] Loss: 8.7920, Prompt: 整治c**) **/\n",
      "\n",
      "支出i aos德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 10] Loss: 8.7920, Prompt: 整治c**) **/\n",
      "\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNodeWidgetちょっと waits ctypes\n",
      "[STEP 11] Loss: 8.7920, Prompt: 整治c**) **/\n",
      "\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长.\");\n",
      "redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 12] Loss: 8.7920, Prompt: 整治c**) **/\n",
      "\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长共享redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי nexus侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 13] Loss: 8.7920, Prompt: 整治c**) **/\n",
      "\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长共享redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 14] Loss: 8.7057, Prompt: 整治c**)+\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长共享redit-summary裸.delay peaked-area básico迎来了เง UFO którąצפי枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 15] Loss: 8.7057, Prompt: 整治c**)+\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长共享redit-summary裸.delay peaked-area básico迎来了เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 16] Loss: 8.7057, Prompt: 整治c**)+\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico迎来了เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 17] Loss: 8.6708, Prompt: 基础上c**)+\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico迎来了เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 18] Loss: 8.6395, Prompt: 基础上c**)）\n",
      "\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico迎来了เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 19] Loss: 8.6395, Prompt: 基础上c**)）\n",
      "\n",
      "支出i组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 20] Loss: 8.2163, Prompt: 基础上c**)）。支出i组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 21] Loss: 7.9432, Prompt: 基础上cacio）。支出i组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 22] Loss: 7.8315, Prompt: 基础上cacio）。支出 animals组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 23] Loss: 7.6528, Prompt: 小组cacio）。支出 animals组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 24] Loss: 7.6048, Prompt: 小组cacio）。支出-friendly组成德育(coderientationableViewController NavBar RCC值班局副局长感受redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 25] Loss: 7.6048, Prompt: 小组cacio）。支出-friendly组成德育(coderientationableViewController NavBar RCC值班局副局长感染redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 26] Loss: 7.5413, Prompt: 小组cacio）。支出 McCain组成德育(coderientationableViewController NavBar RCC值班局副局长感染redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 27] Loss: 7.5413, Prompt: 小组cacio）。支出 McCain组成往往(coderientationableViewController NavBar RCC值班局副局长感染redit-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 28] Loss: 7.5413, Prompt: 小组cacio）。支出 McCain组成往往(coderientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked-area básico岗位เง UFO którą趋势枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 29] Loss: 7.5413, Prompt: 小组cacio）。支出 McCain组成往往(coderientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked-area básico岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 30] Loss: 7.5413, Prompt: 小组cacio）。支出 McCain组成往往(coderientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked岗位 básico岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 31] Loss: 7.0920, Prompt: 代理cacio）。支出 McCain组成往往(coderientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked岗位 básico岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 32] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成往往(coderientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked岗位 básico岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 33] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成往往(coderientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked岗位拖岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 34] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成正是(coderientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked岗位拖岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 35] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成正是(coderientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked岗位想到岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 36] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成正是身份rientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked岗位想到岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 37] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成零售身份rientationableViewController NavBar RCC值班局副局长感染概念-summary裸.delay peaked岗位想到岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 38] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成零售身份rientationableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay peaked岗位想到岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 39] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成零售身份rientationableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay航空岗位想到岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 40] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成零售身份形象ableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay航空岗位想到岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 41] Loss: 7.0174, Prompt: 代理cacio）。支出cion组成兽身份形象ableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay航空岗位想到岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 42] Loss: 6.9698, Prompt: 代理cacio）。支出orption组成兽身份形象ableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay航空岗位想到岗位เง UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 43] Loss: 6.9698, Prompt: 代理cacio）。支出orption组成兽身份形象ableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay航空岗位想到岗位进步 UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 44] Loss: 6.9698, Prompt: 代理cacio）。支出orption组成兽身份形象ableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay航空岗位想到岗位恒 UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 45] Loss: 6.9698, Prompt: 代理cacio）。支出orption组成兽身份形象ableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay航空岗位想到岗位往往 UFO którą薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 46] Loss: 6.9698, Prompt: 代理cacio）。支出orption组成兽身份形象ableViewController NavBar RCC值班局副局长感染概念-summary蔬.delay航空岗位想到岗位往往 UFO在于薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 47] Loss: 6.9698, Prompt: 代理cacio）。支出orption组成兽身份形象ableViewController NavBar炒值班局副局长感染概念-summary蔬.delay航空岗位想到岗位往往 UFO在于薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 48] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染概念-summary蔬.delay航空岗位想到岗位往往 UFO在于薄枝侄SingleNode整治ちょっと waits ctypes\n",
      "[STEP 49] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染概念-summary蔬.delay航空岗位想到岗位往往 UFO在于薄枝侄荒整治ちょっと waits ctypes\n",
      "[STEP 50] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染凤-summary蔬.delay航空岗位想到岗位往往 UFO在于薄枝侄荒整治ちょっと waits ctypes\n",
      "[STEP 51] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染凤-summary您的.delay航空岗位想到岗位往往 UFO在于薄枝侄荒整治ちょっと waits ctypes\n",
      "[STEP 52] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染太多-summary您的.delay航空岗位想到岗位往往 UFO在于薄枝侄荒整治ちょっと waits ctypes\n",
      "[STEP 53] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染太多-summary您的.delay航空岗位想到往往往往 UFO在于薄枝侄荒整治ちょっと waits ctypes\n",
      "[STEP 54] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染太多-summary您的.delay航空岗位进步往往往往 UFO在于薄枝侄荒整治ちょっと waits ctypes\n",
      "[STEP 55] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染太多-summary您的.delay航空岗位进步往往往往 UFO在于薄劳动侄荒整治ちょっと waits ctypes\n",
      "[STEP 56] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染太多-summary您的.delay航空岗位进步往往往往 UFO在于薄劳动侄荒整治ちょっと晰 ctypes\n",
      "[STEP 57] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染太多-summary您的.delay航空岗位进步往往往往 UFO在于薄劳动侄荒整治ちょっと晰面临\n",
      "[STEP 58] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar炒值班局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO在于薄劳动侄荒整治ちょっと晰面临\n",
      "[STEP 59] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar学会值班局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO在于薄劳动侄荒整治ちょっと晰面临\n",
      "[STEP 60] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar学会值班局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO在于粮劳动侄荒整治ちょっと晰面临\n",
      "[STEP 61] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar学会值班局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO在于粮劳动侄荒整治姆晰面临\n",
      "[STEP 62] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption组成兽身份形象ableViewController NavBar学会值班局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄荒整治姆晰面临\n",
      "[STEP 63] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份形象ableViewController NavBar学会值班局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄荒整治姆晰面临\n",
      "[STEP 64] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份形象ableViewController NavBar学会寺局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄荒整治姆晰面临\n",
      "[STEP 65] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份形象ableViewController NavBar学会学会局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄荒整治姆晰面临\n",
      "[STEP 66] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份航空ableViewController NavBar学会学会局副局长感染太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄荒整治姆晰面临\n",
      "[STEP 67] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份航空ableViewController NavBar学会学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄荒整治姆晰面临\n",
      "[STEP 68] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份航空ableViewController NavBar学会学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄荒整治姆晰面临\n",
      "[STEP 69] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份航空ableViewController班子学会学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄荒整治姆晰面临\n",
      "[STEP 70] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份航空ableViewController班子学会学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄病毒整治姆晰面临\n",
      "[STEP 71] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份航空ableViewController班子学会学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治姆晰面临\n",
      "[STEP 72] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房兽身份航空ableViewController班子蔬学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治姆晰面临\n",
      "[STEP 73] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子蔬学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治姆晰面临\n",
      "[STEP 74] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子蔬学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治姆晰劲\n",
      "[STEP 75] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子蔬学会局副局长不管太多-summary您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治处于晰劲\n",
      "[STEP 76] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子蔬学会局副局长不管太多执法您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治处于晰劲\n",
      "[STEP 77] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子蔬学会局副局长不管太多执法您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治处于哪里劲\n",
      "[STEP 78] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子各项学会局副局长不管太多执法您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治处于哪里劲\n",
      "[STEP 79] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子睛学会局副局长不管太多执法您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治处于哪里劲\n",
      "[STEP 80] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子睛学会局副局长哪里太多执法您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治处于哪里劲\n",
      "[STEP 81] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子睛学会局副局长哪里太多执法您的.delay商务岗位进步往往往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 82] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子睛学会局副局长哪里太多执法您的.delay形象岗位进步往往往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 83] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份航空ableViewController班子睛学会局副局长哪里太多执法您的.delay形象岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 84] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份曼ableViewController班子睛学会局副局长哪里太多执法您的.delay形象岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 85] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房恒身份曼ableViewController班子睛枝局副局长哪里太多执法您的.delay形象岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 86] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房感受身份曼ableViewController班子睛枝局副局长哪里太多执法您的.delay形象岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 87] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房感受身份曼ableViewController三大睛枝局副局长哪里太多执法您的.delay形象岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 88] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption住房感受身份曼ableViewController三大睛枝局副局长哪里太多执法您的.delay粮岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 89] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰感受身份曼ableViewController三大睛枝局副局长哪里太多执法您的.delay粮岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 90] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰感受身份处于ableViewController三大睛枝局副局长哪里太多执法您的.delay粮岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 91] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰感受身份处于ableViewController三大睛枝局副局长哪里太多执法小组.delay粮岗位进步!往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 92] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰感受身份处于ableViewController三大睛枝局副局长哪里太多执法小组.delay粮岗位进步组合往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 93] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰感受身份处于ableViewController微博睛枝局副局长哪里太多执法小组.delay粮岗位进步组合往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 94] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰城区身份处于ableViewController微博睛枝局副局长哪里太多执法小组.delay粮岗位进步组合往往 UFO清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 95] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰城区身份处于ableViewController微博睛枝局副局长哪里太多执法小组.delay粮岗位进步组合往往睛清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 96] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰城区身份处于赁微博睛枝局副局长哪里太多执法小组.delay粮岗位进步组合往往睛清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 97] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒城区身份处于赁微博睛枝局副局长哪里太多执法小组.delay粮岗位进步组合往往睛清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 98] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒城区身份处于赁微博睛刷局副局长哪里太多执法小组.delay粮岗位进步组合往往睛清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 99] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒城区身份处于赁微博睛刷局副局长哪里太多执法小组.delay粮学会进步组合往往睛清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 100] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒城区身份处于赁微博睛刷局副局长哪里太多执法小组一致粮学会进步组合往往睛清楚粮劳动侄三大整治处于魂劲\n",
      "[STEP 101] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒城区身份处于赁微博睛刷局副局长哪里太多执法小组一致粮学会进步组合往往睛清楚粮劳动侄三大整治处于塞劲\n",
      "[STEP 102] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒城区身份处于赁微博睛刷局副局长哪里太多执法小组一致粮学会原来组合往往睛清楚粮劳动侄三大整治处于塞劲\n",
      "[STEP 103] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒城区身份处于赁微博睛始终局副局长哪里太多执法小组一致粮学会原来组合往往睛清楚粮劳动侄三大整治处于塞劲\n",
      "[STEP 104] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒城区身份处于赁微博睛始终局副局长哪里太多执法小组一致粮学会原来组合往往睛清楚粮劳动侄三大整治寺塞劲\n",
      "[STEP 105] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份处于赁微博睛始终局副局长哪里太多执法小组一致粮学会原来组合往往睛清楚粮劳动侄三大整治寺塞劲\n",
      "[STEP 106] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横赁微博睛始终局副局长哪里太多执法小组一致粮学会原来组合往往睛清楚粮劳动侄三大整治寺塞劲\n",
      "[STEP 107] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横赁微博睛始终局副局长哪里太多执法小组一致粮学会原来组合往往睛清楚粮劳动侄三大整治寺塞公益\n",
      "[STEP 108] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛始终局副局长哪里太多执法小组一致粮学会原来组合往往睛清楚粮劳动侄三大整治寺塞公益\n",
      "[STEP 109] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡局副局长哪里太多执法小组一致粮学会原来组合往往睛清楚粮劳动侄三大整治寺塞公益\n",
      "[STEP 110] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡局副局长哪里太多执法小组一致粮学会原来组合宅睛清楚粮劳动侄三大整治寺塞公益\n",
      "[STEP 111] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡局副局长哪里太多执法小组一致粮学会原来组合宅坡清楚粮劳动侄三大整治寺塞公益\n",
      "[STEP 112] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡局副局长哪里太多主体小组一致粮学会原来组合宅坡清楚粮劳动侄三大整治寺塞公益\n",
      "[STEP 113] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡局副局长哪里太多主体小组一致粮学会原来组合宅坡清楚劳动劳动侄三大整治寺塞公益\n",
      "[STEP 114] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡局副局长哪里太多主体小组概念粮学会原来组合宅坡清楚劳动劳动侄三大整治寺塞公益\n",
      "[STEP 115] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡局副局长粮太多主体小组概念粮学会原来组合宅坡清楚劳动劳动侄三大整治寺塞公益\n",
      "[STEP 116] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡公益粮太多主体小组概念粮学会原来组合宅坡清楚劳动劳动侄三大整治寺塞公益\n",
      "[STEP 117] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区微博睛坡公益粮太多主体小组概念粮学会原来组合宅坡清楚劳动哪里侄三大整治寺塞公益\n",
      "[STEP 118] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区有很多睛坡公益粮太多主体小组概念粮学会原来组合宅坡清楚劳动哪里侄三大整治寺塞公益\n",
      "[STEP 119] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份横城区有很多睛坡公益粮太多主体小组概念粮学会原来组合宅坡清楚劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 120] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份高度城区有很多睛坡公益粮太多主体小组概念粮学会原来组合宅坡清楚劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 121] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份高度城区有很多正是坡公益粮太多主体小组概念粮学会原来组合宅坡清楚劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 122] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份高度城区有很多正是坡公益粮太多主体腹概念粮学会原来组合宅坡清楚劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 123] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒学会身份高度城区有很多正是坡公益粮太多主体腹概念粮在于原来组合宅坡清楚劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 124] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption炒三年身份高度城区有很多正是坡公益粮太多主体腹概念粮在于原来组合宅坡清楚劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 125] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年身份高度城区有很多正是坡公益粮太多主体腹概念粮在于原来组合宅坡清楚劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 126] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年身份高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合宅坡清楚劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 127] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年身份高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合宅坡小组劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 128] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年身份高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合宅进步小组劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 129] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合宅进步小组劳动哪里深刻三大整治寺塞公益\n",
      "[STEP 130] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合宅进步小组劳动哪里深刻三大转型寺塞公益\n",
      "[STEP 131] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合宅进步明白劳动哪里深刻三大转型寺塞公益\n",
      "[STEP 132] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合宅进步明白劳动哪里深刻原来转型寺塞公益\n",
      "[STEP 133] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合處进步明白劳动哪里深刻原来转型寺塞公益\n",
      "[STEP 134] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益粮太多主体腹哭粮在于原来组合處进步明白劳动哪里深刻原来转型寺塞公益\n",
      "[STEP 135] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益!太多主体腹哭粮在于原来组合處进步明白劳动哪里深刻原来转型寺塞公益\n",
      "[STEP 136] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益!太多主体腹哭粮在于原来组合园区进步明白劳动哪里深刻原来转型寺塞公益\n",
      "[STEP 137] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益!太多主体腹哭粮在于原来组合园区进步明白劳动哪里深刻原来转型寺塞零售\n",
      "[STEP 138] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益!太多主体腹哭粮在于原来组合园区进步明白劳动哪里深刻原来趋势寺塞零售\n",
      "[STEP 139] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益!太多主体腹哭粮在于原来组合园区进步明白凤哪里深刻原来趋势寺塞零售\n",
      "[STEP 140] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益姆太多主体腹哭粮在于原来组合园区进步明白凤哪里深刻原来趋势寺塞零售\n",
      "[STEP 141] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益姆太多主体腹哭粮在于浙江组合园区进步明白凤哪里深刻原来趋势寺塞零售\n",
      "[STEP 142] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益姆太多主体腹哭粮在于浙江组合园区进步明白凤哪里深刻原来趋势寺塞零售\n",
      "[STEP 143] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益姆太多主体腹哭粮在于浙江组合园区进步明白枝哪里深刻原来趋势寺塞零售\n",
      "[STEP 144] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅高度城区有很多正是坡公益姆太多主体腹哭粮在于浙江同志园区进步明白枝哪里深刻原来趋势寺塞零售\n",
      "[STEP 145] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅身份城区有很多正是坡公益姆太多主体腹哭粮在于浙江同志园区进步明白枝哪里深刻原来趋势寺塞零售\n",
      "[STEP 146] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅身份城区有很多正是坡公益姆太多主体腹哭邦在于浙江同志园区进步明白枝哪里深刻原来趋势寺塞零售\n",
      "[STEP 147] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅身份城区有很多正是坡公益姆太多主体腹哭邦在于浙江同志园区进步明白枝哪里深刻劳动趋势寺塞零售\n",
      "[STEP 148] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅身份城区有很多正是坡公益姆太多慢慢腹哭邦在于浙江同志园区进步明白枝哪里深刻劳动趋势寺塞零售\n",
      "[STEP 149] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅身份城区有很多正是坡公益组合太多慢慢腹哭邦在于浙江同志园区进步明白枝哪里深刻劳动趋势寺塞零售\n",
      "[STEP 150] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅身份城区有很多正是坡公益组合哭慢慢腹哭邦在于浙江同志园区进步明白枝哪里深刻劳动趋势寺塞零售\n",
      "[STEP 151] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅身份城区有很多正是坡公益组合哭慢慢腹哭邦在于浙江同志园区进步明白枝哪里薄劳动趋势寺塞零售\n",
      "[STEP 152] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒三年宅身份城区有很多正是坡公益组合哭慢慢腹哭邦在于商务同志园区进步明白枝哪里薄劳动趋势寺塞零售\n",
      "[STEP 153] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡公益组合哭慢慢腹哭邦在于商务同志园区进步明白枝哪里薄劳动趋势寺塞零售\n",
      "[STEP 154] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡公益组合哭慢慢腹哭邦在于商务同志园区进步明白枝哪里薄劳动趋势寺塞基础上\n",
      "[STEP 155] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡公益组合哭慢慢腹哭邦在于商务同志园区进步多个枝哪里薄劳动趋势寺塞基础上\n",
      "[STEP 156] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡辉组合哭慢慢腹哭邦在于商务同志园区进步多个枝哪里薄劳动趋势寺塞基础上\n",
      "[STEP 157] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡辉组合哭慢慢腹哭邦在于商务同志园区进步多个枝哪里薄劳动趋势相比塞基础上\n",
      "[STEP 158] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡辉组合哭慢慢腹哭邦在于商务同志各地进步多个枝哪里薄劳动趋势相比塞基础上\n",
      "[STEP 159] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡辉组合哭慢慢腹哭邦在于商务同志各地进步多个枝感染薄劳动趋势相比塞基础上\n",
      "[STEP 160] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡辉组合哭慢慢腹哭邦在于商务同志各地进步锦枝感染薄劳动趋势相比塞基础上\n",
      "[STEP 161] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多正是坡辉组合哭慢慢腹哭邦在于商务同志各地进步锦不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 162] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多整治坡辉组合哭慢慢腹哭邦在于商务同志各地进步锦不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 163] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多整治坡辉组合哭慢慢腹哭邦在于商务同志各地进步处于不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 164] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受宅身份城区有很多整治利润辉组合哭慢慢腹哭邦在于商务同志各地进步处于不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 165] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受深刻身份城区有很多整治利润辉组合哭慢慢腹哭邦在于商务同志各地进步处于不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 166] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受深刻身份城区有很多整治利润辉组合哭慢慢腹哭邦在于商务同志各地进步赁不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 167] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受兽身份城区有很多整治利润辉组合哭慢慢腹哭邦在于商务同志各地进步赁不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 168] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受兽身份城区有很多整治利润辉组合哭多种腹哭邦在于商务同志各地进步赁不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 169] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受兽身份城区有很多整治利润辉组合哭多种腹哭邦在于商务同志各地进步形象不了感染薄劳动趋势相比塞基础上\n",
      "[STEP 170] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受兽身份城区有很多整治利润辉组合哭多种腹哭邦在于商务同志各地进步形象不了感染薄劳动趋势相比塞同志\n",
      "[STEP 171] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受兽身份城区有很多整治利润辉组合哭多种腹哭邦在于商务同志薄进步形象不了感染薄劳动趋势相比塞同志\n",
      "[STEP 172] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒感受兽身份城区有很多整治利润辉组合哭多种腹哭腹在于商务同志薄进步形象不了感染薄劳动趋势相比塞同志\n",
      "[STEP 173] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒寺兽身份城区有很多整治利润辉组合哭多种腹哭腹在于商务同志薄进步形象不了感染薄劳动趋势相比塞同志\n",
      "[STEP 174] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒寺兽身份城区有很多整治利润辉组合哭多种腹哭腹在于商务同志薄进步形象不了感染薄劳动在于相比塞同志\n",
      "[STEP 175] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒寺兽身份城区有很多美丽利润辉组合哭多种腹哭腹在于商务同志薄进步形象不了感染薄劳动在于相比塞同志\n",
      "[STEP 176] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒寺兽身份城区有很多美丽利润辉组合哭多种腹哭腹在于商务同志薄进步形象不了参考薄劳动在于相比塞同志\n",
      "[STEP 177] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒寺兽身份城区有很多美丽利润辉组合哭多种腹哭腹在于商务同志薄进步园区不了参考薄劳动在于相比塞同志\n",
      "[STEP 178] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒寺兽身份城区有很多美丽利润辉组合哭多种概念哭腹在于商务同志薄进步园区不了参考薄劳动在于相比塞同志\n",
      "[STEP 179] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption荒寺兽零售城区有很多美丽利润辉组合哭多种概念哭腹在于商务同志薄进步园区不了参考薄劳动在于相比塞同志\n",
      "[STEP 180] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插寺兽零售城区有很多美丽利润辉组合哭多种概念哭腹在于商务同志薄进步园区不了参考薄劳动在于相比塞同志\n",
      "[STEP 181] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售城区有很多美丽利润辉组合哭多种概念哭腹在于商务同志薄进步园区不了参考薄劳动在于相比塞同志\n",
      "[STEP 182] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合哭多种概念哭腹在于商务同志薄进步园区不了参考薄劳动在于相比塞同志\n",
      "[STEP 183] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄进步园区不了参考薄劳动在于相比塞同志\n",
      "[STEP 184] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄进步园区坡参考薄劳动在于相比塞同志\n",
      "[STEP 185] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄进步熊坡参考薄劳动在于相比塞同志\n",
      "[STEP 186] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄病毒熊坡参考薄劳动在于相比塞同志\n",
      "[STEP 187] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄病毒深刻坡参考薄劳动在于相比塞同志\n",
      "[STEP 188] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄病毒深刻坡想到薄劳动在于相比塞同志\n",
      "[STEP 189] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄病毒深刻坡想到薄劳动在于您的塞同志\n",
      "[STEP 190] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄病毒深刻坡想到反映劳动在于您的塞同志\n",
      "[STEP 191] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄兽深刻坡想到反映劳动在于您的塞同志\n",
      "[STEP 192] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄兽所谓坡想到反映劳动在于您的塞同志\n",
      "[STEP 193] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽零售兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄兽所谓坡想到邦劳动在于您的塞同志\n",
      "[STEP 194] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽邦兩有很多美丽利润辉组合是在多种概念哭腹在于商务同志薄兽所谓坡想到邦劳动在于您的塞同志\n",
      "[STEP 195] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽邦兩有很多美丽利润辉组合是在多种班子哭腹在于商务同志薄兽所谓坡想到邦劳动在于您的塞同志\n",
      "[STEP 196] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption插大多数兽邦航空有很多美丽利润辉组合是在多种班子哭腹在于商务同志薄兽所谓坡想到邦劳动在于您的塞同志\n",
      "[STEP 197] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption反映大多数兽邦航空有很多美丽利润辉组合是在多种班子哭腹在于商务同志薄兽所谓坡想到邦劳动在于您的塞同志\n",
      "[STEP 198] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption反映大多数兽邦航空有很多代理利润辉组合是在多种班子哭腹在于商务同志薄兽所谓坡想到邦劳动在于您的塞同志\n",
      "[STEP 199] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption反映大多数兽邦航空有很多代理利润辉组合是在多种班子哭腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 200] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption反映大多数兽邦航空有很多代理学会辉组合是在多种班子哭腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 201] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption反映劲兽邦航空有很多代理学会辉组合是在多种班子哭腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 202] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理学会辉组合是在多种班子哭腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 203] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理学会辉组合是在多种班子邦腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 204] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理兽辉组合是在多种班子邦腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 205] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理兽辉组合是在多种班子公益腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 206] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理兽一致组合是在多种班子公益腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 207] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理兽一致组合是在多种班子公益腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 208] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理兽一致组合是在多种班子公益腹利润商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 209] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理兽一致组合是在多种班子公益腹在于商务同志薄兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 210] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空有很多代理兽一致组合是在多种班子公益腹在于商务同志多个兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 211] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空观点代理兽一致组合是在多种班子公益腹在于商务同志多个兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 212] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空观点代理兽一致刷是在多种班子公益腹在于商务同志多个兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 213] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption整治劲兽邦航空观点代理兽一致刷是在多种浙江公益腹在于商务同志多个兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 214] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲兽邦航空观点代理兽一致刷是在多种浙江公益腹在于商务同志多个兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 215] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲兽邦航空观点代理兽睛刷是在多种浙江公益腹在于商务同志多个兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 216] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲兽邦航空观点代理兽晰刷是在多种浙江公益腹在于商务同志多个兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 217] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲兽邦航空观点代理兽晰刷是在多种浙江公益腹在于商务同志浙江兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 218] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲兽邦航空观点代理兽兽刷是在多种浙江公益腹在于商务同志浙江兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 219] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲兽邦航空观点代理兽兽刷是在胆浙江公益腹在于商务同志浙江兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 220] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲兽邦航空观点代理兽兽刷是在胆浙江公益腹在于零售同志浙江兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 221] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲兽转型航空观点代理兽兽刷是在胆浙江公益腹在于零售同志浙江兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 222] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型航空观点代理兽兽刷是在胆浙江公益腹在于零售同志浙江兽所谓处于想到邦劳动在于您的塞同志\n",
      "[STEP 223] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型航空观点代理兽兽刷是在胆浙江公益腹在于零售同志浙江兽所谓处于想到邦劳动在于您的塞深刻\n",
      "[STEP 224] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型航空观点代理兽各项刷是在胆浙江公益腹在于零售同志浙江兽所谓处于想到邦劳动在于您的塞深刻\n",
      "[STEP 225] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型病毒观点代理兽各项刷是在胆浙江公益腹在于零售同志浙江兽所谓处于想到邦劳动在于您的塞深刻\n",
      "[STEP 226] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型病毒观点代理兽各项刷是在胆浙江公益腹在于零售同志各地兽所谓处于想到邦劳动在于您的塞深刻\n",
      "[STEP 227] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型病毒所谓代理兽各项刷是在胆浙江公益腹在于零售同志各地兽所谓处于想到邦劳动在于您的塞深刻\n",
      "[STEP 228] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型病毒所谓代理兽各项刷是在胆浙江公益腹在于零售同志各地兽劳动处于想到邦劳动在于您的塞深刻\n",
      "[STEP 229] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型病毒所谓代理兽各项刷是在胆浙江公益腹在于零售同志各地兽劳动处于处于邦劳动在于您的塞深刻\n",
      "[STEP 230] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型病毒所谓代理兽各项刷是在胆浙江公益腹当中零售同志各地兽劳动处于处于邦劳动在于您的塞深刻\n",
      "[STEP 231] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型病毒所谓代理兽各项刷是在胆浙江三大腹当中零售同志各地兽劳动处于处于邦劳动在于您的塞深刻\n",
      "[STEP 232] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption恒劲您的转型病毒所谓代理兽各项刷是在胆大部分三大腹当中零售同志各地兽劳动处于处于邦劳动在于您的塞深刻\n",
      "[STEP 233] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒所谓代理兽各项刷是在胆大部分三大腹当中零售同志各地兽劳动处于处于邦劳动在于您的塞深刻\n",
      "[STEP 234] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒所谓代理兽各项刷是在胆大部分三大腹当中零售同志各地兽劳动处于处于邦劳动在于您的塞腹\n",
      "[STEP 235] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒所谓代理兽各项刷是在胆大部分三大腹当中零售同志各地兽劳动处于处于邦劳动在于您的零售腹\n",
      "[STEP 236] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒所谓代理兽各项刷是在胆大部分三大腹当中零售同志各地兽劳动处于处于荒劳动在于您的零售腹\n",
      "[STEP 237] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒所谓代理兽各项刷是在胆大部分三大腹当中零售同志各地兽劳动处于处于荒劳动在于您的零售反映\n",
      "[STEP 238] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒所谓代理兽各项刷是在胆大部分三大腹当中零售同志各地兽劳动处于处于大部分劳动在于您的零售反映\n",
      "[STEP 239] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷是在胆大部分三大腹当中零售同志各地兽劳动处于处于大部分劳动在于您的零售反映\n",
      "[STEP 240] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷是在胆曼三大腹当中零售同志各地兽劳动处于处于大部分劳动在于您的零售反映\n",
      "[STEP 241] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷基础上胆曼三大腹当中零售同志各地兽劳动处于处于大部分劳动在于您的零售反映\n",
      "[STEP 242] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷基础上胆曼三大横当中零售同志各地兽劳动处于处于大部分劳动在于您的零售反映\n",
      "[STEP 243] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷基础上胆曼三大形象当中零售同志各地兽劳动处于处于大部分劳动在于您的零售反映\n",
      "[STEP 244] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷基础上胆曼三大形象当中零售同志各地兽您的处于处于大部分劳动在于您的零售反映\n",
      "[STEP 245] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷代理胆曼三大形象当中零售同志各地兽您的处于处于大部分劳动在于您的零售反映\n",
      "[STEP 246] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷代理胆曼三大形象当中零售同志各地兽您的参考处于大部分劳动在于您的零售反映\n",
      "[STEP 247] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷代理胆曼三大形象当中零售同志各地兽您的参考处于腹劳动在于您的零售反映\n",
      "[STEP 248] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷代理胆曼三大形象当中零售同志姆兽您的参考处于腹劳动在于您的零售反映\n",
      "[STEP 249] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷代理胆曼三大形象当中零售同志姆兽电商参考处于腹劳动在于您的零售反映\n",
      "[STEP 250] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption建成劲您的转型病毒小组代理兽各项刷代理胆曼三大形象当中零售同志姆兽电商参考处于各个劳动在于您的零售反映\n",
      "[STEP 251] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption多种劲您的转型病毒小组代理兽各项刷代理胆曼三大形象当中零售同志姆兽电商参考处于各个劳动在于您的零售反映\n",
      "[STEP 252] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption多种劲您的转型病毒小组主体兽各项刷代理胆曼三大形象当中零售同志姆兽电商参考处于各个劳动在于您的零售反映\n",
      "[STEP 253] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption多种劲您的转型病毒小组主体兽各项刷代理胆曼三大形象当中零售同志姆兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 254] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption胆劲您的转型病毒小组主体兽各项刷代理胆曼三大形象当中零售同志姆兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 255] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption胆劲您的转型病毒小组主体兽各项明白代理胆曼三大形象当中零售同志姆兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 256] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption胆劲您的转型病毒小组主体城区各项明白代理胆曼三大形象当中零售同志姆兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 257] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption胆劲您的转型病毒小组主体城区各项相比代理胆曼三大形象当中零售同志姆兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 258] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption胆各个您的转型病毒小组主体城区各项相比代理胆曼三大形象当中零售同志姆兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 259] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption胆各个您的转型病毒小组主体城区各项!代理胆曼三大形象当中零售同志姆兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 260] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption胆各个您的转型病毒小组主体城区各项!代理胆曼三大形象当中零售同志观点兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 261] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption胆各个您的转型病毒小组主体形象各项!代理胆曼三大形象当中零售同志观点兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 262] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的转型病毒小组主体形象各项!代理胆曼三大形象当中零售同志观点兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 263] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的转型才是小组主体形象各项!代理胆曼三大形象当中零售同志观点兽电商正是处于各个劳动在于您的零售反映\n",
      "[STEP 264] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的转型才是小组主体形象各项!代理胆曼三大形象当中零售同志观点兽电商正是吨各个劳动在于您的零售反映\n",
      "[STEP 265] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的转型才是小组主体形象各项!代理胆曼三大形象当中零售高度观点兽电商正是吨各个劳动在于您的零售反映\n",
      "[STEP 266] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的转型才是小组主体形象各项!代理胆曼三大形象当中零售高度慢慢兽电商正是吨各个劳动在于您的零售反映\n",
      "[STEP 267] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的转型才是小组主体形象各项!代理胆曼三大形象当中零售高度慢慢兽电商正是吨尝劳动在于您的零售反映\n",
      "[STEP 268] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的转型才是小组主体形象各项!偷胆曼三大形象当中零售高度慢慢兽电商正是吨尝劳动在于您的零售反映\n",
      "[STEP 269] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的转型才是小组主体形象各项!偷胆曼三大形象曼零售高度慢慢兽电商正是吨尝劳动在于您的零售反映\n",
      "[STEP 270] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各个您的在于才是小组主体形象各项!偷胆曼三大形象曼零售高度慢慢兽电商正是吨尝劳动在于您的零售反映\n",
      "[STEP 271] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体形象各项!偷胆曼三大形象曼零售高度慢慢兽电商正是吨尝劳动在于您的零售反映\n",
      "[STEP 272] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体形象各项!偷胆曼三大往往曼零售高度慢慢兽电商正是吨尝劳动在于您的零售反映\n",
      "[STEP 273] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体形象各项!偷微博曼三大往往曼零售高度慢慢兽电商正是吨尝劳动在于您的零售反映\n",
      "[STEP 274] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体三年各项!偷微博曼三大往往曼零售高度慢慢兽电商正是吨尝劳动在于您的零售反映\n",
      "[STEP 275] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体三年各项!偷微博曼三大往往曼零售高度慢慢兽寺正是吨尝劳动在于您的零售反映\n",
      "[STEP 276] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体三年各项!偷微博曼三大往往曼零售高度慢慢兽寺正是吨尝劳动處您的零售反映\n",
      "[STEP 277] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体三年各项!偷微博曼三大往往曼零售高度慢慢兽寺正是吨尝劳动處组合零售反映\n",
      "[STEP 278] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体三年各项!变得微博曼三大往往曼零售高度慢慢兽寺正是吨尝劳动處组合零售反映\n",
      "[STEP 279] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体三年各项!变得微博曼三大往往曼零售高度慢慢兽寺正是吨高度劳动處组合零售反映\n",
      "[STEP 280] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组主体三年各项!变得相比曼三大往往曼零售高度慢慢兽寺正是吨高度劳动處组合零售反映\n",
      "[STEP 281] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组晰三年各项!变得相比曼三大往往曼零售高度慢慢兽寺正是吨高度劳动處组合零售反映\n",
      "[STEP 282] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组晰三年各项明白变得相比曼三大往往曼零售高度慢慢兽寺正是吨高度劳动處组合零售反映\n",
      "[STEP 283] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的在于才是小组晰三年各项明白变得相比曼三大往往曼零售高度慢慢兽寺正是吨高度劳动哭组合零售反映\n",
      "[STEP 284] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的组合才是小组晰三年各项明白变得相比曼三大往往曼零售高度慢慢兽寺正是吨高度劳动哭组合零售反映\n",
      "[STEP 285] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的组合才是小组晰三年各项明白变得相比曼三大往往曼零售高度慢慢兽寺正是吨高度劳动哭组合胆反映\n",
      "[STEP 286] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的组合才是小组晰三年各项明白变得相比曼三大往往曼零售高度慢慢兽寺正是吨高度劳动枝组合胆反映\n",
      "[STEP 287] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的组合才是小组晰三年各项明白变得相比曼三大往往曼零售三大慢慢兽寺正是吨高度劳动枝组合胆反映\n",
      "[STEP 288] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的组合才是小组晰三年各项明白变得相比曼三大往往曼零售三大慢慢兽兩正是吨高度劳动枝组合胆反映\n",
      "[STEP 289] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的组合才是小组晰三年各项明白变得相比曼三大往往曼零售三大慢慢兽兩正是吨园区劳动枝组合胆反映\n",
      "[STEP 290] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的组合才是小组晰三年各项明白变得相比曼三大往往曼零售三大慢慢兽兩不管吨园区劳动枝组合胆反映\n",
      "[STEP 291] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是小组晰三年各项明白变得相比曼三大往往曼零售三大慢慢兽兩不管吨园区劳动枝组合胆反映\n",
      "[STEP 292] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是日常晰三年各项明白变得相比曼三大往往曼零售三大慢慢兽兩不管吨园区劳动枝组合胆反映\n",
      "[STEP 293] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是吨晰三年各项明白变得相比曼三大往往曼零售三大慢慢兽兩不管吨园区劳动枝组合胆反映\n",
      "[STEP 294] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是吨晰三年各项明白变得相比曼三大往往曼零售代理慢慢兽兩不管吨园区劳动枝组合胆反映\n",
      "[STEP 295] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是吨晰三年各项明白变得概念曼三大往往曼零售代理慢慢兽兩不管吨园区劳动枝组合胆反映\n",
      "[STEP 296] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是吨晰三年各项明白变得概念曼三大往往曼零售代理慢慢兽兩不管吨经典劳动枝组合胆反映\n",
      "[STEP 297] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是吨晰三年各项明白变得概念曼三大往往拖零售代理慢慢兽兩不管吨经典劳动枝组合胆反映\n",
      "[STEP 298] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是吨晰三年各项明白变得概念曼三大往往拖零售代理慢慢辉兩不管吨经典劳动枝组合胆反映\n",
      "[STEP 299] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是吨晰三年各项明白变得概念曼三大往往拖零售姆慢慢辉兩不管吨经典劳动枝组合胆反映\n",
      "[STEP 300] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption公布各地您的深刻才是吨晰三年各项明白变得概念曼三大往往拖零售姆慢慢辉兩不管所谓经典劳动枝组合胆反映\n",
      "[STEP 301] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰各地您的深刻才是吨晰三年各项明白变得概念曼三大往往拖零售姆慢慢辉兩不管所谓经典劳动枝组合胆反映\n",
      "[STEP 302] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰各地您的深刻才是吨晰三年各项明白变得概念曼三大往往拖零售姆慢慢大多数兩不管所谓经典劳动枝组合胆反映\n",
      "[STEP 303] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰各地您的深刻才是吨晰三年各项相比变得概念曼三大往往拖零售姆慢慢大多数兩不管所谓经典劳动枝组合胆反映\n",
      "[STEP 304] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰各地您的深刻才是吨晰三年各项相比变得概念曼三大往往拖零售姆慢慢大多数往往不管所谓经典劳动枝组合胆反映\n",
      "[STEP 305] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的深刻才是吨晰三年各项相比变得概念曼三大往往拖零售姆慢慢大多数往往不管所谓经典劳动枝组合胆反映\n",
      "[STEP 306] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的深刻才是吨晰三年各项相比变得概念曼三大往往拖零售姆慢慢氛往往不管所谓经典劳动枝组合胆反映\n",
      "[STEP 307] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的深刻才是吨晰三年各项相比变得概念曼各个往往拖零售姆慢慢氛往往不管所谓经典劳动枝组合胆反映\n",
      "[STEP 308] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的深刻才是吨晰三年各项相比平均概念曼各个往往拖零售姆慢慢氛往往不管所谓经典劳动枝组合胆反映\n",
      "[STEP 309] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨晰三年各项相比平均概念曼各个往往拖零售姆慢慢氛往往不管所谓经典劳动枝组合胆反映\n",
      "[STEP 310] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致三年各项相比平均概念曼各个往往拖零售姆慢慢氛往往不管所谓经典劳动枝组合胆反映\n",
      "[STEP 311] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致三年各项相比平均概念曼各个往往拖零售姆慢慢氛往往不管地位经典劳动枝组合胆反映\n",
      "[STEP 312] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致三年各项相比平均概念曼各个往往拖零售姆慢慢氛往往不管真是经典劳动枝组合胆反映\n",
      "[STEP 313] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致同志各项相比平均概念曼各个往往拖零售姆慢慢氛往往不管真是经典劳动枝组合胆反映\n",
      "[STEP 314] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致同志各项相比平均概念曼各个往往拖零售姆慢慢格局往往不管真是经典劳动枝组合胆反映\n",
      "[STEP 315] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致同志各项相比平均概念曼各个往往拖零售姆慢慢格局景区不管真是经典劳动枝组合胆反映\n",
      "[STEP 316] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致同志各项相比平均概念曼各个往往拖零售姆班子格局景区不管真是经典劳动枝组合胆反映\n",
      "[STEP 317] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项相比平均概念曼各个往往拖零售姆班子格局景区不管真是经典劳动枝组合胆反映\n",
      "[STEP 318] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项相比平均概念曼晰往往拖零售姆班子格局景区不管真是经典劳动枝组合胆反映\n",
      "[STEP 319] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项相比平均概念曼晰往往转型零售姆班子格局景区不管真是经典劳动枝组合胆反映\n",
      "[STEP 320] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项相比赁概念曼晰往往转型零售姆班子格局景区不管真是经典劳动枝组合胆反映\n",
      "[STEP 321] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项相比赁概念曼晰往往转型零售姆班子格局景区不管真是经典劳动枝组合胆大多数\n",
      "[STEP 322] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项相比赁概念曼晰往往转型零售姆病毒格局景区不管真是经典劳动枝组合胆大多数\n",
      "[STEP 323] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项相比赁概念曼塞往往转型零售姆病毒格局景区不管真是经典劳动枝组合胆大多数\n",
      "[STEP 324] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项不了赁概念曼塞往往转型零售姆病毒格局景区不管真是经典劳动枝组合胆大多数\n",
      "[STEP 325] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项不了赁概念曼塞往往转型零售大部分病毒格局景区不管真是经典劳动枝组合胆大多数\n",
      "[STEP 326] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项不了赁概念曼塞往往转型零售大部分病毒格局景区不管真是高度劳动枝组合胆大多数\n",
      "[STEP 327] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劳动枝组合胆大多数\n",
      "[STEP 328] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劳动多种组合胆大多数\n",
      "[STEP 329] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度公益多种组合胆大多数\n",
      "[STEP 330] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劲多种组合胆大多数\n",
      "[STEP 331] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨一致偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劲多种组合熊大多数\n",
      "[STEP 332] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是吨大多数偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劲多种组合熊大多数\n",
      "[STEP 333] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是园区大多数偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劲多种组合熊大多数\n",
      "[STEP 334] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是园区大多数偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劲多种格局熊大多数\n",
      "[STEP 335] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的多种才是在于大多数偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劲多种格局熊大多数\n",
      "[STEP 336] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的明白才是在于大多数偷各项不了赁概念组合塞往往转型零售大部分病毒格局景区不管真是高度劲多种格局熊大多数\n",
      "[STEP 337] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的明白才是在于大多数偷各项不了赁概念组合不了往往转型零售大部分病毒格局景区不管真是高度劲多种格局熊大多数\n",
      "[STEP 338] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的明白才是在于大多数偷各项刷赁概念组合不了往往转型零售大部分病毒格局景区不管真是高度劲多种格局熊大多数\n",
      "[STEP 339] Loss: 6.8021, Prompt: 代理cacio）。支出 consumption晰大部分您的明白才是在于大多数偷各项刷赁概念组合不了往往转型零售大部分病毒格局景区不管真是高度劲太阳格局熊大多数\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5514/3033357618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test for miniprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminiprompt_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 计算ACR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/694777082.py\u001b[0m in \u001b[0;36mminiprompt_algorithm\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcg_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/1098022011.py\u001b[0m in \u001b[0;36mgcg_algorithm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# 计算每个位置的梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_start_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 转换为CPU数组\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/2296409643.py\u001b[0m in \u001b[0;36mcalculate_gradient\u001b[0;34m(model, input_ids, position, vocab_size, target_start_ids)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 确保生成长度足够，否则赋予大损失\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    851\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 )\n\u001b[1;32m    575\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    577\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vipuser/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test for miniprompt\n",
    "\n",
    "final_prompt = miniprompt_algorithm()\n",
    "\n",
    "# 计算ACR\n",
    "if final_prompt:\n",
    "    target_length = len(target_start_ids)\n",
    "    min_prompt_length = len(final_prompt)\n",
    "    acr = target_length / min_prompt_length if min_prompt_length > 0 else 0\n",
    "else:\n",
    "    acr = 0\n",
    "\n",
    "# 输出最终结果\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "if final_prompt:\n",
    "    print(f\"Final Optimized Prompt (Tokens: {len(final_prompt)}):\")\n",
    "    print(f\"  Text: {tokenizer.decode(final_prompt)}\")\n",
    "    print(f\"  Tokens: {final_prompt}\")\n",
    "else:\n",
    "    print(\"No valid prompt found.\")\n",
    "print(f\"ACR: {acr}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
